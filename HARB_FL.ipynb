{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout, MaxPooling1D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import CSVLogger, EarlyStopping\n",
    "\n",
    "import os\n",
    "from os.path import join\n",
    "import warnings\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
    "from tensorflow.keras.layers import Dropout, Flatten, RepeatVector, Activation, Concatenate\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, Conv2D, MaxPooling2D, LSTM, GRU, BatchNormalization, Reshape\n",
    "from tensorflow.keras.layers import TimeDistributed, Dense, Input, GlobalAveragePooling2D, Bidirectional\n",
    "from tensorflow.keras.layers import LayerNormalization\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
    "\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.models import  Sequential\n",
    "from tensorflow.keras.optimizers import RMSprop, Adadelta, Adam\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.optimizers.schedules import PolynomialDecay\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.losses import BinaryCrossentropy, CategoricalCrossentropy, SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow.keras.backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "from functools import reduce\n",
    "from scipy.signal import savgol_filter \n",
    "import matplotlib.colors as mcolors\n",
    "csfont = {'fontname':'Arial'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_data (data_dir, label, as_np = False, as_df = False) : \n",
    "\n",
    "    experiments = [] \n",
    "    data = [] \n",
    "    with open(data_dir, 'r') as f : \n",
    "        for line in f.readlines() : \n",
    "            if line.startswith('month') : \n",
    "                if len(data) : \n",
    "                    experiments.append(data) \n",
    "                    data = [] \n",
    "            data.append(line) \n",
    "        if len(data) : \n",
    "            experiments.append(data) \n",
    "    \n",
    "    if as_np or as_df : \n",
    "        np_exps = [] \n",
    "        for i, exp in enumerate(experiments) : \n",
    "            _, data = put_experiment_data_to_np(exp, label = label)  \n",
    "            np_exps.append(data) \n",
    "        np_exp = np.concatenate(np_exps) \n",
    "\n",
    "        if as_df : \n",
    "            dataframe_dict = {\n",
    "                'hr': np_exp[:, 0],\n",
    "                'gryo_x': np_exp[:, 1], \n",
    "                'gyro_y': np_exp[:, 2], \n",
    "                'gyro_z': np_exp[:, 3],\n",
    "                'timestamp': np_exp[:, 4], \n",
    "                'label': np_exp[:, 5]}\n",
    "            df = pd.DataFrame(dataframe_dict)\n",
    "            return df \n",
    "         \n",
    "        return np_exp \n",
    "\n",
    "\n",
    "    return experiments \n",
    "\n",
    "\n",
    "\n",
    "def put_experiment_data_to_np(exp, label = None) : \n",
    "\n",
    "    def get_first_hr(exp) : \n",
    "        for i in range(1, len(exp)):\n",
    "            line = exp[i]\n",
    "            vars = line.split(',') \n",
    "            if len(vars) == 2 : \n",
    "                return int(vars[0])\n",
    "    hr = get_first_hr(exp) \n",
    "    np_data = []\n",
    "    for i in range(1, len(exp)):\n",
    "        line = exp[i]\n",
    "        vars = line.split(',') \n",
    "        if len(vars) == 2 : \n",
    "            if (int(vars[0])  < 0) : continue \n",
    "            hr = (int(vars[0]) + hr) // 2\n",
    "        elif len(vars) == 4 : \n",
    "            gryo_vars = list(map(int, vars[:3])) \n",
    "            if label is not None : \n",
    "                data = np.array([hr, *gryo_vars, int(vars[3].split('.')[0]), label])\n",
    "            else : \n",
    "                data = np.array([hr, *gryo_vars, int(vars[3].split('.')[0])])\n",
    "            np_data.append(data)      \n",
    "    return exp[0], np.array(np_data) \n",
    "\n",
    "\n",
    "\n",
    "def get_models(p, configurations) : \n",
    "\n",
    "    learning_rate = p['learning_rate']\n",
    "    seq_len = p['seq_len']\n",
    "    n_features = p['n_features']\n",
    "    n_classes = p['n_classes']\n",
    "\n",
    "    filters1, filters2, filters3 = configurations['filters']\n",
    "    lstm_units1, lstm_units2 = configurations['lstm_units']\n",
    "    ks1, ks2, ks3 = configurations['kernel_size']\n",
    "\n",
    "    # l2_norm_clip = p['l2_norm_clip']\n",
    "    # dp_learning_rate = p['dp_learning_rate']\n",
    "    # batch_size = p['batch_size']\n",
    "    # num_microbatches = p['num_microbatches']\n",
    "    # noise_multiplier = p['noise_multiplier']\n",
    "    # dp_optimizer = p['dp_optimizer']\n",
    "    # from_logits = p['from_logits']\n",
    "\n",
    "    # if batch_size % num_microbatches != 0:\n",
    "    #     raise ValueError('Batch size should be an integer multiple of the number of microbatches')\n",
    "\n",
    "    K.clear_session() \n",
    "    #__________________________Inputs\n",
    "    inp = Input(shape = (seq_len, n_features))\n",
    "    #__________________________layers\n",
    "    conv1 = Conv1D(filters = filters1 , kernel_size = 20, dilation_rate = 2, activation = 'relu')(inp)\n",
    "    conv2 = Conv1D(filters = filters2 , kernel_size = 20, dilation_rate = 2, activation = 'relu')(conv1)\n",
    "    conv3 = Conv1D(filters = filters3 , kernel_size = 10, dilation_rate = 2, activation = 'relu')(conv2)\n",
    "    lstm1 = LSTM(lstm_units1, return_sequences = True, activation = 'tanh')(conv3)\n",
    "    lstm2 = LSTM(lstm_units2, return_sequences = False, activation = 'tanh')(lstm1) \n",
    "    lstm_d = Dropout(0.1)(lstm2)\n",
    "    dense1 = Dense(10)(lstm_d)\n",
    "    dense2 = Dense(n_classes)(dense1)\n",
    "    dense2 = Activation('softmax')(dense2)\n",
    "    model_A = models.Model(inputs = inp, outputs = dense2)\n",
    "\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n",
    "    model_A.compile(optimizer= optimizer, loss = loss, metrics = [\"accuracy\"])\n",
    "    \n",
    "    # remove the last layer and compile with a different loss function\n",
    "    model_B = models.Model(inputs = model_A.inputs, outputs = model_A.layers[-2].output)\n",
    "    model_B.compile(optimizer = optimizer, loss = \"mean_absolute_error\")\n",
    "\n",
    "    return model_A, model_B\n",
    "\n",
    "# def split_dataset(x, y, samples_per_class, n_models, to_categorical = False) : \n",
    "#   datasets = [None]*n_models \n",
    "#   labels = [None]*n_models \n",
    "   \n",
    "#   sample_indecies = [None]*n_models \n",
    "#   n_classes = len(np.unique(y))\n",
    "#   combined_idx = np.array([], dtype = np.int16) \n",
    "#   n_samples_per_model = len(np.unique(y)) * samples_per_class \n",
    "\n",
    "#   for label in np.unique(y) : \n",
    "#     idx = np.where(y == label)[0]\n",
    "#     idx = np.random.choice(idx, samples_per_class*n_models, replace = True) \n",
    "#     combined_idx = np.r_[combined_idx, idx]\n",
    "#     for i in range(n_models) :\n",
    "#       if datasets[i] is None :\n",
    "#         datasets[i] = [x[idx[i*samples_per_class : (i+1)*samples_per_class]]]\n",
    "#         labels[i] = [y[idx[i*samples_per_class : (i+1)*samples_per_class]]]\n",
    "#       else : \n",
    "#         datasets[i].append( x[idx[i*samples_per_class : (i+1)*samples_per_class]])\n",
    "#         labels[i].append(y[idx[i*samples_per_class : (i+1)*samples_per_class]])\n",
    "  \n",
    "#   for i in range(n_models) : \n",
    "#     datasets[i] = np.concatenate(datasets[i])\n",
    "#     labels[i] = np.concatenate(labels[i])\n",
    "  \n",
    "\n",
    "#   total_datasets = x[combined_idx]\n",
    "#   total_labels = y[combined_idx]\n",
    "\n",
    "    \n",
    "#   if to_categorical : \n",
    "#     for i, l in enumerate(labels): \n",
    "#         labels[i] = tf.keras.utils.to_categorical(l, num_classes = n_classes)\n",
    "#     total_labels = tf.keras.utils.to_categorical(total_labels, num_classes = n_classes)\n",
    "  \n",
    "#   return datasets, labels, total_datasets, total_labels \n",
    "\n",
    "\n",
    "\n",
    "def split_dataset(x, y, samples_per_class, n_models, include_classes, to_categorical = False) : \n",
    "    datasets = [None]*n_models \n",
    "    labels = [None]*n_models \n",
    "\n",
    "    sample_indecies = [None]*n_models \n",
    "    n_classes = len(original_labels)\n",
    "    combined_idx = np.array([], dtype = np.int16) \n",
    "     \n",
    "    all_classes = list(np.arange(n_classes))\n",
    "\n",
    "    for label in all_classes :\n",
    "        idx = np.where(y == label)[0]\n",
    "        idx = np.random.choice(idx, samples_per_class*n_models, replace = True) \n",
    "        combined_idx = np.r_[combined_idx, idx]\n",
    "        for i in range(n_models) :\n",
    "            if include_classes != 'all' : \n",
    "                if label not in include_classes[i] :\n",
    "                    continue\n",
    "            if datasets[i] is None :\n",
    "                datasets[i] = [x[idx[i*samples_per_class : (i+1)*samples_per_class]]]\n",
    "                labels[i] = [y[idx[i*samples_per_class : (i+1)*samples_per_class]]]\n",
    "            else : \n",
    "                datasets[i].append( x[idx[i*samples_per_class : (i+1)*samples_per_class]])\n",
    "                labels[i].append(y[idx[i*samples_per_class : (i+1)*samples_per_class]])\n",
    "  \n",
    "    for i in range(n_models) : \n",
    "        datasets[i] = np.concatenate(datasets[i])\n",
    "        labels[i] = np.concatenate(labels[i])\n",
    "    \n",
    "\n",
    "    total_datasets = x[combined_idx]\n",
    "    total_labels = y[combined_idx]\n",
    "\n",
    "    \n",
    "    if to_categorical : \n",
    "        for i, l in enumerate(labels): \n",
    "            labels[i] = tf.keras.utils.to_categorical(l, num_classes = n_classes)       \n",
    "        total_labels = tf.keras.utils.to_categorical(total_labels, num_classes = n_classes)\n",
    "    \n",
    "    return datasets, labels, total_datasets, total_labels \n",
    "\n",
    "\n",
    "\n",
    "def get_optimizer(hp) : \n",
    "    optimizer_name = hp['optimizer'].lower()\n",
    "    if optimizer_name == 'adam' :\n",
    "        return tf.keras.optimizers.Adam(learning_rate=hp['learning_rate'])\n",
    "    elif optimizer_name == 'sgd' :\n",
    "        return tf.keras.optimizers.SGD(learning_rate=hp['learning_rate'])\n",
    "    elif optimizer_name == 'rmsprop' :\n",
    "        return tf.keras.optimizers.RMSprop(learning_rate=hp['learning_rate'])\n",
    "    else : \n",
    "        raise Exception('Optimizer not supported')\n",
    "\n",
    "\n",
    "def get_model(n_classes, input_shape, model_configurations) : \n",
    "    ub, ua, dropout_rate = model_configurations\n",
    "    act1, act2 = np.random.choice([\"relu\", \"elu\", \"selu\", \"tanh\"], 2)\n",
    "    lr = np.random.choice([1e-3, 1e-4, 1e-5])\n",
    "    opt = np.random.choice([\"adam\", \"sgd\", \"rmsprop\"])\n",
    "    optimizer = get_optimizer({\"optimizer\" : opt, \"learning_rate\" : lr})\n",
    "    \n",
    "    inp = tf.keras.layers.Input(input_shape) \n",
    "    y = Dense(units = ua, activation = act1)(inp) \n",
    "    y = Dropout(dropout_rate)(y)\n",
    "    y = Dense(units = ub, activation = act2)(y) \n",
    "    y = Dense(units = n_classes)(y)\n",
    "    y = tf.keras.layers.Activation('softmax')(y) \n",
    "\n",
    "    model_A = tf.keras.models.Model(inputs = inp, outputs = y)\n",
    "\n",
    "    model_A.compile(optimizer=optimizer,  \n",
    "                        loss = \"categorical_crossentropy\",\n",
    "                        metrics = [\"accuracy\"])\n",
    "    model_B = remove_last_layer(model_A) \n",
    "    configurations = {\n",
    "        \"act1\" : act1,\n",
    "        \"act2\" : act2,\n",
    "        \"ua\" : ua,\n",
    "        \"ub\" : ub,\n",
    "        \"dropout_rate\" : dropout_rate,\n",
    "        \"lr\" : lr,\n",
    "        \"opt\" : opt\n",
    "        \n",
    "    }\n",
    "    return model_A, model_B, configurations \n",
    "\n",
    "\n",
    "def remove_last_layer(model, loss = \"mean_absolute_error\"):\n",
    "    \"\"\"\n",
    "    Input: Keras model, a classification model whose last layer is a softmax activation\n",
    "    Output: Keras model, the same model with the last softmax activation layer removed,\n",
    "        while keeping the same parameters \n",
    "    \"\"\"\n",
    "    \n",
    "    new_model = tf.keras.models.Model(inputs = model.inputs, outputs = model.layers[-2].output)\n",
    "    new_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate = 1e-3), \n",
    "                      loss = loss)\n",
    "    \n",
    "    return new_model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_label(filename) : \n",
    "    filename = filename.split(\".\")[0]\n",
    "    if filename.startswith('study') :\n",
    "        return 0\n",
    "    elif filename.startswith('walk') : \n",
    "        return 1\n",
    "    elif filename.startswith('sleep') : \n",
    "        return 2\n",
    "    elif filename.startswith('idle') : \n",
    "        return 3\n",
    "    else :\n",
    "        return -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def number_of_parameters(model) : \n",
    "    return model.count_params()\n",
    "\n",
    "\n",
    "\n",
    "def get_tunable_models(hp) : \n",
    "    K.clear_session()\n",
    "    n_conv_layers = hp['n_conv_layers'] \n",
    "    n_lstm_layers = hp['n_lstm_layers']\n",
    "    activation_function = hp['activation_function']\n",
    "    dropout_rate = hp['dropout_rate']\n",
    "    conv_filter = hp['conv_filter']\n",
    "    conv_kernel_size = hp['conv_kernel_size']\n",
    "    lstm_units = hp['lstm_units']\n",
    "    optimizer = get_optimizer(hp)\n",
    "    learning_rate = hp['learning_rate']\n",
    "    input_shape = hp['input_shape']\n",
    "\n",
    "    x = Input(shape = input_shape) \n",
    "    y = Reshape(input_shape)(x) \n",
    "    for i in range(n_conv_layers) : \n",
    "        y = Conv1D(conv_filter, conv_kernel_size, activation = activation_function)(y)\n",
    "        y = MaxPooling1D(2)(y)\n",
    "    y = Dropout(dropout_rate)(y)\n",
    "    for i in range(n_lstm_layers) :\n",
    "        y = LSTM(lstm_units, return_sequences = True)(y)\n",
    "    lstm_layer = LSTM(lstm_units, return_sequences = False)(y)\n",
    "    lstm_dropout_layer = Dropout(dropout_rate)(lstm_layer)\n",
    "    \n",
    "    dense = Dense(hp['n_classes'])(lstm_dropout_layer)\n",
    "    output = Activation('softmax')(dense)\n",
    "    model1 = tf.keras.models.Model(inputs = x, outputs = output)\n",
    "    model1.compile(optimizer = optimizer, loss= 'categorical_crossentropy', metrics=['accuracy'])\n",
    "    model2 = tf.keras.models.Model(inputs = x, outputs = dense)\n",
    "    model2.compile(optimizer = optimizer, loss= 'mean_absolute_error')\n",
    "\n",
    "    return model1, model2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Node : \n",
    "\n",
    "    model = None \n",
    "    carrier_dataset_metadata = None\n",
    "    carrier_datset = None\n",
    "\n",
    "    local_target_dataset = None \n",
    "    target_validation_set = None \n",
    "\n",
    "    target_validation_acc = []\n",
    "    target_validation_loss = [] \n",
    "\n",
    "\n",
    "    def __init__(self, model, local_target_dataset, shared_public_dataset, target_validation_gen) : \n",
    "        self.model = model \n",
    "        self.local_target_dataset = local_target_dataset\n",
    "        self.shared_public_dataset = shared_public_dataset\n",
    "        self.target_validation_gen = target_validation_gen\n",
    "\n",
    "\n",
    "    def get_training_metadata(self, seed, alpha) : \n",
    "\n",
    "        self.seed = seed \n",
    "        self.alpha = alpha\n",
    "        carrier_preds = self.get_carrier_scores() \n",
    "        target_performance = self.evaluate_on_validation_set(save = False)[1]\n",
    "        data_shape = carrier_preds.shape\n",
    "\n",
    "        # carrier_preds = from_categorical(carrier_preds) \n",
    "\n",
    "        # print(\"carrier_preds:{}  new_labels:{}\".format(carrier_preds.shape, new_labels.shape))\n",
    "        return carrier_preds, target_performance\n",
    "\n",
    "\n",
    "    def get_carrier_scores(self) : \n",
    "        return self.model[1].predict(self.shared_public_dataset[0], batch_size = 32)\n",
    "\n",
    "\n",
    "    def receive_training_metadata(self, metadata) : \n",
    "\n",
    "        self.update_public_dataset_labels(metadata) \n",
    "\n",
    "\n",
    "    def update_public_dataset_labels(self, metadata) : \n",
    "        new_shared_public_dataset = (self.shared_public_dataset[0], metadata )\n",
    "        \n",
    "        self.shared_public_dataset = new_shared_public_dataset\n",
    "\n",
    "\n",
    "    def evaluate_on_validation_set(self, save = True) : \n",
    "        eval_x, eval_y = self.target_validation_gen\n",
    "        loss, acc = self.model[0].evaluate(eval_x, eval_y, batch_size = 32, verbose = False)\n",
    "        if save : \n",
    "            self.target_validation_loss.append(loss)\n",
    "            self.target_validation_acc.append(acc)\n",
    "        return loss, acc\n",
    "\n",
    "    def train_on_target(self, epochs = 1, use_callbacks = False, verbose = True, logger_file = None, evaluate = False) :\n",
    "        if use_callbacks : cbs = [EarlyStopping(monitor = 'val_loss', patience = 7, restore_best_weights= True)]\n",
    "        else : cbs = []\n",
    "        if logger_file : \n",
    "            cbs.append([CSVLogger(filename = logger_file, append = True)])\n",
    "        \n",
    "        if evaluate : \n",
    "            history = self.model[0].fit(self.local_target_dataset[0], self.local_target_dataset[1], \\\n",
    "                validation_data = self.target_validation_gen, epochs = epochs, callbacks = cbs, verbose = verbose)\n",
    "        else : \n",
    "\n",
    "            history = self.model[0].fit(self.local_target_dataset[0], self.local_target_dataset[1], epochs = epochs, \n",
    "                                        callbacks = cbs, verbose = verbose)\n",
    "\n",
    "\n",
    "\n",
    "    def train_on_public(self, epochs = 1, use_callbacks = False, verbose = True, logger_file = None) : \n",
    "\n",
    "        if use_callbacks : cbs = [EarlyStopping(monitor = 'val_loss', patience = 7, restore_best_weights= True)]\n",
    "        else : cbs = []\n",
    "        if logger_file : \n",
    "            cbs.append([CSVLogger(filename = logger_file, append = True)])\n",
    "        history = self.model[1].fit(self.shared_public_dataset[0], self.shared_public_dataset[1],\n",
    "         epochs = epochs, callbacks = cbs, verbose = verbose)\n",
    "\n",
    "\n",
    "\n",
    "    def save_model(self, model_path) : \n",
    "        self.model[0].save(model_path + '_classifier.h5') \n",
    "        self.model[1].save(model_path + '_regressor.h5') \n",
    "\n",
    "\n",
    "def aggregate_training_metadatas(carrier_labels, target_performance, weighted_averaging = False) : \n",
    "    \n",
    "    \n",
    "    if weighted_averaging : \n",
    "        aggregate_training_metadata = np.average(carrier_labels, weights = target_performance, axis = 0)\n",
    "    else : \n",
    "        aggregate_training_metadata = np.average(carrier_labels, axis = 0) \n",
    "\n",
    "    return aggregate_training_metadata\n",
    "\n",
    "\n",
    "def collect_metadatas(nodes, seed, alpha) : \n",
    "    # Collect training metadata\n",
    "    pub_scores, target_performances = [], []\n",
    "    for i, node in enumerate(nodes) : \n",
    "        training_metadata, target_performance = node.get_training_metadata(seed, alpha) \n",
    "        pub_scores.append(training_metadata)\n",
    "        target_performances.append(target_performance) \n",
    "    return pub_scores, target_performances \n",
    "\n",
    "\n",
    "class FedAMDNode : \n",
    "\n",
    "    model = None \n",
    "    carrier_dataset_metadata = None\n",
    "    carrier_datset = None\n",
    "\n",
    "    local_target_dataset = None \n",
    "    target_validation_set = None \n",
    "\n",
    "    target_validation_acc = []\n",
    "    target_validation_loss = [] \n",
    "\n",
    "\n",
    "    def __init__(self, model, local_target_dataset, shared_public_dataset, target_validation_gen) : \n",
    "        self.model = model \n",
    "        self.local_target_dataset = local_target_dataset\n",
    "        self.shared_public_dataset = shared_public_dataset\n",
    "        self.target_validation_gen = target_validation_gen\n",
    "\n",
    "\n",
    "    def get_training_metadata(self, seed, alpha) : \n",
    "\n",
    "        self.seed = seed \n",
    "        self.alpha = alpha\n",
    "        carrier_preds = self.get_carrier_scores() \n",
    "        target_performance = self.evaluate_on_validation_set(save = False)[1]\n",
    "        data_shape = carrier_preds.shape\n",
    "\n",
    "        # carrier_preds = from_categorical(carrier_preds) \n",
    "\n",
    "        # print(\"carrier_preds:{}  new_labels:{}\".format(carrier_preds.shape, new_labels.shape))\n",
    "        return carrier_preds, target_performance\n",
    "\n",
    "\n",
    "    def get_carrier_scores(self) : \n",
    "        \n",
    "        x = self.shared_public_dataset[0]\n",
    "        np.random.seed(self.seed) \n",
    "        index = np.random.permutation(len(x))  \n",
    "        mixed_x = self.alpha * x + (1 - self.alpha) * x[index, ...]\n",
    "    \n",
    "        return self.model[1].predict(mixed_x, batch_size = 32)\n",
    "\n",
    "\n",
    "    def receive_training_metadata(self, metadata) : \n",
    "\n",
    "        self.update_public_dataset_labels(metadata) \n",
    "\n",
    "\n",
    "    def update_public_dataset_labels(self, metadata) : \n",
    "        new_shared_public_dataset = (self.shared_public_dataset[0], metadata )\n",
    "        \n",
    "        self.shared_public_dataset = new_shared_public_dataset\n",
    "\n",
    "\n",
    "    def evaluate_on_validation_set(self, save = True) : \n",
    "        eval_x, eval_y = self.target_validation_gen\n",
    "        loss, acc = self.model[0].evaluate(eval_x, eval_y, batch_size = 32, verbose = False)\n",
    "        if save : \n",
    "            self.target_validation_loss.append(loss)\n",
    "            self.target_validation_acc.append(acc)\n",
    "        return loss, acc\n",
    "\n",
    "    def train_on_target(self, epochs = 1, use_callbacks = False, verbose = True, logger_file = None, evaluate = False) :\n",
    "        if use_callbacks : cbs = [EarlyStopping(monitor = 'val_loss', patience = 7, restore_best_weights= True)]\n",
    "        else : cbs = []\n",
    "        if logger_file : \n",
    "            cbs.append([CSVLogger(filename = logger_file, append = True)])\n",
    "        if evaluate : \n",
    "            history = self.model[0].fit(self.local_target_dataset[0], self.local_target_dataset[1], \\\n",
    "                validation_data = self.target_validation_gen, epochs = epochs, callbacks = cbs, verbose = verbose)\n",
    "        else : \n",
    "\n",
    "            history = self.model[0].fit(self.local_target_dataset[0], self.local_target_dataset[1], epochs = epochs, \n",
    "                                        callbacks = cbs, verbose = verbose)\n",
    "\n",
    "\n",
    "    def train_on_public(self, epochs = 1, use_callbacks = False, verbose = True, logger_file = None) : \n",
    "\n",
    "        if use_callbacks : cbs = [EarlyStopping(monitor = 'val_loss', patience = 7, restore_best_weights= True)]\n",
    "        else : cbs = []\n",
    "        if logger_file : \n",
    "            cbs.append([CSVLogger(filename = logger_file, append = True)])\n",
    "    \n",
    "        x = self.shared_public_dataset[0]\n",
    "        np.random.seed(self.seed) \n",
    "        index = np.random.permutation(len(x))  \n",
    "        mixed_x = self.alpha * x + (1 - self.alpha) * x[index, ...]\n",
    "\n",
    "        history = self.model[1].fit(mixed_x, self.shared_public_dataset[1],\n",
    "         epochs = epochs, callbacks = cbs, verbose = verbose)\n",
    "\n",
    "\n",
    "\n",
    "    def save_model(self, model_path) : \n",
    "        self.model[0].save(model_path + '_classifier.h5') \n",
    "        self.model[1].save(model_path + '_regressor.h5') \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data and models setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = 'results'\n",
    "\n",
    "experiment_dir = os.path.join(results_dir, 'exp_smartHAR_FedWAKD')\n",
    "subdirs = ['local_train_iid', 'local_train_noniid', 'central_train_iid', 'central_train_noniid', 'iid', 'noniid']\n",
    "# subdirs = ['local_train_iid', 'local_train_noniid', 'central_train_iid', 'central_train_noniid', 'fedAMD_iid', 'fedAMD_noniid']\n",
    "if not os.path.exists(experiment_dir):\n",
    "    os.makedirs(experiment_dir)\n",
    "    for subdir in subdirs : \n",
    "        os.makedirs(os.path.join(experiment_dir, subdir))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "n_parties = 10\n",
    "n_samples_per_class = 20\n",
    "input_shape = (561,)\n",
    "n_alignment =  100\n",
    "n_iterations = 50 \n",
    "\n",
    "models_params = [\n",
    "    (5, 8, 0.1), # n1, n2, dropout_rate \n",
    "    (5, 10, 0.25), # n1, n2, dropout_rate \n",
    "    (7, 30, 0.15), # n1, n2, dropout_rate \n",
    "    (20, 70, 0.2), # n1, n2, dropout_rate \n",
    "\n",
    "\n",
    "\n",
    "    (90, 120, 0.1), \n",
    "    (99, 170, 0.15), \n",
    "    (93, 200, 0.25),\n",
    "\n",
    "    (200, 270, 0.1),\n",
    "    (240, 300, 0.15),\n",
    "    (290, 340, 0.25)\n",
    "]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../smartphone_HAR/train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/gadmohamed/Library/CloudStorage/GoogleDrive-ggad@lakeheadu.ca/My Drive/dead repos/FedAKD/explore_FL_results.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gadmohamed/Library/CloudStorage/GoogleDrive-ggad%40lakeheadu.ca/My%20Drive/dead%20repos/FedAKD/explore_FL_results.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m dataset_dir \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m../smartphone_HAR\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/gadmohamed/Library/CloudStorage/GoogleDrive-ggad%40lakeheadu.ca/My%20Drive/dead%20repos/FedAKD/explore_FL_results.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m train_data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(dataset_dir,\u001b[39m'\u001b[39;49m\u001b[39mtrain.csv\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gadmohamed/Library/CloudStorage/GoogleDrive-ggad%40lakeheadu.ca/My%20Drive/dead%20repos/FedAKD/explore_FL_results.ipynb#X14sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m test_data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(dataset_dir,\u001b[39m'\u001b[39m\u001b[39mtest.csv\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gadmohamed/Library/CloudStorage/GoogleDrive-ggad%40lakeheadu.ca/My%20Drive/dead%20repos/FedAKD/explore_FL_results.ipynb#X14sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m train_data \u001b[39m=\u001b[39m train_data\u001b[39m.\u001b[39msample(frac \u001b[39m=\u001b[39m \u001b[39m1.0\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/fl/lib/python3.9/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/fl/lib/python3.9/site-packages/pandas/util/_decorators.py:317\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    312\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    313\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[1;32m    314\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    315\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(inspect\u001b[39m.\u001b[39mcurrentframe()),\n\u001b[1;32m    316\u001b[0m     )\n\u001b[0;32m--> 317\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/fl/lib/python3.9/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/miniforge3/envs/fl/lib/python3.9/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    607\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/miniforge3/envs/fl/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/miniforge3/envs/fl/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1729\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1727\u001b[0m     is_text \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1728\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1729\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1730\u001b[0m     f,\n\u001b[1;32m   1731\u001b[0m     mode,\n\u001b[1;32m   1732\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1733\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1734\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1735\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1736\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1737\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1738\u001b[0m )\n\u001b[1;32m   1739\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1740\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/miniforge3/envs/fl/lib/python3.9/site-packages/pandas/io/common.py:857\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    852\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    853\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    855\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    856\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    858\u001b[0m             handle,\n\u001b[1;32m    859\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    860\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    861\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    862\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    863\u001b[0m         )\n\u001b[1;32m    864\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    865\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    866\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../smartphone_HAR/train.csv'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "dataset_dir = '../smartphone_HAR'\n",
    "train_data = pd.read_csv(os.path.join(dataset_dir,'train.csv'))\n",
    "test_data = pd.read_csv(os.path.join(dataset_dir,'test.csv'))\n",
    "\n",
    "train_data = train_data.sample(frac = 1.0)\n",
    "\n",
    "train_data_len = int(0.9 * len(train_data) ) \n",
    "train_data, public_data = train_data.iloc[:train_data_len], train_data.iloc[train_data_len:]\n",
    "\n",
    "# Eliminate last two columns from the x data ('subject', 'label') \n",
    "x_train, y_train = train_data.iloc[:, :-2], train_data.iloc[:, -1:] \n",
    "x_test, y_test = test_data.iloc[:, :-2], test_data.iloc[:, -1:]\n",
    "\n",
    "pub_x, pub_y = public_data.iloc[:, :-2], public_data.iloc[:, -1:]\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)\n",
    "pub_y = le.transform(pub_y) \n",
    "\n",
    "scaling_data = MinMaxScaler()\n",
    "x_train = scaling_data.fit_transform(x_train)\n",
    "x_test = scaling_data.transform(x_test)\n",
    "pub_x = scaling_data.transform(pub_x) \n",
    "\n",
    "n_classes = len(le.classes_)\n",
    "original_labels = le.classes_\n",
    "pri_x_list, pri_y_list, pri_x_total, pri_y_total  = split_dataset(x_train, y_train, include_classes = 'all', samples_per_class = n_samples_per_class ,\\\n",
    "                                                                n_models = n_parties, to_categorical = True) \n",
    "y_train_cat = to_categorical(y_train, num_classes = n_classes)\n",
    "y_test_cat = to_categorical(y_test, num_classes = n_classes)\n",
    "pub_y_cat = to_categorical(pub_y, num_classes = n_classes)\n",
    "\n",
    "print(f'Shape of x train data is: {x_train.shape}. Shape of  y train data is: {y_train.shape}')\n",
    "print(f'Shape of x test data is: {x_test.shape}. Shape of y test data is: {y_test.shape}')\n",
    "print(f\"Shape of x public data is: {pub_x.shape}. Shape of y public data is: {pub_y.shape}\")\n",
    "print(f\"Single local x train is: {pri_x_list[0].shape}. Shape of single y train is: {pri_y_list[0].shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federated learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## i.i.d. clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_batches shape :  (6616, 561)\n",
      "train_labels shape :  (6616,)\n",
      "pub_data_batches shape :  (736, 561)\n",
      "pub_data_labels shape :  (736,)\n",
      "test_batches shape :  (2947, 561)\n",
      "cat_test_labels shape :  (2947, 6)\n",
      "pri_x_list shape :  (120, 561)\n",
      "pri_y_list shape :  (120, 6)\n",
      "pri_x_total shape :  (1200, 561)\n",
      "pri_y_total shape :  (1200, 6)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "iid_models = [get_model(n_classes, input_shape, model_params ) for model_params in models_params] \n",
    "\n",
    "# print data shapes\n",
    "print('train_batches shape : ', x_train.shape)\n",
    "print('train_labels shape : ', y_train.shape)\n",
    "print('pub_data_batches shape : ', pub_x.shape)\n",
    "print('pub_data_labels shape : ', pub_y.shape)\n",
    "print('test_batches shape : ', x_test.shape)\n",
    "print('cat_test_labels shape : ', y_test_cat.shape)\n",
    "\n",
    "print('pri_x_list shape : ', pri_x_list[0].shape)\n",
    "print('pri_y_list shape : ', pri_y_list[0].shape)\n",
    "print('pri_x_total shape : ', pri_x_total.shape)\n",
    "print('pri_y_total shape : ', pri_y_total.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 2s 224ms/step - loss: 1.9224 - accuracy: 0.1667 - val_loss: 1.8808 - val_accuracy: 0.1724\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 1.8999 - accuracy: 0.1667 - val_loss: 1.8807 - val_accuracy: 0.1724\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 1.9111 - accuracy: 0.1750 - val_loss: 1.8806 - val_accuracy: 0.1724\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 1.9200 - accuracy: 0.1833 - val_loss: 1.8805 - val_accuracy: 0.1724\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 1.9103 - accuracy: 0.1917 - val_loss: 1.8804 - val_accuracy: 0.1724\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 1.9225 - accuracy: 0.1833 - val_loss: 1.8803 - val_accuracy: 0.1724\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.9264 - accuracy: 0.1833 - val_loss: 1.8802 - val_accuracy: 0.1724\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 1.9028 - accuracy: 0.1750 - val_loss: 1.8801 - val_accuracy: 0.1724\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 1.9238 - accuracy: 0.1833 - val_loss: 1.8800 - val_accuracy: 0.1724\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 1.9063 - accuracy: 0.1833 - val_loss: 1.8799 - val_accuracy: 0.1724\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 1.9010 - accuracy: 0.1833 - val_loss: 1.8798 - val_accuracy: 0.1724\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 1.9082 - accuracy: 0.1833 - val_loss: 1.8797 - val_accuracy: 0.1731\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.9159 - accuracy: 0.1833 - val_loss: 1.8796 - val_accuracy: 0.1727\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 1.9093 - accuracy: 0.1917 - val_loss: 1.8795 - val_accuracy: 0.1727\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 1.9104 - accuracy: 0.1750 - val_loss: 1.8794 - val_accuracy: 0.1727\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.8984 - accuracy: 0.1750 - val_loss: 1.8793 - val_accuracy: 0.1727\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.9074 - accuracy: 0.1833 - val_loss: 1.8792 - val_accuracy: 0.1727\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 1.9260 - accuracy: 0.1750 - val_loss: 1.8791 - val_accuracy: 0.1727\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 1.9217 - accuracy: 0.1750 - val_loss: 1.8790 - val_accuracy: 0.1727\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 1.9123 - accuracy: 0.1667 - val_loss: 1.8789 - val_accuracy: 0.1724\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 1s 132ms/step - loss: 1.9118 - accuracy: 0.2083 - val_loss: 1.8734 - val_accuracy: 0.2548\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 1.8656 - accuracy: 0.2583 - val_loss: 1.8530 - val_accuracy: 0.2844\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 1.8601 - accuracy: 0.2417 - val_loss: 1.8380 - val_accuracy: 0.2962\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.7948 - accuracy: 0.3000 - val_loss: 1.8241 - val_accuracy: 0.3054\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.8284 - accuracy: 0.2750 - val_loss: 1.8109 - val_accuracy: 0.3081\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.7777 - accuracy: 0.3583 - val_loss: 1.7984 - val_accuracy: 0.3105\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 1.7536 - accuracy: 0.3750 - val_loss: 1.7874 - val_accuracy: 0.3163\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.7713 - accuracy: 0.3333 - val_loss: 1.7772 - val_accuracy: 0.3207\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 1.7810 - accuracy: 0.3000 - val_loss: 1.7680 - val_accuracy: 0.3156\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 1.7315 - accuracy: 0.3417 - val_loss: 1.7591 - val_accuracy: 0.3115\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.7150 - accuracy: 0.4000 - val_loss: 1.7512 - val_accuracy: 0.3234\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.7275 - accuracy: 0.3750 - val_loss: 1.7428 - val_accuracy: 0.3312\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 1.7123 - accuracy: 0.3167 - val_loss: 1.7335 - val_accuracy: 0.3363\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.6907 - accuracy: 0.3917 - val_loss: 1.7253 - val_accuracy: 0.3417\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 1.6742 - accuracy: 0.3083 - val_loss: 1.7177 - val_accuracy: 0.3444\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 1.6810 - accuracy: 0.3417 - val_loss: 1.7110 - val_accuracy: 0.3478\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 1.6940 - accuracy: 0.3250 - val_loss: 1.7045 - val_accuracy: 0.3488\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.6453 - accuracy: 0.3667 - val_loss: 1.6957 - val_accuracy: 0.3502\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.6635 - accuracy: 0.3750 - val_loss: 1.6864 - val_accuracy: 0.3580\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.6695 - accuracy: 0.3167 - val_loss: 1.6790 - val_accuracy: 0.3699\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 1s 91ms/step - loss: 1.8615 - accuracy: 0.1500 - val_loss: 1.8360 - val_accuracy: 0.2189\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 1.8407 - accuracy: 0.1583 - val_loss: 1.8348 - val_accuracy: 0.2185\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.8241 - accuracy: 0.1750 - val_loss: 1.8334 - val_accuracy: 0.2185\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 1.8350 - accuracy: 0.1333 - val_loss: 1.8322 - val_accuracy: 0.2189\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 1.8323 - accuracy: 0.1833 - val_loss: 1.8309 - val_accuracy: 0.2189\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 1.8508 - accuracy: 0.1083 - val_loss: 1.8295 - val_accuracy: 0.2192\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 1.8202 - accuracy: 0.1750 - val_loss: 1.8283 - val_accuracy: 0.2185\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 1.8422 - accuracy: 0.1500 - val_loss: 1.8270 - val_accuracy: 0.2189\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.8362 - accuracy: 0.1333 - val_loss: 1.8258 - val_accuracy: 0.2189\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 1.8457 - accuracy: 0.1250 - val_loss: 1.8245 - val_accuracy: 0.2192\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.8282 - accuracy: 0.1167 - val_loss: 1.8232 - val_accuracy: 0.2189\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.8594 - accuracy: 0.1500 - val_loss: 1.8220 - val_accuracy: 0.2195\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.8584 - accuracy: 0.1917 - val_loss: 1.8208 - val_accuracy: 0.2199\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.8604 - accuracy: 0.1167 - val_loss: 1.8196 - val_accuracy: 0.2206\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 1.8419 - accuracy: 0.1583 - val_loss: 1.8185 - val_accuracy: 0.2209\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 1.7800 - accuracy: 0.2333 - val_loss: 1.8173 - val_accuracy: 0.2212\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.8379 - accuracy: 0.1667 - val_loss: 1.8161 - val_accuracy: 0.2226\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 1.8489 - accuracy: 0.1750 - val_loss: 1.8149 - val_accuracy: 0.2229\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.8388 - accuracy: 0.1417 - val_loss: 1.8138 - val_accuracy: 0.2233\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 1.8239 - accuracy: 0.1500 - val_loss: 1.8125 - val_accuracy: 0.2233\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 1s 79ms/step - loss: 2.0278 - accuracy: 0.1000 - val_loss: 1.9491 - val_accuracy: 0.0780\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 1.9758 - accuracy: 0.1083 - val_loss: 1.9276 - val_accuracy: 0.0848\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 2.0219 - accuracy: 0.0667 - val_loss: 1.9074 - val_accuracy: 0.0909\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 1.9908 - accuracy: 0.1000 - val_loss: 1.8877 - val_accuracy: 0.1042\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 1.9552 - accuracy: 0.1083 - val_loss: 1.8700 - val_accuracy: 0.1130\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 1.9619 - accuracy: 0.1250 - val_loss: 1.8529 - val_accuracy: 0.1201\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.8852 - accuracy: 0.1833 - val_loss: 1.8367 - val_accuracy: 0.1239\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 1.8586 - accuracy: 0.1667 - val_loss: 1.8221 - val_accuracy: 0.1303\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 1.8983 - accuracy: 0.1333 - val_loss: 1.8077 - val_accuracy: 0.1374\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 1.8708 - accuracy: 0.1417 - val_loss: 1.7936 - val_accuracy: 0.1418\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 1.8354 - accuracy: 0.1750 - val_loss: 1.7806 - val_accuracy: 0.1486\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 1.8262 - accuracy: 0.2167 - val_loss: 1.7684 - val_accuracy: 0.1527\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 1.8156 - accuracy: 0.1917 - val_loss: 1.7567 - val_accuracy: 0.1625\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 1.8235 - accuracy: 0.1583 - val_loss: 1.7449 - val_accuracy: 0.1731\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 1.7879 - accuracy: 0.1750 - val_loss: 1.7336 - val_accuracy: 0.1843\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 1.7743 - accuracy: 0.2000 - val_loss: 1.7227 - val_accuracy: 0.1958\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 1.8072 - accuracy: 0.1917 - val_loss: 1.7125 - val_accuracy: 0.2114\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 1.7576 - accuracy: 0.2583 - val_loss: 1.7024 - val_accuracy: 0.2331\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 1.7948 - accuracy: 0.2083 - val_loss: 1.6932 - val_accuracy: 0.2474\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.7378 - accuracy: 0.2167 - val_loss: 1.6845 - val_accuracy: 0.2606\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 1s 79ms/step - loss: 1.9050 - accuracy: 0.1083 - val_loss: 1.6949 - val_accuracy: 0.2297\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 1.6971 - accuracy: 0.2667 - val_loss: 1.6038 - val_accuracy: 0.3451\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 1.5898 - accuracy: 0.2917 - val_loss: 1.5356 - val_accuracy: 0.3692\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 1.5267 - accuracy: 0.4167 - val_loss: 1.4759 - val_accuracy: 0.3994\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 1.4722 - accuracy: 0.3750 - val_loss: 1.4243 - val_accuracy: 0.4472\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 1.4235 - accuracy: 0.4250 - val_loss: 1.3822 - val_accuracy: 0.4618\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 1.3747 - accuracy: 0.4750 - val_loss: 1.3422 - val_accuracy: 0.5521\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 1.3042 - accuracy: 0.5167 - val_loss: 1.3052 - val_accuracy: 0.5870\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 1.2761 - accuracy: 0.5083 - val_loss: 1.2721 - val_accuracy: 0.5959\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 1.2504 - accuracy: 0.5250 - val_loss: 1.2396 - val_accuracy: 0.6138\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 1.1848 - accuracy: 0.5833 - val_loss: 1.2094 - val_accuracy: 0.6298\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 1.2000 - accuracy: 0.5583 - val_loss: 1.1871 - val_accuracy: 0.6352\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 1.1432 - accuracy: 0.6000 - val_loss: 1.1606 - val_accuracy: 0.6729\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.1540 - accuracy: 0.6250 - val_loss: 1.1420 - val_accuracy: 0.6661\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 1.1018 - accuracy: 0.6583 - val_loss: 1.1202 - val_accuracy: 0.6854\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 1.0936 - accuracy: 0.6083 - val_loss: 1.0984 - val_accuracy: 0.7017\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 1.0726 - accuracy: 0.6167 - val_loss: 1.0817 - val_accuracy: 0.7051\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 1.0509 - accuracy: 0.6417 - val_loss: 1.0606 - val_accuracy: 0.7031\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.9921 - accuracy: 0.7000 - val_loss: 1.0442 - val_accuracy: 0.7017\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.9975 - accuracy: 0.6917 - val_loss: 1.0258 - val_accuracy: 0.7251\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 1s 81ms/step - loss: 1.7600 - accuracy: 0.1667 - val_loss: 1.5297 - val_accuracy: 0.3638\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 1.4087 - accuracy: 0.5250 - val_loss: 1.2853 - val_accuracy: 0.6176\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 1.2095 - accuracy: 0.5500 - val_loss: 1.1086 - val_accuracy: 0.7078\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 1.0537 - accuracy: 0.6000 - val_loss: 0.9844 - val_accuracy: 0.6804\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.9576 - accuracy: 0.6750 - val_loss: 0.9094 - val_accuracy: 0.7482\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.8644 - accuracy: 0.7417 - val_loss: 0.8269 - val_accuracy: 0.7825\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.7602 - accuracy: 0.7917 - val_loss: 0.7695 - val_accuracy: 0.7747\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.7509 - accuracy: 0.6667 - val_loss: 0.7259 - val_accuracy: 0.7336\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.6708 - accuracy: 0.7750 - val_loss: 0.6958 - val_accuracy: 0.7642\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.5753 - accuracy: 0.8083 - val_loss: 0.6244 - val_accuracy: 0.8090\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.5408 - accuracy: 0.8083 - val_loss: 0.5808 - val_accuracy: 0.8368\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.4895 - accuracy: 0.8667 - val_loss: 0.5777 - val_accuracy: 0.8001\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.4297 - accuracy: 0.8917 - val_loss: 0.5383 - val_accuracy: 0.8178\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.4557 - accuracy: 0.8333 - val_loss: 0.5119 - val_accuracy: 0.8405\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.3917 - accuracy: 0.8917 - val_loss: 0.5276 - val_accuracy: 0.7906\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.3731 - accuracy: 0.8833 - val_loss: 0.4732 - val_accuracy: 0.8398\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.3538 - accuracy: 0.9000 - val_loss: 0.4737 - val_accuracy: 0.8307\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.3239 - accuracy: 0.9167 - val_loss: 0.4556 - val_accuracy: 0.8442\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.3204 - accuracy: 0.8917 - val_loss: 0.4255 - val_accuracy: 0.8619\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.2526 - accuracy: 0.9500 - val_loss: 0.4311 - val_accuracy: 0.8395\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 1s 85ms/step - loss: 1.8319 - accuracy: 0.1917 - val_loss: 1.7937 - val_accuracy: 0.2128\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 1.8227 - accuracy: 0.2917 - val_loss: 1.7923 - val_accuracy: 0.2151\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 1.8032 - accuracy: 0.2333 - val_loss: 1.7910 - val_accuracy: 0.2158\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 1.8161 - accuracy: 0.2000 - val_loss: 1.7897 - val_accuracy: 0.2172\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 1.7991 - accuracy: 0.2500 - val_loss: 1.7884 - val_accuracy: 0.2185\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 1.8319 - accuracy: 0.2000 - val_loss: 1.7872 - val_accuracy: 0.2216\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 1.8383 - accuracy: 0.2000 - val_loss: 1.7859 - val_accuracy: 0.2233\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 1.8469 - accuracy: 0.1583 - val_loss: 1.7846 - val_accuracy: 0.2243\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 1.7853 - accuracy: 0.2500 - val_loss: 1.7834 - val_accuracy: 0.2253\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 1.8041 - accuracy: 0.2583 - val_loss: 1.7822 - val_accuracy: 0.2277\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 1.8156 - accuracy: 0.2417 - val_loss: 1.7809 - val_accuracy: 0.2304\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 1.8079 - accuracy: 0.2583 - val_loss: 1.7795 - val_accuracy: 0.2341\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 1.8379 - accuracy: 0.1750 - val_loss: 1.7782 - val_accuracy: 0.2362\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 1.8217 - accuracy: 0.2083 - val_loss: 1.7768 - val_accuracy: 0.2382\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 1.8388 - accuracy: 0.2333 - val_loss: 1.7756 - val_accuracy: 0.2402\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 1.8306 - accuracy: 0.1917 - val_loss: 1.7743 - val_accuracy: 0.2423\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 1.7845 - accuracy: 0.2667 - val_loss: 1.7730 - val_accuracy: 0.2443\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 1.8189 - accuracy: 0.2500 - val_loss: 1.7718 - val_accuracy: 0.2450\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 1.8171 - accuracy: 0.2250 - val_loss: 1.7706 - val_accuracy: 0.2491\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 1.8180 - accuracy: 0.2333 - val_loss: 1.7693 - val_accuracy: 0.2518\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 1s 82ms/step - loss: 1.7987 - accuracy: 0.1417 - val_loss: 1.7146 - val_accuracy: 0.1598\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 1.6667 - accuracy: 0.2167 - val_loss: 1.6133 - val_accuracy: 0.2806\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 1.5669 - accuracy: 0.3667 - val_loss: 1.5231 - val_accuracy: 0.4449\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 1.4902 - accuracy: 0.4167 - val_loss: 1.4435 - val_accuracy: 0.5209\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 1.3895 - accuracy: 0.5583 - val_loss: 1.3748 - val_accuracy: 0.5819\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 1.3214 - accuracy: 0.5667 - val_loss: 1.3133 - val_accuracy: 0.6210\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 1.2621 - accuracy: 0.6000 - val_loss: 1.2596 - val_accuracy: 0.6549\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 1.2267 - accuracy: 0.6167 - val_loss: 1.2109 - val_accuracy: 0.6943\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.1613 - accuracy: 0.7167 - val_loss: 1.1687 - val_accuracy: 0.7258\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.1136 - accuracy: 0.6833 - val_loss: 1.1296 - val_accuracy: 0.7900\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 1.0843 - accuracy: 0.7333 - val_loss: 1.0965 - val_accuracy: 0.7818\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 1.0490 - accuracy: 0.7750 - val_loss: 1.0656 - val_accuracy: 0.7998\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 1.0172 - accuracy: 0.7500 - val_loss: 1.0367 - val_accuracy: 0.8117\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.9781 - accuracy: 0.7833 - val_loss: 1.0108 - val_accuracy: 0.8174\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.9535 - accuracy: 0.8417 - val_loss: 0.9873 - val_accuracy: 0.7984\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.9159 - accuracy: 0.8000 - val_loss: 0.9644 - val_accuracy: 0.8083\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.8912 - accuracy: 0.8667 - val_loss: 0.9420 - val_accuracy: 0.8269\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 0.8667 - accuracy: 0.8000 - val_loss: 0.9225 - val_accuracy: 0.8249\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.8498 - accuracy: 0.8417 - val_loss: 0.9030 - val_accuracy: 0.8293\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 0.8179 - accuracy: 0.8417 - val_loss: 0.8847 - val_accuracy: 0.8297\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 2s 210ms/step - loss: 1.8962 - accuracy: 0.1667 - val_loss: 1.8534 - val_accuracy: 0.1469\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 98ms/step - loss: 1.8648 - accuracy: 0.1667 - val_loss: 1.8260 - val_accuracy: 0.1588\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 1.8399 - accuracy: 0.1417 - val_loss: 1.8034 - val_accuracy: 0.1707\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 1.8002 - accuracy: 0.2083 - val_loss: 1.7839 - val_accuracy: 0.1846\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 1.7902 - accuracy: 0.1917 - val_loss: 1.7661 - val_accuracy: 0.2029\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 1.7741 - accuracy: 0.2500 - val_loss: 1.7496 - val_accuracy: 0.2182\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 1.7473 - accuracy: 0.1833 - val_loss: 1.7337 - val_accuracy: 0.2385\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 1.7251 - accuracy: 0.2750 - val_loss: 1.7183 - val_accuracy: 0.2528\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 1.7250 - accuracy: 0.2417 - val_loss: 1.7031 - val_accuracy: 0.2721\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 1.7311 - accuracy: 0.2500 - val_loss: 1.6885 - val_accuracy: 0.2874\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 1.6533 - accuracy: 0.3500 - val_loss: 1.6743 - val_accuracy: 0.2989\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.6972 - accuracy: 0.1833 - val_loss: 1.6605 - val_accuracy: 0.3098\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.6773 - accuracy: 0.2500 - val_loss: 1.6466 - val_accuracy: 0.3220\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.6246 - accuracy: 0.2917 - val_loss: 1.6331 - val_accuracy: 0.3305\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.6375 - accuracy: 0.2667 - val_loss: 1.6200 - val_accuracy: 0.3370\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.6227 - accuracy: 0.3917 - val_loss: 1.6071 - val_accuracy: 0.3414\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 1.6015 - accuracy: 0.2750 - val_loss: 1.5944 - val_accuracy: 0.3468\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.5913 - accuracy: 0.2833 - val_loss: 1.5821 - val_accuracy: 0.3509\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.5906 - accuracy: 0.3250 - val_loss: 1.5701 - val_accuracy: 0.3570\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.5673 - accuracy: 0.3500 - val_loss: 1.5584 - val_accuracy: 0.3682\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 1s 87ms/step - loss: 1.7307 - accuracy: 0.2667 - val_loss: 1.5178 - val_accuracy: 0.4102\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 1.4744 - accuracy: 0.3583 - val_loss: 1.3721 - val_accuracy: 0.4910\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 1.3821 - accuracy: 0.4000 - val_loss: 1.2865 - val_accuracy: 0.5070\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 1.2639 - accuracy: 0.5083 - val_loss: 1.2175 - val_accuracy: 0.6366\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 1.1990 - accuracy: 0.4667 - val_loss: 1.1716 - val_accuracy: 0.5714\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 1.1601 - accuracy: 0.5583 - val_loss: 1.1134 - val_accuracy: 0.6722\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 1.0950 - accuracy: 0.5750 - val_loss: 1.1027 - val_accuracy: 0.5314\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 1.0318 - accuracy: 0.6167 - val_loss: 1.0303 - val_accuracy: 0.7238\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 1.0308 - accuracy: 0.5833 - val_loss: 0.9974 - val_accuracy: 0.7642\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.9699 - accuracy: 0.6333 - val_loss: 0.9692 - val_accuracy: 0.7343\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.9443 - accuracy: 0.6917 - val_loss: 0.9315 - val_accuracy: 0.7937\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.9091 - accuracy: 0.7167 - val_loss: 0.9084 - val_accuracy: 0.7560\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.8738 - accuracy: 0.7750 - val_loss: 0.8854 - val_accuracy: 0.7686\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.8721 - accuracy: 0.6917 - val_loss: 0.8634 - val_accuracy: 0.7825\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.8094 - accuracy: 0.7750 - val_loss: 0.8372 - val_accuracy: 0.8117\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7923 - accuracy: 0.7167 - val_loss: 0.8145 - val_accuracy: 0.7859\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.7521 - accuracy: 0.8333 - val_loss: 0.7951 - val_accuracy: 0.8229\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7203 - accuracy: 0.7833 - val_loss: 0.7841 - val_accuracy: 0.7950\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7148 - accuracy: 0.8000 - val_loss: 0.7515 - val_accuracy: 0.8242\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.6979 - accuracy: 0.8167 - val_loss: 0.7344 - val_accuracy: 0.8256\n",
      "Epoch 1/20\n",
      "38/38 [==============================] - 1s 7ms/step - loss: 1.8782 - accuracy: 0.1583 - val_loss: 1.8823 - val_accuracy: 0.1581\n",
      "Epoch 2/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.8548 - accuracy: 0.1608 - val_loss: 1.8594 - val_accuracy: 0.1524\n",
      "Epoch 3/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.8278 - accuracy: 0.1675 - val_loss: 1.8377 - val_accuracy: 0.1466\n",
      "Epoch 4/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.8075 - accuracy: 0.1567 - val_loss: 1.8176 - val_accuracy: 0.1415\n",
      "Epoch 5/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.7936 - accuracy: 0.1625 - val_loss: 1.7980 - val_accuracy: 0.1371\n",
      "Epoch 6/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.7635 - accuracy: 0.1658 - val_loss: 1.7797 - val_accuracy: 0.1344\n",
      "Epoch 7/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.7513 - accuracy: 0.1700 - val_loss: 1.7623 - val_accuracy: 0.1361\n",
      "Epoch 8/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.7316 - accuracy: 0.1658 - val_loss: 1.7453 - val_accuracy: 0.1344\n",
      "Epoch 9/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.7111 - accuracy: 0.1783 - val_loss: 1.7292 - val_accuracy: 0.1351\n",
      "Epoch 10/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.6953 - accuracy: 0.1925 - val_loss: 1.7131 - val_accuracy: 0.1449\n",
      "Epoch 11/20\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.6830 - accuracy: 0.1958 - val_loss: 1.6979 - val_accuracy: 0.1568\n",
      "Epoch 12/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.6627 - accuracy: 0.2342 - val_loss: 1.6826 - val_accuracy: 0.1775\n",
      "Epoch 13/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.6568 - accuracy: 0.2425 - val_loss: 1.6680 - val_accuracy: 0.2009\n",
      "Epoch 14/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.6391 - accuracy: 0.2508 - val_loss: 1.6534 - val_accuracy: 0.2223\n",
      "Epoch 15/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.6250 - accuracy: 0.2667 - val_loss: 1.6394 - val_accuracy: 0.2382\n",
      "Epoch 16/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.6090 - accuracy: 0.2808 - val_loss: 1.6258 - val_accuracy: 0.2474\n",
      "Epoch 17/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.5974 - accuracy: 0.2883 - val_loss: 1.6125 - val_accuracy: 0.2616\n",
      "Epoch 18/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.5861 - accuracy: 0.2933 - val_loss: 1.5998 - val_accuracy: 0.2708\n",
      "Epoch 19/20\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.5752 - accuracy: 0.2950 - val_loss: 1.5872 - val_accuracy: 0.2762\n",
      "Epoch 20/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.5593 - accuracy: 0.3067 - val_loss: 1.5752 - val_accuracy: 0.2810\n",
      "Epoch 1/20\n",
      "38/38 [==============================] - 1s 8ms/step - loss: 1.8844 - accuracy: 0.1608 - val_loss: 1.8477 - val_accuracy: 0.1815\n",
      "Epoch 2/20\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.8623 - accuracy: 0.1533 - val_loss: 1.8269 - val_accuracy: 0.1809\n",
      "Epoch 3/20\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.8366 - accuracy: 0.1592 - val_loss: 1.8094 - val_accuracy: 0.1798\n",
      "Epoch 4/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.8139 - accuracy: 0.1617 - val_loss: 1.7953 - val_accuracy: 0.1741\n",
      "Epoch 5/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.8023 - accuracy: 0.1525 - val_loss: 1.7833 - val_accuracy: 0.1656\n",
      "Epoch 6/20\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.7985 - accuracy: 0.1508 - val_loss: 1.7733 - val_accuracy: 0.1666\n",
      "Epoch 7/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.7811 - accuracy: 0.1642 - val_loss: 1.7660 - val_accuracy: 0.1798\n",
      "Epoch 8/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.7670 - accuracy: 0.1842 - val_loss: 1.7597 - val_accuracy: 0.1982\n",
      "Epoch 9/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.7712 - accuracy: 0.1800 - val_loss: 1.7546 - val_accuracy: 0.2097\n",
      "Epoch 10/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.7606 - accuracy: 0.1733 - val_loss: 1.7494 - val_accuracy: 0.2236\n",
      "Epoch 11/20\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.7499 - accuracy: 0.2025 - val_loss: 1.7444 - val_accuracy: 0.2321\n",
      "Epoch 12/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.7518 - accuracy: 0.2008 - val_loss: 1.7392 - val_accuracy: 0.2430\n",
      "Epoch 13/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.7495 - accuracy: 0.2017 - val_loss: 1.7339 - val_accuracy: 0.2467\n",
      "Epoch 14/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.7429 - accuracy: 0.2108 - val_loss: 1.7279 - val_accuracy: 0.2609\n",
      "Epoch 15/20\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.7315 - accuracy: 0.2183 - val_loss: 1.7219 - val_accuracy: 0.2694\n",
      "Epoch 16/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.7256 - accuracy: 0.2358 - val_loss: 1.7157 - val_accuracy: 0.2637\n",
      "Epoch 17/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.7209 - accuracy: 0.2517 - val_loss: 1.7091 - val_accuracy: 0.2640\n",
      "Epoch 18/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.7143 - accuracy: 0.2500 - val_loss: 1.7028 - val_accuracy: 0.2704\n",
      "Epoch 19/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.7065 - accuracy: 0.2617 - val_loss: 1.6962 - val_accuracy: 0.2725\n",
      "Epoch 20/20\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.7043 - accuracy: 0.2517 - val_loss: 1.6906 - val_accuracy: 0.2782\n",
      "Epoch 1/20\n",
      "38/38 [==============================] - 1s 8ms/step - loss: 1.8020 - accuracy: 0.1983 - val_loss: 1.7468 - val_accuracy: 0.1812\n",
      "Epoch 2/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.6922 - accuracy: 0.1783 - val_loss: 1.6397 - val_accuracy: 0.1663\n",
      "Epoch 3/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.6298 - accuracy: 0.1875 - val_loss: 1.6018 - val_accuracy: 0.1951\n",
      "Epoch 4/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.6038 - accuracy: 0.2558 - val_loss: 1.5653 - val_accuracy: 0.3071\n",
      "Epoch 5/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.5567 - accuracy: 0.3008 - val_loss: 1.5149 - val_accuracy: 0.3370\n",
      "Epoch 6/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.5352 - accuracy: 0.2750 - val_loss: 1.4739 - val_accuracy: 0.3492\n",
      "Epoch 7/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.4905 - accuracy: 0.3567 - val_loss: 1.4393 - val_accuracy: 0.3987\n",
      "Epoch 8/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.4411 - accuracy: 0.3783 - val_loss: 1.3752 - val_accuracy: 0.4360\n",
      "Epoch 9/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.3640 - accuracy: 0.4117 - val_loss: 1.2750 - val_accuracy: 0.4320\n",
      "Epoch 10/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.2711 - accuracy: 0.5025 - val_loss: 1.2192 - val_accuracy: 0.5623\n",
      "Epoch 11/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.2367 - accuracy: 0.5092 - val_loss: 1.1794 - val_accuracy: 0.6220\n",
      "Epoch 12/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.1972 - accuracy: 0.5633 - val_loss: 1.1491 - val_accuracy: 0.6054\n",
      "Epoch 13/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.1592 - accuracy: 0.5908 - val_loss: 1.1173 - val_accuracy: 0.6515\n",
      "Epoch 14/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.1375 - accuracy: 0.5908 - val_loss: 1.0905 - val_accuracy: 0.6885\n",
      "Epoch 15/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.1122 - accuracy: 0.6092 - val_loss: 1.0687 - val_accuracy: 0.6695\n",
      "Epoch 16/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.0742 - accuracy: 0.6250 - val_loss: 1.0402 - val_accuracy: 0.7116\n",
      "Epoch 17/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.0569 - accuracy: 0.6442 - val_loss: 1.0192 - val_accuracy: 0.7340\n",
      "Epoch 18/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.0384 - accuracy: 0.6492 - val_loss: 0.9972 - val_accuracy: 0.7421\n",
      "Epoch 19/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.0063 - accuracy: 0.6750 - val_loss: 0.9721 - val_accuracy: 0.7452\n",
      "Epoch 20/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.9869 - accuracy: 0.6800 - val_loss: 0.9519 - val_accuracy: 0.7530\n",
      "Epoch 1/20\n",
      "38/38 [==============================] - 1s 8ms/step - loss: 2.0373 - accuracy: 0.1608 - val_loss: 1.9376 - val_accuracy: 0.1809\n",
      "Epoch 2/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.9341 - accuracy: 0.1708 - val_loss: 1.8560 - val_accuracy: 0.1863\n",
      "Epoch 3/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.8536 - accuracy: 0.2058 - val_loss: 1.7958 - val_accuracy: 0.2172\n",
      "Epoch 4/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.7911 - accuracy: 0.2642 - val_loss: 1.7460 - val_accuracy: 0.2576\n",
      "Epoch 5/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.7359 - accuracy: 0.2817 - val_loss: 1.7021 - val_accuracy: 0.3000\n",
      "Epoch 6/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.7026 - accuracy: 0.2858 - val_loss: 1.6620 - val_accuracy: 0.3190\n",
      "Epoch 7/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.6557 - accuracy: 0.3267 - val_loss: 1.6228 - val_accuracy: 0.3434\n",
      "Epoch 8/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.6115 - accuracy: 0.3292 - val_loss: 1.5873 - val_accuracy: 0.3655\n",
      "Epoch 9/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.5775 - accuracy: 0.3508 - val_loss: 1.5544 - val_accuracy: 0.3807\n",
      "Epoch 10/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.5473 - accuracy: 0.3483 - val_loss: 1.5240 - val_accuracy: 0.3977\n",
      "Epoch 11/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.4983 - accuracy: 0.3850 - val_loss: 1.4953 - val_accuracy: 0.4252\n",
      "Epoch 12/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.4821 - accuracy: 0.3917 - val_loss: 1.4683 - val_accuracy: 0.4547\n",
      "Epoch 13/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.4570 - accuracy: 0.4067 - val_loss: 1.4437 - val_accuracy: 0.4842\n",
      "Epoch 14/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.4324 - accuracy: 0.4350 - val_loss: 1.4206 - val_accuracy: 0.5029\n",
      "Epoch 15/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.4032 - accuracy: 0.4142 - val_loss: 1.3986 - val_accuracy: 0.5314\n",
      "Epoch 16/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.3700 - accuracy: 0.4683 - val_loss: 1.3777 - val_accuracy: 0.5477\n",
      "Epoch 17/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.3581 - accuracy: 0.4633 - val_loss: 1.3577 - val_accuracy: 0.5558\n",
      "Epoch 18/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.3461 - accuracy: 0.4592 - val_loss: 1.3389 - val_accuracy: 0.5833\n",
      "Epoch 19/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.3261 - accuracy: 0.4467 - val_loss: 1.3211 - val_accuracy: 0.5948\n",
      "Epoch 20/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.2968 - accuracy: 0.4958 - val_loss: 1.3045 - val_accuracy: 0.6013\n",
      "Epoch 1/20\n",
      "38/38 [==============================] - 1s 9ms/step - loss: 1.8751 - accuracy: 0.1567 - val_loss: 1.8411 - val_accuracy: 0.1646\n",
      "Epoch 2/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.8574 - accuracy: 0.1625 - val_loss: 1.8260 - val_accuracy: 0.1649\n",
      "Epoch 3/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.8390 - accuracy: 0.1617 - val_loss: 1.8118 - val_accuracy: 0.1649\n",
      "Epoch 4/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.8234 - accuracy: 0.1617 - val_loss: 1.7981 - val_accuracy: 0.1649\n",
      "Epoch 5/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.8135 - accuracy: 0.1650 - val_loss: 1.7852 - val_accuracy: 0.1649\n",
      "Epoch 6/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.7972 - accuracy: 0.1567 - val_loss: 1.7729 - val_accuracy: 0.1653\n",
      "Epoch 7/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.7874 - accuracy: 0.1617 - val_loss: 1.7612 - val_accuracy: 0.1653\n",
      "Epoch 8/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.7786 - accuracy: 0.1642 - val_loss: 1.7500 - val_accuracy: 0.1659\n",
      "Epoch 9/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.7571 - accuracy: 0.1708 - val_loss: 1.7393 - val_accuracy: 0.1666\n",
      "Epoch 10/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.7510 - accuracy: 0.1833 - val_loss: 1.7291 - val_accuracy: 0.1673\n",
      "Epoch 11/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.7424 - accuracy: 0.1733 - val_loss: 1.7195 - val_accuracy: 0.1683\n",
      "Epoch 12/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.7294 - accuracy: 0.1858 - val_loss: 1.7100 - val_accuracy: 0.1690\n",
      "Epoch 13/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.7215 - accuracy: 0.1908 - val_loss: 1.7012 - val_accuracy: 0.1720\n",
      "Epoch 14/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.7093 - accuracy: 0.1908 - val_loss: 1.6926 - val_accuracy: 0.1758\n",
      "Epoch 15/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.7043 - accuracy: 0.1925 - val_loss: 1.6843 - val_accuracy: 0.1805\n",
      "Epoch 16/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.6949 - accuracy: 0.2008 - val_loss: 1.6763 - val_accuracy: 0.1860\n",
      "Epoch 17/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.6828 - accuracy: 0.1933 - val_loss: 1.6685 - val_accuracy: 0.1917\n",
      "Epoch 18/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.6758 - accuracy: 0.2342 - val_loss: 1.6609 - val_accuracy: 0.1999\n",
      "Epoch 19/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.6705 - accuracy: 0.2358 - val_loss: 1.6535 - val_accuracy: 0.2067\n",
      "Epoch 20/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.6577 - accuracy: 0.2400 - val_loss: 1.6463 - val_accuracy: 0.2158\n",
      "Epoch 1/20\n",
      "38/38 [==============================] - 1s 8ms/step - loss: 1.7201 - accuracy: 0.2842 - val_loss: 1.6593 - val_accuracy: 0.3682\n",
      "Epoch 2/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.6142 - accuracy: 0.3250 - val_loss: 1.5836 - val_accuracy: 0.3627\n",
      "Epoch 3/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.5508 - accuracy: 0.3458 - val_loss: 1.5226 - val_accuracy: 0.3655\n",
      "Epoch 4/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.4870 - accuracy: 0.3725 - val_loss: 1.4694 - val_accuracy: 0.3912\n",
      "Epoch 5/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.4368 - accuracy: 0.4083 - val_loss: 1.4221 - val_accuracy: 0.4248\n",
      "Epoch 6/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.3938 - accuracy: 0.4358 - val_loss: 1.3789 - val_accuracy: 0.4632\n",
      "Epoch 7/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.3499 - accuracy: 0.4483 - val_loss: 1.3398 - val_accuracy: 0.4930\n",
      "Epoch 8/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.3061 - accuracy: 0.4850 - val_loss: 1.3042 - val_accuracy: 0.5253\n",
      "Epoch 9/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.2745 - accuracy: 0.5025 - val_loss: 1.2717 - val_accuracy: 0.5344\n",
      "Epoch 10/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.2420 - accuracy: 0.4825 - val_loss: 1.2407 - val_accuracy: 0.5982\n",
      "Epoch 11/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.2142 - accuracy: 0.5408 - val_loss: 1.2130 - val_accuracy: 0.6210\n",
      "Epoch 12/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.1857 - accuracy: 0.5575 - val_loss: 1.1874 - val_accuracy: 0.6491\n",
      "Epoch 13/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.1547 - accuracy: 0.5825 - val_loss: 1.1630 - val_accuracy: 0.6671\n",
      "Epoch 14/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.1352 - accuracy: 0.5767 - val_loss: 1.1402 - val_accuracy: 0.6926\n",
      "Epoch 15/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.1241 - accuracy: 0.6108 - val_loss: 1.1191 - val_accuracy: 0.7051\n",
      "Epoch 16/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.1013 - accuracy: 0.6183 - val_loss: 1.0996 - val_accuracy: 0.7238\n",
      "Epoch 17/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.0661 - accuracy: 0.6450 - val_loss: 1.0807 - val_accuracy: 0.7360\n",
      "Epoch 18/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.0649 - accuracy: 0.6483 - val_loss: 1.0633 - val_accuracy: 0.7370\n",
      "Epoch 19/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.0488 - accuracy: 0.6433 - val_loss: 1.0466 - val_accuracy: 0.7455\n",
      "Epoch 20/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.0268 - accuracy: 0.6775 - val_loss: 1.0307 - val_accuracy: 0.7642\n",
      "Epoch 1/20\n",
      "38/38 [==============================] - 1s 9ms/step - loss: 1.8310 - accuracy: 0.1733 - val_loss: 1.7919 - val_accuracy: 0.2043\n",
      "Epoch 2/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.8272 - accuracy: 0.1908 - val_loss: 1.7836 - val_accuracy: 0.2073\n",
      "Epoch 3/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.8134 - accuracy: 0.1767 - val_loss: 1.7757 - val_accuracy: 0.2097\n",
      "Epoch 4/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.8122 - accuracy: 0.1842 - val_loss: 1.7681 - val_accuracy: 0.2141\n",
      "Epoch 5/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.8002 - accuracy: 0.1967 - val_loss: 1.7607 - val_accuracy: 0.2195\n",
      "Epoch 6/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.7840 - accuracy: 0.2200 - val_loss: 1.7535 - val_accuracy: 0.2250\n",
      "Epoch 7/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.7815 - accuracy: 0.2000 - val_loss: 1.7467 - val_accuracy: 0.2324\n",
      "Epoch 8/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.7766 - accuracy: 0.2183 - val_loss: 1.7399 - val_accuracy: 0.2406\n",
      "Epoch 9/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.7527 - accuracy: 0.2225 - val_loss: 1.7334 - val_accuracy: 0.2514\n",
      "Epoch 10/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.7544 - accuracy: 0.2350 - val_loss: 1.7271 - val_accuracy: 0.2667\n",
      "Epoch 11/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.7460 - accuracy: 0.2525 - val_loss: 1.7209 - val_accuracy: 0.2810\n",
      "Epoch 12/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.7461 - accuracy: 0.2450 - val_loss: 1.7149 - val_accuracy: 0.2956\n",
      "Epoch 13/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.7512 - accuracy: 0.2275 - val_loss: 1.7089 - val_accuracy: 0.3091\n",
      "Epoch 14/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.7339 - accuracy: 0.2625 - val_loss: 1.7032 - val_accuracy: 0.3251\n",
      "Epoch 15/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.7306 - accuracy: 0.2583 - val_loss: 1.6975 - val_accuracy: 0.3386\n",
      "Epoch 16/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.7159 - accuracy: 0.2800 - val_loss: 1.6920 - val_accuracy: 0.3498\n",
      "Epoch 17/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.7020 - accuracy: 0.3000 - val_loss: 1.6867 - val_accuracy: 0.3590\n",
      "Epoch 18/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.7111 - accuracy: 0.2883 - val_loss: 1.6813 - val_accuracy: 0.3665\n",
      "Epoch 19/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.7059 - accuracy: 0.2817 - val_loss: 1.6762 - val_accuracy: 0.3716\n",
      "Epoch 20/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.6946 - accuracy: 0.3158 - val_loss: 1.6711 - val_accuracy: 0.3811\n",
      "Epoch 1/20\n",
      "38/38 [==============================] - 1s 9ms/step - loss: 0.9104 - accuracy: 0.6317 - val_loss: 0.5078 - val_accuracy: 0.8609\n",
      "Epoch 2/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4053 - accuracy: 0.8650 - val_loss: 0.3488 - val_accuracy: 0.8663\n",
      "Epoch 3/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3286 - accuracy: 0.8733 - val_loss: 0.4610 - val_accuracy: 0.8113\n",
      "Epoch 4/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3000 - accuracy: 0.8733 - val_loss: 0.3175 - val_accuracy: 0.8636\n",
      "Epoch 5/20\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2419 - accuracy: 0.9108 - val_loss: 0.2333 - val_accuracy: 0.9030\n",
      "Epoch 6/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1770 - accuracy: 0.9383 - val_loss: 0.2585 - val_accuracy: 0.8826\n",
      "Epoch 7/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1412 - accuracy: 0.9475 - val_loss: 0.2233 - val_accuracy: 0.9063\n",
      "Epoch 8/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1364 - accuracy: 0.9508 - val_loss: 0.2567 - val_accuracy: 0.8850\n",
      "Epoch 9/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1407 - accuracy: 0.9450 - val_loss: 0.1824 - val_accuracy: 0.9277\n",
      "Epoch 10/20\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1144 - accuracy: 0.9650 - val_loss: 0.1833 - val_accuracy: 0.9281\n",
      "Epoch 11/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1292 - accuracy: 0.9508 - val_loss: 0.1878 - val_accuracy: 0.9277\n",
      "Epoch 12/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1044 - accuracy: 0.9625 - val_loss: 0.2010 - val_accuracy: 0.9189\n",
      "Epoch 13/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0851 - accuracy: 0.9700 - val_loss: 0.1572 - val_accuracy: 0.9372\n",
      "Epoch 14/20\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0870 - accuracy: 0.9692 - val_loss: 0.1699 - val_accuracy: 0.9382\n",
      "Epoch 15/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0872 - accuracy: 0.9650 - val_loss: 0.2432 - val_accuracy: 0.9104\n",
      "Epoch 16/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0774 - accuracy: 0.9750 - val_loss: 0.1855 - val_accuracy: 0.9277\n",
      "Epoch 17/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0601 - accuracy: 0.9842 - val_loss: 0.1668 - val_accuracy: 0.9348\n",
      "Epoch 18/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0755 - accuracy: 0.9758 - val_loss: 0.1900 - val_accuracy: 0.9267\n",
      "Epoch 19/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0827 - accuracy: 0.9700 - val_loss: 0.2480 - val_accuracy: 0.9097\n",
      "Epoch 20/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0718 - accuracy: 0.9700 - val_loss: 0.2239 - val_accuracy: 0.9182\n",
      "Epoch 1/20\n",
      "38/38 [==============================] - 1s 10ms/step - loss: 1.7787 - accuracy: 0.1750 - val_loss: 1.7263 - val_accuracy: 0.2155\n",
      "Epoch 2/20\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 1.6806 - accuracy: 0.2500 - val_loss: 1.6407 - val_accuracy: 0.2667\n",
      "Epoch 3/20\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 1.5901 - accuracy: 0.3075 - val_loss: 1.5655 - val_accuracy: 0.3173\n",
      "Epoch 4/20\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 1.5070 - accuracy: 0.3750 - val_loss: 1.4928 - val_accuracy: 0.4082\n",
      "Epoch 5/20\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 1.4308 - accuracy: 0.4517 - val_loss: 1.4286 - val_accuracy: 0.5110\n",
      "Epoch 6/20\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 1.3822 - accuracy: 0.4983 - val_loss: 1.3679 - val_accuracy: 0.6023\n",
      "Epoch 7/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.3196 - accuracy: 0.5608 - val_loss: 1.3128 - val_accuracy: 0.6471\n",
      "Epoch 8/20\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 1.2644 - accuracy: 0.5708 - val_loss: 1.2608 - val_accuracy: 0.7360\n",
      "Epoch 9/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.2149 - accuracy: 0.6083 - val_loss: 1.2133 - val_accuracy: 0.7435\n",
      "Epoch 10/20\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 1.1664 - accuracy: 0.6450 - val_loss: 1.1707 - val_accuracy: 0.7713\n",
      "Epoch 11/20\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 1.1220 - accuracy: 0.6700 - val_loss: 1.1328 - val_accuracy: 0.7920\n",
      "Epoch 12/20\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 1.0926 - accuracy: 0.6783 - val_loss: 1.0979 - val_accuracy: 0.8018\n",
      "Epoch 13/20\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 1.0616 - accuracy: 0.6833 - val_loss: 1.0658 - val_accuracy: 0.8076\n",
      "Epoch 14/20\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 1.0294 - accuracy: 0.7067 - val_loss: 1.0357 - val_accuracy: 0.8219\n",
      "Epoch 15/20\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 1.0071 - accuracy: 0.6992 - val_loss: 1.0085 - val_accuracy: 0.8215\n",
      "Epoch 16/20\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.9687 - accuracy: 0.7375 - val_loss: 0.9823 - val_accuracy: 0.8375\n",
      "Epoch 17/20\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.9446 - accuracy: 0.7608 - val_loss: 0.9579 - val_accuracy: 0.8419\n",
      "Epoch 18/20\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.9211 - accuracy: 0.7708 - val_loss: 0.9349 - val_accuracy: 0.8398\n",
      "Epoch 19/20\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.8981 - accuracy: 0.7808 - val_loss: 0.9136 - val_accuracy: 0.8463\n",
      "Epoch 20/20\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.8791 - accuracy: 0.7692 - val_loss: 0.8944 - val_accuracy: 0.8290\n",
      "Epoch 1/20\n",
      "38/38 [==============================] - 1s 9ms/step - loss: 0.8280 - accuracy: 0.6392 - val_loss: 0.5141 - val_accuracy: 0.7533\n",
      "Epoch 2/20\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3624 - accuracy: 0.8625 - val_loss: 0.3188 - val_accuracy: 0.8649\n",
      "Epoch 3/20\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2416 - accuracy: 0.9058 - val_loss: 0.2643 - val_accuracy: 0.9009\n",
      "Epoch 4/20\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1953 - accuracy: 0.9300 - val_loss: 0.2815 - val_accuracy: 0.8707\n",
      "Epoch 5/20\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1595 - accuracy: 0.9467 - val_loss: 0.2251 - val_accuracy: 0.9121\n",
      "Epoch 6/20\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1664 - accuracy: 0.9408 - val_loss: 0.2694 - val_accuracy: 0.8979\n",
      "Epoch 7/20\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1156 - accuracy: 0.9558 - val_loss: 0.2389 - val_accuracy: 0.9023\n",
      "Epoch 8/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1287 - accuracy: 0.9533 - val_loss: 0.2001 - val_accuracy: 0.9213\n",
      "Epoch 9/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1125 - accuracy: 0.9525 - val_loss: 0.1751 - val_accuracy: 0.9291\n",
      "Epoch 10/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1067 - accuracy: 0.9567 - val_loss: 0.1821 - val_accuracy: 0.9253\n",
      "Epoch 11/20\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1252 - accuracy: 0.9517 - val_loss: 0.2107 - val_accuracy: 0.9216\n",
      "Epoch 12/20\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0982 - accuracy: 0.9625 - val_loss: 0.2231 - val_accuracy: 0.9169\n",
      "Epoch 13/20\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0848 - accuracy: 0.9667 - val_loss: 0.2243 - val_accuracy: 0.9118\n",
      "Epoch 14/20\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1708 - accuracy: 0.9467 - val_loss: 0.3128 - val_accuracy: 0.8972\n",
      "Epoch 15/20\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1137 - accuracy: 0.9550 - val_loss: 0.2954 - val_accuracy: 0.8935\n",
      "Epoch 16/20\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0628 - accuracy: 0.9775 - val_loss: 0.1766 - val_accuracy: 0.9372\n",
      "Epoch 17/20\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0743 - accuracy: 0.9742 - val_loss: 0.2046 - val_accuracy: 0.9240\n",
      "Epoch 18/20\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0677 - accuracy: 0.9742 - val_loss: 0.2425 - val_accuracy: 0.9230\n",
      "Epoch 19/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1144 - accuracy: 0.9592 - val_loss: 0.2357 - val_accuracy: 0.9165\n",
      "Epoch 20/20\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0850 - accuracy: 0.9708 - val_loss: 0.1703 - val_accuracy: 0.9335\n"
     ]
    }
   ],
   "source": [
    "# Train on own private dataset only\n",
    "local_models = [get_model(n_classes, input_shape, model_params )[0] for model_params in models_params] \n",
    "for i, model in enumerate(local_models) : \n",
    "    local_training_history = model.fit(pri_x_list[i], pri_y_list[i], validation_data = (x_test, y_test_cat), epochs = 20, verbose = True)\n",
    "    pd.DataFrame(local_training_history.history).to_csv(os.path.join(experiment_dir, 'local_train_iid', 'local_training_{}.csv'.format(i)))\n",
    "\n",
    "# Training a model on all distributed dataset (centralized training). \n",
    "centralized_models = [get_model(n_classes, input_shape, model_params )[0] for model_params in models_params] \n",
    "for i, model in enumerate(centralized_models) : \n",
    "    centralized_training_history = model.fit(pri_x_total, pri_y_total, validation_data = (x_test, y_test_cat), epochs = 20, verbose = True)\n",
    "    pd.DataFrame(centralized_training_history.history).to_csv(os.path.join(experiment_dir, 'central_train_iid', 'centralized_training_{}.csv'.format(i)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Iteration: 0\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "models' accuracies: [0.2429589480161667, 0.2504241466522217, 0.3447573781013489, 0.35934847593307495, 0.21072277426719666, 0.4340006709098816, 0.5761791467666626, 0.4384119510650635, 0.6172378659248352, 0.4204275608062744]\n",
      "Avg Acc:0.3894468918442726 Mean:-0.05554039403796196 Std:0.8197790384292603\n",
      "\n",
      " Iteration: 1\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "models' accuracies: [0.22463522851467133, 0.18086189031600952, 0.3783508539199829, 0.30743128061294556, 0.34713268280029297, 0.6915507316589355, 0.76823890209198, 0.5714285969734192, 0.7410926222801208, 0.5802510976791382]\n",
      "Avg Acc:0.4790973886847496 Mean:0.08898923546075821 Std:1.0115286111831665\n",
      "\n",
      " Iteration: 2\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 996us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 998us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.18052256107330322, 0.18052256107330322, 0.4855785667896271, 0.3372921645641327, 0.35697320103645325, 0.8255853652954102, 0.6813709139823914, 0.6131659150123596, 0.7519511580467224, 0.5924668908119202]\n",
      "Avg Acc:0.5005429297685623 Mean:0.08251027762889862 Std:1.024034857749939\n",
      "\n",
      " Iteration: 3\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "models' accuracies: [0.003393281251192093, 0.16728876531124115, 0.5497115850448608, 0.49338310956954956, 0.34984731674194336, 0.8425517678260803, 0.6912114024162292, 0.6202918291091919, 0.8500169515609741, 0.6739056706428528]\n",
      "Avg Acc:0.5241601679474115 Mean:0.06089765951037407 Std:1.4473787546157837\n",
      "\n",
      " Iteration: 4\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "models' accuracies: [0.013233796693384647, 0.22056327760219574, 0.6094332933425903, 0.39735323190689087, 0.41398030519485474, 0.838819146156311, 0.5663386583328247, 0.7163217067718506, 0.8082796335220337, 0.736681342124939]\n",
      "Avg Acc:0.5321004391647876 Mean:0.09224341064691544 Std:1.5062462091445923\n",
      "\n",
      " Iteration: 5\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "models' accuracies: [0.18052256107330322, 0.26230064034461975, 0.6508313417434692, 0.3732609450817108, 0.3355955183506012, 0.7797760367393494, 0.6817102432250977, 0.7556837201118469, 0.8279606103897095, 0.7875806093215942]\n",
      "Avg Acc:0.5635222226381302 Mean:0.08952087163925171 Std:1.3486895561218262\n",
      "\n",
      " Iteration: 6\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "models' accuracies: [0.16728876531124115, 0.21275873482227325, 0.6267390847206116, 0.45469969511032104, 0.337631493806839, 0.8411944508552551, 0.6559212803840637, 0.7509331703186035, 0.8618934750556946, 0.7797760367393494]\n",
      "Avg Acc:0.5688836187124252 Mean:0.10761689394712448 Std:1.4837462902069092\n",
      "\n",
      " Iteration: 7\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "models' accuracies: [0.17543263733386993, 0.18052256107330322, 0.6559212803840637, 0.4747200608253479, 0.3956565856933594, 0.8133695125579834, 0.6820495128631592, 0.8059043288230896, 0.833050549030304, 0.7512724995613098]\n",
      "Avg Acc:0.576789952814579 Mean:0.11132403463125229 Std:1.3750325441360474\n",
      "\n",
      " Iteration: 8\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "models' accuracies: [0.16728876531124115, 0.188666433095932, 0.684085488319397, 0.44587716460227966, 0.49643704295158386, 0.8028503656387329, 0.7845266461372375, 0.8310145735740662, 0.8500169515609741, 0.8361045122146606]\n",
      "Avg Acc:0.6086867943406105 Mean:0.09268012642860413 Std:1.6836931705474854\n",
      "\n",
      " Iteration: 9\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "models' accuracies: [0.16728876531124115, 0.25551408529281616, 0.6559212803840637, 0.5059382319450378, 0.4394299387931824, 0.8425517678260803, 0.7563623785972595, 0.8215134143829346, 0.8469629883766174, 0.7953851222991943]\n",
      "Avg Acc:0.6086867973208427 Mean:0.10783528536558151 Std:1.3980326652526855\n",
      "\n",
      " Iteration: 10\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 988us/step\n",
      "4/4 [==============================] - 0s 998us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "models' accuracies: [0.16728876531124115, 0.31353920698165894, 0.6691550612449646, 0.5093315243721008, 0.4774346649646759, 0.8411944508552551, 0.764845609664917, 0.7991177439689636, 0.8517135977745056, 0.8483203053474426]\n",
      "Avg Acc:0.6241940930485725 Mean:0.11093202978372574 Std:1.5384374856948853\n",
      "\n",
      " Iteration: 11\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 665us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.16661010682582855, 0.3400067985057831, 0.6952833533287048, 0.4645402133464813, 0.36308109760284424, 0.8367831707000732, 0.7410926222801208, 0.8574821949005127, 0.8557855486869812, 0.8442484140396118]\n",
      "Avg Acc:0.6164913520216941 Mean:0.1331828385591507 Std:1.533998727798462\n",
      "\n",
      " Iteration: 12\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 998us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 996us/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.16321682929992676, 0.3400067985057831, 0.7064811587333679, 0.4747200608253479, 0.35493722558021545, 0.8245673775672913, 0.6467593908309937, 0.8605361580848694, 0.866644024848938, 0.8415337800979614]\n",
      "Avg Acc:0.6079402804374695 Mean:0.14112886786460876 Std:1.4262897968292236\n",
      "\n",
      " Iteration: 13\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "models' accuracies: [0.1486257165670395, 0.3400067985057831, 0.7404139637947083, 0.4309467375278473, 0.39531728625297546, 0.8099762201309204, 0.8194774389266968, 0.8181201219558716, 0.8710553050041199, 0.8456056714057922]\n",
      "Avg Acc:0.6219545260071755 Mean:0.13645465672016144 Std:1.5143922567367554\n",
      "\n",
      " Iteration: 14\n",
      "4/4 [==============================] - 0s 665us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.16084153950214386, 0.3400067985057831, 0.6569392681121826, 0.4791313111782074, 0.4221242070198059, 0.8591788411140442, 0.8391584753990173, 0.8595181703567505, 0.8632507920265198, 0.8327112197875977]\n",
      "Avg Acc:0.6312860623002052 Mean:0.13055109977722168 Std:1.3782267570495605\n",
      "\n",
      " Iteration: 15\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 665us/step\n",
      "4/4 [==============================] - 0s 998us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "models' accuracies: [0.16593144834041595, 0.3240583539009094, 0.6599932312965393, 0.5134034752845764, 0.45503902435302734, 0.8316932320594788, 0.731252133846283, 0.8469629883766174, 0.854428231716156, 0.8473023176193237]\n",
      "Avg Acc:0.6230064436793328 Mean:0.1331907957792282 Std:1.7134720087051392\n",
      "\n",
      " Iteration: 16\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 988us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 665us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "models' accuracies: [0.15405496954917908, 0.31252121925354004, 0.7634882926940918, 0.46114692091941833, 0.4424838721752167, 0.8289785981178284, 0.8299965858459473, 0.8557855486869812, 0.8473023176193237, 0.8469629883766174]\n",
      "Avg Acc:0.6342721313238144 Mean:0.13554291427135468 Std:1.427333950996399\n",
      "\n",
      " Iteration: 17\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.15812690556049347, 0.3308449387550354, 0.7431285977363586, 0.582287073135376, 0.41465896368026733, 0.8401764631271362, 0.7858839631080627, 0.8568035364151001, 0.8598574995994568, 0.8615541458129883]\n",
      "Avg Acc:0.6433322086930275 Mean:0.13734936714172363 Std:1.5925590991973877\n",
      "\n",
      " Iteration: 18\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 998us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 998us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "models' accuracies: [0.17543263733386993, 0.3318628966808319, 0.7835086584091187, 0.46080759167671204, 0.3736002743244171, 0.8588395118713379, 0.6796742677688599, 0.8683406710624695, 0.8632507920265198, 0.8534102439880371]\n",
      "Avg Acc:0.6248727545142174 Mean:0.12726552784442902 Std:1.60866117477417\n",
      "\n",
      " Iteration: 19\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 998us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "models' accuracies: [0.20054292678833008, 0.334238201379776, 0.7943671345710754, 0.4865965247154236, 0.3732609450817108, 0.8564642071723938, 0.689854085445404, 0.8724126219749451, 0.8601968288421631, 0.8744485974311829]\n",
      "Avg Acc:0.6342382073402405 Mean:0.13113677501678467 Std:1.454256534576416\n",
      "\n",
      " Iteration: 20\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 998us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "models' accuracies: [0.2371903657913208, 0.3400067985057831, 0.805225670337677, 0.6145232319831848, 0.45402103662490845, 0.8062436580657959, 0.8598574995994568, 0.8710553050041199, 0.8571428656578064, 0.8649473786354065]\n",
      "Avg Acc:0.671021381020546 Mean:0.11206258088350296 Std:1.547711730003357\n",
      "\n",
      " Iteration: 21\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "models' accuracies: [0.2416016310453415, 0.3400067985057831, 0.7662029266357422, 0.5276552438735962, 0.4346793293952942, 0.8238887190818787, 0.5551407933235168, 0.8639293909072876, 0.8398371338844299, 0.8676620125770569]\n",
      "Avg Acc:0.6260603979229927 Mean:0.09409210085868835 Std:1.5119702816009521\n",
      "\n",
      " Iteration: 22\n",
      "4/4 [==============================] - 0s 998us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.21445538103580475, 0.3400067985057831, 0.7726501822471619, 0.5208686590194702, 0.45402103662490845, 0.8713946342468262, 0.8696979880332947, 0.8632507920265198, 0.8608754873275757, 0.8727519512176514]\n",
      "Avg Acc:0.6639972910284996 Mean:0.13416247069835663 Std:1.7173904180526733\n",
      "\n",
      " Iteration: 23\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 998us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "models' accuracies: [0.233797088265419, 0.3403461277484894, 0.8089582920074463, 0.5313878655433655, 0.5093315243721008, 0.8747879266738892, 0.705463171005249, 0.8696979880332947, 0.8333898782730103, 0.8747879266738892]\n",
      "Avg Acc:0.6581947788596153 Mean:0.12363877147436142 Std:1.47652006149292\n",
      "\n",
      " Iteration: 24\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.26772990822792053, 0.3400067985057831, 0.8133695125579834, 0.5958601832389832, 0.5843230485916138, 0.8727519512176514, 0.7512724995613098, 0.8744485974311829, 0.854428231716156, 0.8683406710624695]\n",
      "Avg Acc:0.6822531402111054 Mean:0.13317885994911194 Std:1.6381487846374512\n",
      "\n",
      " Iteration: 25\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 665us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.30369868874549866, 0.3400067985057831, 0.7831693291664124, 0.547675609588623, 0.44418051838874817, 0.8323718905448914, 0.7702748775482178, 0.8598574995994568, 0.8564642071723938, 0.8690193295478821]\n",
      "Avg Acc:0.6606718748807907 Mean:0.13189393281936646 Std:1.6214005947113037\n",
      "\n",
      " Iteration: 26\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.30810993909835815, 0.3349168598651886, 0.8238887190818787, 0.5680353045463562, 0.45503902435302734, 0.8082796335220337, 0.782829999923706, 0.8635901212692261, 0.8605361580848694, 0.884628415107727]\n",
      "Avg Acc:0.6689854174852371 Mean:0.13412240147590637 Std:1.4981672763824463\n",
      "\n",
      " Iteration: 27\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.31184256076812744, 0.3389888107776642, 0.8357651829719543, 0.5680353045463562, 0.507295548915863, 0.8238887190818787, 0.8062436580657959, 0.8618934750556946, 0.8608754873275757, 0.8707159757614136]\n",
      "Avg Acc:0.6785544723272323 Mean:0.12728776037693024 Std:1.5851479768753052\n",
      "\n",
      " Iteration: 28\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.3213437497615814, 0.3400067985057831, 0.8184594511985779, 0.5866983532905579, 0.5639633536338806, 0.8618934750556946, 0.8496776223182678, 0.8890396952629089, 0.8710553050041199, 0.8761452436447144]\n",
      "Avg Acc:0.6978283047676086 Mean:0.119949109852314 Std:1.4586166143417358\n",
      "\n",
      " Iteration: 29\n",
      "4/4 [==============================] - 0s 998us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.3257550001144409, 0.3420427441596985, 0.8425517678260803, 0.705463171005249, 0.7074991464614868, 0.8483203053474426, 0.810654878616333, 0.8954869508743286, 0.870037317276001, 0.8788598775863647]\n",
      "Avg Acc:0.7226671159267426 Mean:0.12145139276981354 Std:1.7564363479614258\n",
      "\n",
      " Iteration: 30\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.3291482925415039, 0.3420427441596985, 0.8184594511985779, 0.7166610360145569, 0.68747878074646, 0.8693586587905884, 0.8089582920074463, 0.8761452436447144, 0.8710553050041199, 0.8863250613212585]\n",
      "Avg Acc:0.7205632865428925 Mean:0.09848518669605255 Std:1.4654223918914795\n",
      "\n",
      " Iteration: 31\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 991us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.3233796954154968, 0.3400067985057831, 0.7885985970497131, 0.6549032926559448, 0.6993553042411804, 0.8154054880142212, 0.8537495732307434, 0.8758059144020081, 0.8717339634895325, 0.885646402835846]\n",
      "Avg Acc:0.710858502984047 Mean:0.11339354515075684 Std:1.6158891916275024\n",
      "\n",
      " Iteration: 32\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.31625381112098694, 0.3267729878425598, 0.8381404876708984, 0.607058048248291, 0.6474380493164062, 0.7933491468429565, 0.84764164686203, 0.8601968288421631, 0.8710553050041199, 0.8819137811660767]\n",
      "Avg Acc:0.6989820092916489 Mean:0.1147594079375267 Std:1.6153349876403809\n",
      "\n",
      " Iteration: 33\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 998us/step\n",
      "4/4 [==============================] - 0s 998us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.31659314036369324, 0.334238201379776, 0.8456056714057922, 0.6118085980415344, 0.6616898775100708, 0.8177807927131653, 0.6525279879570007, 0.8903970122337341, 0.8710553050041199, 0.8859857320785522]\n",
      "Avg Acc:0.6887682318687439 Mean:0.12080464512109756 Std:1.537887692451477\n",
      "\n",
      " Iteration: 34\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.3254156708717346, 0.3400067985057831, 0.8513742685317993, 0.6426874995231628, 0.7505938410758972, 0.8320325613021851, 0.8340685367584229, 0.8778418898582458, 0.8737699389457703, 0.8917543292045593]\n",
      "Avg Acc:0.7219545334577561 Mean:0.1057053953409195 Std:1.6137844324111938\n",
      "\n",
      " Iteration: 35\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.3254156708717346, 0.3400067985057831, 0.8527315855026245, 0.668476402759552, 0.7519511580467224, 0.861214816570282, 0.8211740851402283, 0.8815745115280151, 0.8720732927322388, 0.8730912804603577]\n",
      "Avg Acc:0.7247709602117538 Mean:0.08293132483959198 Std:1.4975450038909912\n",
      "\n",
      " Iteration: 36\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.3233796954154968, 0.3400067985057831, 0.8452664017677307, 0.6759416460990906, 0.7634882926940918, 0.8585001826286316, 0.7058025002479553, 0.882253110408783, 0.8720732927322388, 0.8961656093597412]\n",
      "Avg Acc:0.7162877529859543 Mean:0.06627683341503143 Std:1.8460240364074707\n",
      "\n",
      " Iteration: 37\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.3260943293571472, 0.3400067985057831, 0.8218527436256409, 0.6735663414001465, 0.6474380493164062, 0.8676620125770569, 0.8537495732307434, 0.8951476216316223, 0.8646080493927002, 0.8741092681884766]\n",
      "Avg Acc:0.7164234787225723 Mean:0.04739025980234146 Std:1.5091159343719482\n",
      "\n",
      " Iteration: 38\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.3325415551662445, 0.3413640856742859, 0.8394978046417236, 0.5907703042030334, 0.7597556710243225, 0.8449270725250244, 0.8378011584281921, 0.8832710981369019, 0.8656260371208191, 0.8958262801170349]\n",
      "Avg Acc:0.7191381067037582 Mean:0.03975410386919975 Std:1.678171992301941\n",
      "\n",
      " Iteration: 39\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 998us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "models' accuracies: [0.3264336585998535, 0.34679335355758667, 0.8625721335411072, 0.6138445734977722, 0.791652500629425, 0.8489989638328552, 0.7831693291664124, 0.8975229263305664, 0.8669833540916443, 0.8870037198066711]\n",
      "Avg Acc:0.7224974513053894 Mean:0.022990496829152107 Std:1.661446213722229\n",
      "\n",
      " Iteration: 40\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.3254156708717346, 0.3461146950721741, 0.8506956100463867, 0.6677977442741394, 0.7407532930374146, 0.835425853729248, 0.7899559140205383, 0.8825924396514893, 0.8601968288421631, 0.88802170753479]\n",
      "Avg Acc:0.7186969757080078 Mean:0.03582410514354706 Std:1.5366687774658203\n",
      "\n",
      " Iteration: 41\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.3257550001144409, 0.3417034149169922, 0.8228707313537598, 0.6640651226043701, 0.7071598172187805, 0.8608754873275757, 0.8378011584281921, 0.8965049386024475, 0.8642687201499939, 0.8853070735931396]\n",
      "Avg Acc:0.7206311464309693 Mean:0.049653682857751846 Std:1.6565231084823608\n",
      "\n",
      " Iteration: 42\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.3671530485153198, 0.3403461277484894, 0.8557855486869812, 0.7285374999046326, 0.7251442074775696, 0.84764164686203, 0.8537495732307434, 0.8961656093597412, 0.8581608533859253, 0.8907363414764404]\n",
      "Avg Acc:0.7363420456647873 Mean:0.014007752761244774 Std:1.536113977432251\n",
      "\n",
      " Iteration: 43\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.36952832341194153, 0.3403461277484894, 0.84764164686203, 0.7261621952056885, 0.8154054880142212, 0.8418731093406677, 0.777061402797699, 0.8961656093597412, 0.8656260371208191, 0.8866643905639648]\n",
      "Avg Acc:0.7366474330425262 Mean:0.020350471138954163 Std:1.8745044469833374\n",
      "\n",
      " Iteration: 44\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.39531728625297546, 0.3406854569911957, 0.8435697555541992, 0.6935867071151733, 0.7967424392700195, 0.851034939289093, 0.8245673775672913, 0.8836104273796082, 0.8520529270172119, 0.8900576829910278]\n",
      "Avg Acc:0.7371224999427796 Mean:0.020637627691030502 Std:1.549207091331482\n",
      "\n",
      " Iteration: 45\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.3800475001335144, 0.3406854569911957, 0.8452664017677307, 0.7356634140014648, 0.7529691457748413, 0.8473023176193237, 0.8350865244865417, 0.8853070735931396, 0.8571428656578064, 0.8907363414764404]\n",
      "Avg Acc:0.7370207041501999 Mean:0.018968241289258003 Std:1.7212249040603638\n",
      "\n",
      " Iteration: 46\n",
      "4/4 [==============================] - 0s 956us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.35188326239585876, 0.3403461277484894, 0.8323718905448914, 0.7153037190437317, 0.7858839631080627, 0.8357651829719543, 0.7875806093215942, 0.8998982310295105, 0.854428231716156, 0.8887003660202026]\n",
      "Avg Acc:0.7292161583900452 Mean:0.005198436789214611 Std:1.731188178062439\n",
      "\n",
      " Iteration: 47\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "models' accuracies: [0.41431963443756104, 0.3417034149169922, 0.8547675609588623, 0.6949440240859985, 0.7960637807846069, 0.8215134143829346, 0.8228707313537598, 0.8853070735931396, 0.8456056714057922, 0.8934509754180908]\n",
      "Avg Acc:0.7370546281337738 Mean:0.004107401706278324 Std:1.6106623411178589\n",
      "\n",
      " Iteration: 48\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.35256192088127136, 0.34848999977111816, 0.8595181703567505, 0.671869695186615, 0.8062436580657959, 0.810654878616333, 0.8598574995994568, 0.8992195725440979, 0.8598574995994568, 0.8917543292045593]\n",
      "Avg Acc:0.7360027223825455 Mean:0.0018915074178948998 Std:1.712143898010254\n",
      "\n",
      " Iteration: 49\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.34950798749923706, 0.36443841457366943, 0.8581608533859253, 0.6820495128631592, 0.8150661587715149, 0.8249067068099976, 0.8571428656578064, 0.8975229263305664, 0.8601968288421631, 0.885646402835846]\n",
      "Avg Acc:0.7394638657569885 Mean:0.011396527290344238 Std:1.594581127166748\n"
     ]
    }
   ],
   "source": [
    "\n",
    "shared_public_dataset = (pub_x[:n_alignment, ...], pub_y[:n_alignment, ...])\n",
    "validation_dataset = (x_test, y_test_cat)\n",
    "fedmd_nodes = [FedAMDNode(iid_models[i], (pri_x_list[i], pri_y_list[i]), shared_public_dataset, target_validation_gen = validation_dataset) for i in range(n_parties)]\n",
    "\n",
    "# Training iterations \n",
    "for iteration in range(n_iterations) : \n",
    "  print('\\n Iteration:', iteration)\n",
    "\n",
    "  for i, node in enumerate(fedmd_nodes) : \n",
    "    logger_file = os.path.join(experiment_dir,'iid', 'train_{}.csv'.format(i))\n",
    "    node.train_on_target(epochs = 2, verbose = False, logger_file = logger_file, evaluate = True)\n",
    "\n",
    "  # seed and alpha variables are not used in FedMD since it uses Node not FedAMDNode\n",
    "  seed = np.random.randint(0, 10000) \n",
    "  alpha = np.random.rand()\n",
    "\n",
    "  pub_scores, priv_performances = collect_metadatas(fedmd_nodes, seed, alpha) \n",
    "  print(\"models' accuracies:\", priv_performances) \n",
    "  print(\"Avg Acc:{} Mean:{} Std:{}\".format(np.mean(priv_performances), np.mean(pub_scores), np.std(pub_scores)))\n",
    "  \n",
    "  # Aggregate training metadata \n",
    "  weighted_pub_scores = aggregate_training_metadatas(pub_scores, priv_performances, weighted_averaging = True) \n",
    "\n",
    "\n",
    "  # Receive training metadata (and rebuilds Carrier dataset with updated labels)\n",
    "  for i, node in enumerate(fedmd_nodes) : \n",
    "    node.receive_training_metadata(weighted_pub_scores)   \n",
    "    node.train_on_public(epochs = 1, verbose = False) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-i.i.d. clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_batches shape :  (6616, 561)\n",
      "train_labels shape :  (6616,)\n",
      "pub_data_batches shape :  (736, 561)\n",
      "pub_data_labels shape :  (736,)\n",
      "test_batches shape :  (2947, 561)\n",
      "categorical test_labels shape :  (2947, 6)\n",
      "_____________________________________________\n",
      "pri_x_total shape :  (100, 561)\n",
      "pri_y_total shape :  (100, 6)\n",
      "pri_x_total shape :  (80, 561)\n",
      "pri_y_total shape :  (80, 6)\n",
      "pri_x_total shape :  (60, 561)\n",
      "pri_y_total shape :  (60, 6)\n",
      "pri_x_total shape :  (60, 561)\n",
      "pri_y_total shape :  (60, 6)\n",
      "pri_x_total shape :  (80, 561)\n",
      "pri_y_total shape :  (80, 6)\n",
      "pri_x_total shape :  (100, 561)\n",
      "pri_y_total shape :  (100, 6)\n",
      "pri_x_total shape :  (60, 561)\n",
      "pri_y_total shape :  (60, 6)\n",
      "pri_x_total shape :  (100, 561)\n",
      "pri_y_total shape :  (100, 6)\n",
      "pri_x_total shape :  (80, 561)\n",
      "pri_y_total shape :  (80, 6)\n",
      "pri_x_total shape :  (60, 561)\n",
      "pri_y_total shape :  (60, 6)\n",
      "_____________________________________________\n",
      "pri_x_total shape :  (1200, 561)\n",
      "pri_y_total shape :  (1200, 6)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "parties_classes = [\n",
    "    [0, 1, 2, 3, 4], \n",
    "    [0, 1, 4, 5], \n",
    "    [2, 3, 4],\n",
    "    [0, 2, 3],\n",
    "    [1, 2, 3, 5],\n",
    "    [0, 1, 3, 4, 2],\n",
    "    [0, 1, 2],\n",
    "    [0, 1, 2, 3, 5],\n",
    "    [0, 3, 4, 5], \n",
    "    [1, 2, 5]\n",
    "]\n",
    "noniid_models = [get_model(n_classes, input_shape, model_params ) for model_params in models_params] \n",
    "\n",
    "\n",
    "pri_x_list_noniid, pri_y_list_noniid, pri_x_total_noniid, pri_y_total_noniid  = split_dataset(x_train, y_train, samples_per_class = n_samples_per_class ,\\\n",
    "                                                                n_models = n_parties, include_classes = parties_classes, to_categorical = True) \n",
    "\n",
    "\n",
    "\n",
    "# print data shapes\n",
    "print('train_batches shape : ', x_train.shape)\n",
    "print('train_labels shape : ', y_train.shape)\n",
    "print('pub_data_batches shape : ', pub_x.shape)\n",
    "print('pub_data_labels shape : ', pub_y.shape)\n",
    "print('test_batches shape : ', x_test.shape)\n",
    "print('categorical test_labels shape : ', y_test_cat.shape)\n",
    "\n",
    "print(\"_____________________________________________\")\n",
    "for i in range(n_parties):\n",
    "  print('pri_x_total shape : ', pri_x_list_noniid[i].shape)\n",
    "  print('pri_y_total shape : ', pri_y_list_noniid[i].shape)\n",
    "print(\"_____________________________________________\")\n",
    "print('pri_x_total shape : ', pri_x_total_noniid.shape)\n",
    "print('pri_y_total shape : ', pri_y_total_noniid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 1s 75ms/step - loss: 1.8497 - accuracy: 0.2200 - val_loss: 1.7696 - val_accuracy: 0.1388\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.7067 - accuracy: 0.2300 - val_loss: 1.7208 - val_accuracy: 0.1479\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 1.6152 - accuracy: 0.2300 - val_loss: 1.6890 - val_accuracy: 0.1449\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 1.5766 - accuracy: 0.2000 - val_loss: 1.6730 - val_accuracy: 0.1422\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 1.5285 - accuracy: 0.2200 - val_loss: 1.6700 - val_accuracy: 0.1425\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 1.5202 - accuracy: 0.2000 - val_loss: 1.6654 - val_accuracy: 0.1425\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.4810 - accuracy: 0.2100 - val_loss: 1.6625 - val_accuracy: 0.1425\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.4680 - accuracy: 0.2100 - val_loss: 1.6594 - val_accuracy: 0.1425\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.4655 - accuracy: 0.2100 - val_loss: 1.6567 - val_accuracy: 0.1425\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 1.4272 - accuracy: 0.2200 - val_loss: 1.6616 - val_accuracy: 0.1425\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.4233 - accuracy: 0.2200 - val_loss: 1.6711 - val_accuracy: 0.1490\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.4011 - accuracy: 0.2300 - val_loss: 1.6764 - val_accuracy: 0.2793\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.3915 - accuracy: 0.3300 - val_loss: 1.6811 - val_accuracy: 0.3091\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 1.3963 - accuracy: 0.3700 - val_loss: 1.6827 - val_accuracy: 0.3146\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.3853 - accuracy: 0.3600 - val_loss: 1.6835 - val_accuracy: 0.3173\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.3732 - accuracy: 0.3600 - val_loss: 1.6839 - val_accuracy: 0.3203\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 1.3813 - accuracy: 0.3600 - val_loss: 1.6864 - val_accuracy: 0.3213\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.3510 - accuracy: 0.4400 - val_loss: 1.6917 - val_accuracy: 0.3213\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.3622 - accuracy: 0.3900 - val_loss: 1.7031 - val_accuracy: 0.3227\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.3392 - accuracy: 0.3700 - val_loss: 1.7145 - val_accuracy: 0.3210\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 117ms/step - loss: 1.8887 - accuracy: 0.0500 - val_loss: 1.8344 - val_accuracy: 0.1703\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 1.8602 - accuracy: 0.0875 - val_loss: 1.8344 - val_accuracy: 0.1700\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 1.8840 - accuracy: 0.1125 - val_loss: 1.8345 - val_accuracy: 0.1703\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 1.8875 - accuracy: 0.1250 - val_loss: 1.8345 - val_accuracy: 0.1700\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 1.8589 - accuracy: 0.0750 - val_loss: 1.8344 - val_accuracy: 0.1707\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 1.8632 - accuracy: 0.1000 - val_loss: 1.8343 - val_accuracy: 0.1700\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 1.8854 - accuracy: 0.0875 - val_loss: 1.8343 - val_accuracy: 0.1710\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 1.8879 - accuracy: 0.1000 - val_loss: 1.8342 - val_accuracy: 0.1707\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 1.8700 - accuracy: 0.1125 - val_loss: 1.8341 - val_accuracy: 0.1697\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 1.8559 - accuracy: 0.0875 - val_loss: 1.8340 - val_accuracy: 0.1693\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 1.9253 - accuracy: 0.0875 - val_loss: 1.8338 - val_accuracy: 0.1703\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 1.8428 - accuracy: 0.1125 - val_loss: 1.8337 - val_accuracy: 0.1700\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 1.9102 - accuracy: 0.0750 - val_loss: 1.8337 - val_accuracy: 0.1710\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 1.8759 - accuracy: 0.0875 - val_loss: 1.8337 - val_accuracy: 0.1686\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 1.8821 - accuracy: 0.0875 - val_loss: 1.8337 - val_accuracy: 0.1686\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 1.8540 - accuracy: 0.1500 - val_loss: 1.8336 - val_accuracy: 0.1686\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 1.8781 - accuracy: 0.1250 - val_loss: 1.8336 - val_accuracy: 0.1686\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 1.8662 - accuracy: 0.0625 - val_loss: 1.8335 - val_accuracy: 0.1680\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 1.8765 - accuracy: 0.1125 - val_loss: 1.8334 - val_accuracy: 0.1680\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 1.8570 - accuracy: 0.0500 - val_loss: 1.8334 - val_accuracy: 0.1676\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 237ms/step - loss: 1.9669 - accuracy: 0.0167 - val_loss: 1.9735 - val_accuracy: 0.0122\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 1.9985 - accuracy: 0.0000e+00 - val_loss: 1.9672 - val_accuracy: 0.0105\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 1.9502 - accuracy: 0.0333 - val_loss: 1.9617 - val_accuracy: 0.0078\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 1.9590 - accuracy: 0.0333 - val_loss: 1.9562 - val_accuracy: 0.0075\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 1.9253 - accuracy: 0.0000e+00 - val_loss: 1.9516 - val_accuracy: 0.0085\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 1.9079 - accuracy: 0.0167 - val_loss: 1.9473 - val_accuracy: 0.0075\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 1.9175 - accuracy: 0.0333 - val_loss: 1.9430 - val_accuracy: 0.0075\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 1.9078 - accuracy: 0.0167 - val_loss: 1.9390 - val_accuracy: 0.0068\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 1.8641 - accuracy: 0.0500 - val_loss: 1.9355 - val_accuracy: 0.0071\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 1.8722 - accuracy: 0.0500 - val_loss: 1.9324 - val_accuracy: 0.0078\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 1.8517 - accuracy: 0.0333 - val_loss: 1.9292 - val_accuracy: 0.0085\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 1.8394 - accuracy: 0.0333 - val_loss: 1.9265 - val_accuracy: 0.0088\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 1.8150 - accuracy: 0.0333 - val_loss: 1.9240 - val_accuracy: 0.0102\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 1.7914 - accuracy: 0.0500 - val_loss: 1.9216 - val_accuracy: 0.0143\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 1.7749 - accuracy: 0.0333 - val_loss: 1.9192 - val_accuracy: 0.0159\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 1.7687 - accuracy: 0.1000 - val_loss: 1.9168 - val_accuracy: 0.0224\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 1.7994 - accuracy: 0.0833 - val_loss: 1.9149 - val_accuracy: 0.0282\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 1.7708 - accuracy: 0.0667 - val_loss: 1.9132 - val_accuracy: 0.0339\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 1.7543 - accuracy: 0.1667 - val_loss: 1.9117 - val_accuracy: 0.0370\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 1.7225 - accuracy: 0.1500 - val_loss: 1.9102 - val_accuracy: 0.0451\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 240ms/step - loss: 1.6941 - accuracy: 0.2667 - val_loss: 1.8324 - val_accuracy: 0.3342\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 1.1595 - accuracy: 0.5833 - val_loss: 1.8813 - val_accuracy: 0.3784\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 0.8857 - accuracy: 0.7000 - val_loss: 1.9142 - val_accuracy: 0.4527\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.7498 - accuracy: 0.7833 - val_loss: 1.9498 - val_accuracy: 0.4564\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.6810 - accuracy: 0.7667 - val_loss: 1.9713 - val_accuracy: 0.5063\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.5885 - accuracy: 0.8500 - val_loss: 1.9863 - val_accuracy: 0.5209\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.5611 - accuracy: 0.8333 - val_loss: 2.0004 - val_accuracy: 0.5219\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 0.4768 - accuracy: 0.9333 - val_loss: 2.0021 - val_accuracy: 0.5215\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.4342 - accuracy: 0.9833 - val_loss: 1.9939 - val_accuracy: 0.5202\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.3998 - accuracy: 0.9833 - val_loss: 1.9789 - val_accuracy: 0.5199\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 0.3639 - accuracy: 1.0000 - val_loss: 1.9629 - val_accuracy: 0.5215\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.3299 - accuracy: 1.0000 - val_loss: 1.9501 - val_accuracy: 0.5226\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.3209 - accuracy: 0.9833 - val_loss: 1.9406 - val_accuracy: 0.5232\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.2992 - accuracy: 1.0000 - val_loss: 1.9311 - val_accuracy: 0.5215\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.2977 - accuracy: 1.0000 - val_loss: 1.9294 - val_accuracy: 0.5202\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.2581 - accuracy: 0.9667 - val_loss: 1.9316 - val_accuracy: 0.5202\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.2475 - accuracy: 1.0000 - val_loss: 1.9361 - val_accuracy: 0.5219\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.2040 - accuracy: 1.0000 - val_loss: 1.9402 - val_accuracy: 0.5226\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.1950 - accuracy: 1.0000 - val_loss: 1.9462 - val_accuracy: 0.5229\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.1786 - accuracy: 1.0000 - val_loss: 1.9532 - val_accuracy: 0.5236\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 126ms/step - loss: 1.7877 - accuracy: 0.1625 - val_loss: 1.8810 - val_accuracy: 0.1734\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 1.8078 - accuracy: 0.1125 - val_loss: 1.8783 - val_accuracy: 0.1761\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 1.8133 - accuracy: 0.1250 - val_loss: 1.8754 - val_accuracy: 0.1792\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 1.7850 - accuracy: 0.1500 - val_loss: 1.8727 - val_accuracy: 0.1795\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 1.8255 - accuracy: 0.1250 - val_loss: 1.8700 - val_accuracy: 0.1829\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 1.7793 - accuracy: 0.1625 - val_loss: 1.8677 - val_accuracy: 0.1839\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 1.7941 - accuracy: 0.1250 - val_loss: 1.8655 - val_accuracy: 0.1836\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 1.7626 - accuracy: 0.1250 - val_loss: 1.8631 - val_accuracy: 0.1826\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 1.7510 - accuracy: 0.1625 - val_loss: 1.8608 - val_accuracy: 0.1798\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 1.7491 - accuracy: 0.1250 - val_loss: 1.8586 - val_accuracy: 0.1815\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 1.6810 - accuracy: 0.2000 - val_loss: 1.8567 - val_accuracy: 0.1829\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 1.7440 - accuracy: 0.2000 - val_loss: 1.8546 - val_accuracy: 0.1829\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 1.7131 - accuracy: 0.2125 - val_loss: 1.8524 - val_accuracy: 0.1822\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 1.7097 - accuracy: 0.2250 - val_loss: 1.8508 - val_accuracy: 0.1863\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 1.7083 - accuracy: 0.1750 - val_loss: 1.8494 - val_accuracy: 0.1876\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 1.6928 - accuracy: 0.2250 - val_loss: 1.8478 - val_accuracy: 0.1863\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 1.7027 - accuracy: 0.1750 - val_loss: 1.8462 - val_accuracy: 0.1893\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 1.6949 - accuracy: 0.2250 - val_loss: 1.8447 - val_accuracy: 0.1890\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 1.6977 - accuracy: 0.2250 - val_loss: 1.8432 - val_accuracy: 0.1907\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 1.6886 - accuracy: 0.2000 - val_loss: 1.8416 - val_accuracy: 0.1900\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 1s 86ms/step - loss: 1.7287 - accuracy: 0.2100 - val_loss: 1.7628 - val_accuracy: 0.1656\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 1.7138 - accuracy: 0.2300 - val_loss: 1.7545 - val_accuracy: 0.1666\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 1.7050 - accuracy: 0.1800 - val_loss: 1.7474 - val_accuracy: 0.1659\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 1.6868 - accuracy: 0.1500 - val_loss: 1.7419 - val_accuracy: 0.1690\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 1.6703 - accuracy: 0.1900 - val_loss: 1.7340 - val_accuracy: 0.1761\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 1.6500 - accuracy: 0.2500 - val_loss: 1.7276 - val_accuracy: 0.1853\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 1.6677 - accuracy: 0.2300 - val_loss: 1.7232 - val_accuracy: 0.1904\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 1.6348 - accuracy: 0.2400 - val_loss: 1.7179 - val_accuracy: 0.2056\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 1.6158 - accuracy: 0.2300 - val_loss: 1.7122 - val_accuracy: 0.2331\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 1.6207 - accuracy: 0.2800 - val_loss: 1.7060 - val_accuracy: 0.2457\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 1.5749 - accuracy: 0.2900 - val_loss: 1.7016 - val_accuracy: 0.2582\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 1.5853 - accuracy: 0.2800 - val_loss: 1.6972 - val_accuracy: 0.2721\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 1.5952 - accuracy: 0.2600 - val_loss: 1.6924 - val_accuracy: 0.2782\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 1.5740 - accuracy: 0.3000 - val_loss: 1.6900 - val_accuracy: 0.2806\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 1.5419 - accuracy: 0.3000 - val_loss: 1.6857 - val_accuracy: 0.2942\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 1.5759 - accuracy: 0.2800 - val_loss: 1.6815 - val_accuracy: 0.3312\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 1.5251 - accuracy: 0.3200 - val_loss: 1.6780 - val_accuracy: 0.3546\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 1.5233 - accuracy: 0.3700 - val_loss: 1.6745 - val_accuracy: 0.3478\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 1.4806 - accuracy: 0.3900 - val_loss: 1.6706 - val_accuracy: 0.3604\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 1.4947 - accuracy: 0.3700 - val_loss: 1.6664 - val_accuracy: 0.3794\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 251ms/step - loss: 1.9060 - accuracy: 0.0667 - val_loss: 1.9421 - val_accuracy: 0.1449\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 1.9020 - accuracy: 0.0667 - val_loss: 1.9406 - val_accuracy: 0.1418\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 1.9033 - accuracy: 0.0333 - val_loss: 1.9395 - val_accuracy: 0.1381\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 123ms/step - loss: 1.8670 - accuracy: 0.1000 - val_loss: 1.9388 - val_accuracy: 0.1303\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 124ms/step - loss: 1.8546 - accuracy: 0.1333 - val_loss: 1.9383 - val_accuracy: 0.1191\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 1.8474 - accuracy: 0.1167 - val_loss: 1.9382 - val_accuracy: 0.1110\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 1.8337 - accuracy: 0.1167 - val_loss: 1.9383 - val_accuracy: 0.1011\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 123ms/step - loss: 1.7686 - accuracy: 0.2167 - val_loss: 1.9386 - val_accuracy: 0.0960\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 1.8259 - accuracy: 0.1833 - val_loss: 1.9391 - val_accuracy: 0.0913\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 1.7491 - accuracy: 0.1667 - val_loss: 1.9398 - val_accuracy: 0.0933\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 1.7483 - accuracy: 0.1833 - val_loss: 1.9409 - val_accuracy: 0.0991\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 1.7682 - accuracy: 0.2167 - val_loss: 1.9421 - val_accuracy: 0.0981\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 124ms/step - loss: 1.7236 - accuracy: 0.2333 - val_loss: 1.9435 - val_accuracy: 0.1055\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 1.7616 - accuracy: 0.1833 - val_loss: 1.9449 - val_accuracy: 0.1157\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 1.7057 - accuracy: 0.2000 - val_loss: 1.9467 - val_accuracy: 0.1272\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 124ms/step - loss: 1.7020 - accuracy: 0.2333 - val_loss: 1.9486 - val_accuracy: 0.1405\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 1.7322 - accuracy: 0.2000 - val_loss: 1.9507 - val_accuracy: 0.1493\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 122ms/step - loss: 1.6897 - accuracy: 0.2500 - val_loss: 1.9530 - val_accuracy: 0.1639\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 1.6806 - accuracy: 0.2833 - val_loss: 1.9554 - val_accuracy: 0.1737\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 123ms/step - loss: 1.7033 - accuracy: 0.2167 - val_loss: 1.9580 - val_accuracy: 0.1815\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 1s 103ms/step - loss: 1.7810 - accuracy: 0.3400 - val_loss: 1.8873 - val_accuracy: 0.3505\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 1.1182 - accuracy: 0.4300 - val_loss: 1.7189 - val_accuracy: 0.4343\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.9458 - accuracy: 0.5900 - val_loss: 1.9255 - val_accuracy: 0.3400\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.8719 - accuracy: 0.5700 - val_loss: 2.0304 - val_accuracy: 0.3407\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.8683 - accuracy: 0.5000 - val_loss: 1.8500 - val_accuracy: 0.5154\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.6846 - accuracy: 0.7300 - val_loss: 1.5793 - val_accuracy: 0.6026\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.5580 - accuracy: 0.7400 - val_loss: 1.7485 - val_accuracy: 0.5660\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 0.6521 - accuracy: 0.6800 - val_loss: 1.6677 - val_accuracy: 0.6162\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.5191 - accuracy: 0.8300 - val_loss: 1.7045 - val_accuracy: 0.5867\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.7121 - accuracy: 0.6700 - val_loss: 1.5155 - val_accuracy: 0.6583\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 0.4681 - accuracy: 0.7800 - val_loss: 1.9360 - val_accuracy: 0.5087\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.5974 - accuracy: 0.7200 - val_loss: 1.9737 - val_accuracy: 0.5504\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.6018 - accuracy: 0.7200 - val_loss: 1.5233 - val_accuracy: 0.6851\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 0.4022 - accuracy: 0.8100 - val_loss: 1.6589 - val_accuracy: 0.6739\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.3045 - accuracy: 0.9000 - val_loss: 1.8651 - val_accuracy: 0.6651\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 0.4444 - accuracy: 0.7800 - val_loss: 2.1664 - val_accuracy: 0.5151\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.3850 - accuracy: 0.8500 - val_loss: 1.6532 - val_accuracy: 0.7238\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 0.3319 - accuracy: 0.8600 - val_loss: 2.3107 - val_accuracy: 0.5107\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.5027 - accuracy: 0.7800 - val_loss: 2.8323 - val_accuracy: 0.5199\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.5119 - accuracy: 0.8400 - val_loss: 1.7077 - val_accuracy: 0.6658\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 161ms/step - loss: 1.9472 - accuracy: 0.0625 - val_loss: 1.8431 - val_accuracy: 0.1673\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 1.8147 - accuracy: 0.2250 - val_loss: 1.8265 - val_accuracy: 0.1978\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 1.7164 - accuracy: 0.3250 - val_loss: 1.8142 - val_accuracy: 0.2097\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 1.7401 - accuracy: 0.2375 - val_loss: 1.8038 - val_accuracy: 0.2094\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 1.6769 - accuracy: 0.3000 - val_loss: 1.7957 - val_accuracy: 0.2070\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 1.6575 - accuracy: 0.2875 - val_loss: 1.7871 - val_accuracy: 0.2097\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 1.6104 - accuracy: 0.3375 - val_loss: 1.7829 - val_accuracy: 0.2087\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 1.5858 - accuracy: 0.3250 - val_loss: 1.7769 - val_accuracy: 0.2168\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 1.5748 - accuracy: 0.3250 - val_loss: 1.7706 - val_accuracy: 0.2209\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 1.5531 - accuracy: 0.3375 - val_loss: 1.7654 - val_accuracy: 0.2273\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 1.5468 - accuracy: 0.2750 - val_loss: 1.7603 - val_accuracy: 0.2270\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 1.5029 - accuracy: 0.2750 - val_loss: 1.7576 - val_accuracy: 0.2287\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 1.4248 - accuracy: 0.3500 - val_loss: 1.7555 - val_accuracy: 0.2341\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 1.4411 - accuracy: 0.3500 - val_loss: 1.7545 - val_accuracy: 0.2345\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 1.3964 - accuracy: 0.4375 - val_loss: 1.7526 - val_accuracy: 0.2555\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 1.4373 - accuracy: 0.3875 - val_loss: 1.7496 - val_accuracy: 0.2738\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 1.4153 - accuracy: 0.3125 - val_loss: 1.7485 - val_accuracy: 0.2935\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 1.3950 - accuracy: 0.4000 - val_loss: 1.7466 - val_accuracy: 0.3146\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 1.3516 - accuracy: 0.4125 - val_loss: 1.7449 - val_accuracy: 0.3342\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 1.3208 - accuracy: 0.4875 - val_loss: 1.7451 - val_accuracy: 0.3458\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 359ms/step - loss: 1.4479 - accuracy: 0.4500 - val_loss: 2.0823 - val_accuracy: 0.2844\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 208ms/step - loss: 1.0519 - accuracy: 0.6167 - val_loss: 2.1560 - val_accuracy: 0.2949\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 207ms/step - loss: 0.9360 - accuracy: 0.6000 - val_loss: 2.2321 - val_accuracy: 0.3132\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 211ms/step - loss: 0.7900 - accuracy: 0.7000 - val_loss: 2.3254 - val_accuracy: 0.3237\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 206ms/step - loss: 0.7643 - accuracy: 0.6167 - val_loss: 2.4598 - val_accuracy: 0.3342\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 207ms/step - loss: 0.7182 - accuracy: 0.6667 - val_loss: 2.5650 - val_accuracy: 0.3502\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 210ms/step - loss: 0.6779 - accuracy: 0.7000 - val_loss: 2.6708 - val_accuracy: 0.3278\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 204ms/step - loss: 0.6423 - accuracy: 0.7167 - val_loss: 2.7285 - val_accuracy: 0.3631\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 208ms/step - loss: 0.6298 - accuracy: 0.7000 - val_loss: 2.8363 - val_accuracy: 0.3349\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 211ms/step - loss: 0.5843 - accuracy: 0.7167 - val_loss: 2.9126 - val_accuracy: 0.3410\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 210ms/step - loss: 0.5174 - accuracy: 0.7500 - val_loss: 2.9575 - val_accuracy: 0.3787\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 208ms/step - loss: 0.5224 - accuracy: 0.8167 - val_loss: 3.0233 - val_accuracy: 0.3933\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 209ms/step - loss: 0.5302 - accuracy: 0.7500 - val_loss: 3.0915 - val_accuracy: 0.3892\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 209ms/step - loss: 0.5181 - accuracy: 0.7167 - val_loss: 3.1681 - val_accuracy: 0.4004\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 209ms/step - loss: 0.4336 - accuracy: 0.9000 - val_loss: 3.2485 - val_accuracy: 0.3957\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 211ms/step - loss: 0.4634 - accuracy: 0.8167 - val_loss: 3.2990 - val_accuracy: 0.3933\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 207ms/step - loss: 0.4153 - accuracy: 0.8000 - val_loss: 3.3990 - val_accuracy: 0.3811\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 210ms/step - loss: 0.4518 - accuracy: 0.7833 - val_loss: 3.4722 - val_accuracy: 0.4130\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 209ms/step - loss: 0.4383 - accuracy: 0.7667 - val_loss: 3.5360 - val_accuracy: 0.4052\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 204ms/step - loss: 0.3840 - accuracy: 0.9167 - val_loss: 3.5995 - val_accuracy: 0.4150\n",
      "Epoch 1/20\n",
      "38/38 [==============================] - 1s 8ms/step - loss: 2.0129 - accuracy: 0.1708 - val_loss: 2.0041 - val_accuracy: 0.1900\n",
      "Epoch 2/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.0163 - accuracy: 0.1633 - val_loss: 2.0028 - val_accuracy: 0.1900\n",
      "Epoch 3/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.0064 - accuracy: 0.1725 - val_loss: 2.0015 - val_accuracy: 0.1897\n",
      "Epoch 4/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.0091 - accuracy: 0.1842 - val_loss: 2.0002 - val_accuracy: 0.1897\n",
      "Epoch 5/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.0086 - accuracy: 0.1658 - val_loss: 1.9989 - val_accuracy: 0.1897\n",
      "Epoch 6/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.9980 - accuracy: 0.1667 - val_loss: 1.9976 - val_accuracy: 0.1897\n",
      "Epoch 7/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.9997 - accuracy: 0.1650 - val_loss: 1.9963 - val_accuracy: 0.1897\n",
      "Epoch 8/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.0090 - accuracy: 0.1617 - val_loss: 1.9951 - val_accuracy: 0.1897\n",
      "Epoch 9/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.0005 - accuracy: 0.1725 - val_loss: 1.9938 - val_accuracy: 0.1897\n",
      "Epoch 10/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.0011 - accuracy: 0.1667 - val_loss: 1.9927 - val_accuracy: 0.1897\n",
      "Epoch 11/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.9985 - accuracy: 0.1675 - val_loss: 1.9915 - val_accuracy: 0.1897\n",
      "Epoch 12/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.9971 - accuracy: 0.1683 - val_loss: 1.9903 - val_accuracy: 0.1897\n",
      "Epoch 13/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.9964 - accuracy: 0.1775 - val_loss: 1.9891 - val_accuracy: 0.1897\n",
      "Epoch 14/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.9977 - accuracy: 0.1733 - val_loss: 1.9879 - val_accuracy: 0.1897\n",
      "Epoch 15/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.0005 - accuracy: 0.1658 - val_loss: 1.9867 - val_accuracy: 0.1897\n",
      "Epoch 16/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.9886 - accuracy: 0.1700 - val_loss: 1.9856 - val_accuracy: 0.1897\n",
      "Epoch 17/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.9906 - accuracy: 0.1683 - val_loss: 1.9845 - val_accuracy: 0.1890\n",
      "Epoch 18/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.9834 - accuracy: 0.1650 - val_loss: 1.9834 - val_accuracy: 0.1890\n",
      "Epoch 19/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.0030 - accuracy: 0.1558 - val_loss: 1.9823 - val_accuracy: 0.1887\n",
      "Epoch 20/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.9822 - accuracy: 0.1692 - val_loss: 1.9812 - val_accuracy: 0.1880\n",
      "Epoch 1/20\n",
      "38/38 [==============================] - 1s 8ms/step - loss: 1.8465 - accuracy: 0.1675 - val_loss: 1.7494 - val_accuracy: 0.1802\n",
      "Epoch 2/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.7552 - accuracy: 0.2025 - val_loss: 1.7090 - val_accuracy: 0.2816\n",
      "Epoch 3/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.7142 - accuracy: 0.2392 - val_loss: 1.6802 - val_accuracy: 0.2769\n",
      "Epoch 4/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.6812 - accuracy: 0.2583 - val_loss: 1.6508 - val_accuracy: 0.3142\n",
      "Epoch 5/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.6724 - accuracy: 0.2492 - val_loss: 1.6264 - val_accuracy: 0.3023\n",
      "Epoch 6/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.6392 - accuracy: 0.2717 - val_loss: 1.6000 - val_accuracy: 0.3186\n",
      "Epoch 7/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.6278 - accuracy: 0.2542 - val_loss: 1.5764 - val_accuracy: 0.3332\n",
      "Epoch 8/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.5970 - accuracy: 0.3000 - val_loss: 1.5501 - val_accuracy: 0.3302\n",
      "Epoch 9/20\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.5717 - accuracy: 0.2983 - val_loss: 1.5270 - val_accuracy: 0.3376\n",
      "Epoch 10/20\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.5655 - accuracy: 0.2983 - val_loss: 1.5042 - val_accuracy: 0.3505\n",
      "Epoch 11/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.5487 - accuracy: 0.3108 - val_loss: 1.4848 - val_accuracy: 0.3529\n",
      "Epoch 12/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.5225 - accuracy: 0.3125 - val_loss: 1.4630 - val_accuracy: 0.3587\n",
      "Epoch 13/20\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.5082 - accuracy: 0.3283 - val_loss: 1.4404 - val_accuracy: 0.3695\n",
      "Epoch 14/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.4934 - accuracy: 0.3283 - val_loss: 1.4204 - val_accuracy: 0.3784\n",
      "Epoch 15/20\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.4616 - accuracy: 0.3625 - val_loss: 1.3982 - val_accuracy: 0.3909\n",
      "Epoch 16/20\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.4635 - accuracy: 0.3425 - val_loss: 1.3812 - val_accuracy: 0.4045\n",
      "Epoch 17/20\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.4296 - accuracy: 0.3792 - val_loss: 1.3600 - val_accuracy: 0.4279\n",
      "Epoch 18/20\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.4037 - accuracy: 0.3900 - val_loss: 1.3379 - val_accuracy: 0.4493\n",
      "Epoch 19/20\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.3855 - accuracy: 0.4083 - val_loss: 1.3178 - val_accuracy: 0.4866\n",
      "Epoch 20/20\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.3813 - accuracy: 0.4258 - val_loss: 1.2986 - val_accuracy: 0.4995\n",
      "Epoch 1/20\n",
      "38/38 [==============================] - 1s 7ms/step - loss: 1.7913 - accuracy: 0.1883 - val_loss: 1.7473 - val_accuracy: 0.1951\n",
      "Epoch 2/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.7426 - accuracy: 0.2167 - val_loss: 1.6970 - val_accuracy: 0.2562\n",
      "Epoch 3/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.7067 - accuracy: 0.2533 - val_loss: 1.6550 - val_accuracy: 0.3186\n",
      "Epoch 4/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.6646 - accuracy: 0.2858 - val_loss: 1.6204 - val_accuracy: 0.3370\n",
      "Epoch 5/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.6378 - accuracy: 0.3017 - val_loss: 1.5923 - val_accuracy: 0.3441\n",
      "Epoch 6/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.6131 - accuracy: 0.3142 - val_loss: 1.5681 - val_accuracy: 0.3485\n",
      "Epoch 7/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.5926 - accuracy: 0.3300 - val_loss: 1.5478 - val_accuracy: 0.3526\n",
      "Epoch 8/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.5685 - accuracy: 0.3333 - val_loss: 1.5297 - val_accuracy: 0.3597\n",
      "Epoch 9/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.5496 - accuracy: 0.3467 - val_loss: 1.5127 - val_accuracy: 0.3631\n",
      "Epoch 10/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.5390 - accuracy: 0.3442 - val_loss: 1.4969 - val_accuracy: 0.3726\n",
      "Epoch 11/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.5143 - accuracy: 0.3783 - val_loss: 1.4819 - val_accuracy: 0.3824\n",
      "Epoch 12/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.4963 - accuracy: 0.3742 - val_loss: 1.4681 - val_accuracy: 0.3889\n",
      "Epoch 13/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.4776 - accuracy: 0.3692 - val_loss: 1.4549 - val_accuracy: 0.4096\n",
      "Epoch 14/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.4678 - accuracy: 0.3833 - val_loss: 1.4432 - val_accuracy: 0.4231\n",
      "Epoch 15/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.4653 - accuracy: 0.3683 - val_loss: 1.4321 - val_accuracy: 0.4408\n",
      "Epoch 16/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.4542 - accuracy: 0.3808 - val_loss: 1.4220 - val_accuracy: 0.4459\n",
      "Epoch 17/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.4395 - accuracy: 0.3933 - val_loss: 1.4123 - val_accuracy: 0.4496\n",
      "Epoch 18/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.4261 - accuracy: 0.4042 - val_loss: 1.4033 - val_accuracy: 0.4503\n",
      "Epoch 19/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.4176 - accuracy: 0.4125 - val_loss: 1.3947 - val_accuracy: 0.4493\n",
      "Epoch 20/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.4111 - accuracy: 0.3925 - val_loss: 1.3865 - val_accuracy: 0.4438\n",
      "Epoch 1/20\n",
      "38/38 [==============================] - 1s 8ms/step - loss: 1.5081 - accuracy: 0.3625 - val_loss: 1.3303 - val_accuracy: 0.5674\n",
      "Epoch 2/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.2550 - accuracy: 0.5242 - val_loss: 1.1769 - val_accuracy: 0.6169\n",
      "Epoch 3/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.1371 - accuracy: 0.5958 - val_loss: 1.0790 - val_accuracy: 0.6977\n",
      "Epoch 4/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.0500 - accuracy: 0.6675 - val_loss: 1.0132 - val_accuracy: 0.7462\n",
      "Epoch 5/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.9830 - accuracy: 0.7183 - val_loss: 0.9560 - val_accuracy: 0.7703\n",
      "Epoch 6/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.9198 - accuracy: 0.7558 - val_loss: 0.9151 - val_accuracy: 0.8076\n",
      "Epoch 7/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.8723 - accuracy: 0.7850 - val_loss: 0.8639 - val_accuracy: 0.7811\n",
      "Epoch 8/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.8210 - accuracy: 0.8092 - val_loss: 0.8197 - val_accuracy: 0.8117\n",
      "Epoch 9/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.7815 - accuracy: 0.8242 - val_loss: 0.7859 - val_accuracy: 0.8344\n",
      "Epoch 10/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.7386 - accuracy: 0.8533 - val_loss: 0.7433 - val_accuracy: 0.8249\n",
      "Epoch 11/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6997 - accuracy: 0.8383 - val_loss: 0.7166 - val_accuracy: 0.8609\n",
      "Epoch 12/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6622 - accuracy: 0.8608 - val_loss: 0.6863 - val_accuracy: 0.8422\n",
      "Epoch 13/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.6287 - accuracy: 0.8683 - val_loss: 0.6522 - val_accuracy: 0.8554\n",
      "Epoch 14/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6045 - accuracy: 0.8792 - val_loss: 0.6278 - val_accuracy: 0.8395\n",
      "Epoch 15/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.5765 - accuracy: 0.8842 - val_loss: 0.6123 - val_accuracy: 0.8341\n",
      "Epoch 16/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.5527 - accuracy: 0.8817 - val_loss: 0.5764 - val_accuracy: 0.8694\n",
      "Epoch 17/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.5316 - accuracy: 0.8933 - val_loss: 0.5608 - val_accuracy: 0.8714\n",
      "Epoch 18/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.5060 - accuracy: 0.8958 - val_loss: 0.5391 - val_accuracy: 0.8778\n",
      "Epoch 19/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4848 - accuracy: 0.8975 - val_loss: 0.5261 - val_accuracy: 0.8483\n",
      "Epoch 20/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4684 - accuracy: 0.8983 - val_loss: 0.5076 - val_accuracy: 0.8609\n",
      "Epoch 1/20\n",
      "38/38 [==============================] - 1s 8ms/step - loss: 0.9443 - accuracy: 0.6192 - val_loss: 0.6333 - val_accuracy: 0.6766\n",
      "Epoch 2/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4589 - accuracy: 0.8283 - val_loss: 0.4717 - val_accuracy: 0.7794\n",
      "Epoch 3/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3607 - accuracy: 0.8492 - val_loss: 0.3326 - val_accuracy: 0.8704\n",
      "Epoch 4/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2592 - accuracy: 0.9025 - val_loss: 0.3303 - val_accuracy: 0.8527\n",
      "Epoch 5/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2074 - accuracy: 0.9142 - val_loss: 0.2828 - val_accuracy: 0.8802\n",
      "Epoch 6/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2030 - accuracy: 0.9275 - val_loss: 0.2428 - val_accuracy: 0.9009\n",
      "Epoch 7/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1514 - accuracy: 0.9467 - val_loss: 0.3188 - val_accuracy: 0.8680\n",
      "Epoch 8/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1368 - accuracy: 0.9475 - val_loss: 0.2073 - val_accuracy: 0.9179\n",
      "Epoch 9/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1508 - accuracy: 0.9358 - val_loss: 0.2437 - val_accuracy: 0.9104\n",
      "Epoch 10/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1204 - accuracy: 0.9567 - val_loss: 0.2270 - val_accuracy: 0.9080\n",
      "Epoch 11/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1001 - accuracy: 0.9633 - val_loss: 0.2627 - val_accuracy: 0.8975\n",
      "Epoch 12/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0863 - accuracy: 0.9742 - val_loss: 0.2476 - val_accuracy: 0.8982\n",
      "Epoch 13/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0973 - accuracy: 0.9683 - val_loss: 0.2199 - val_accuracy: 0.9182\n",
      "Epoch 14/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0889 - accuracy: 0.9692 - val_loss: 0.2288 - val_accuracy: 0.9125\n",
      "Epoch 15/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0623 - accuracy: 0.9800 - val_loss: 0.2336 - val_accuracy: 0.9169\n",
      "Epoch 16/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0654 - accuracy: 0.9742 - val_loss: 0.2275 - val_accuracy: 0.9203\n",
      "Epoch 17/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0578 - accuracy: 0.9808 - val_loss: 0.3027 - val_accuracy: 0.9013\n",
      "Epoch 18/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0581 - accuracy: 0.9792 - val_loss: 0.2168 - val_accuracy: 0.9274\n",
      "Epoch 19/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0465 - accuracy: 0.9858 - val_loss: 0.3587 - val_accuracy: 0.8884\n",
      "Epoch 20/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0524 - accuracy: 0.9825 - val_loss: 0.3426 - val_accuracy: 0.8870\n",
      "Epoch 1/20\n",
      "38/38 [==============================] - 1s 8ms/step - loss: 1.0005 - accuracy: 0.5850 - val_loss: 0.6204 - val_accuracy: 0.7818\n",
      "Epoch 2/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4761 - accuracy: 0.8258 - val_loss: 0.3746 - val_accuracy: 0.8741\n",
      "Epoch 3/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3109 - accuracy: 0.8825 - val_loss: 0.2976 - val_accuracy: 0.8921\n",
      "Epoch 4/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2342 - accuracy: 0.9175 - val_loss: 0.3690 - val_accuracy: 0.8419\n",
      "Epoch 5/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2274 - accuracy: 0.9100 - val_loss: 0.2943 - val_accuracy: 0.8880\n",
      "Epoch 6/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1756 - accuracy: 0.9433 - val_loss: 0.2240 - val_accuracy: 0.9131\n",
      "Epoch 7/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1568 - accuracy: 0.9433 - val_loss: 0.2138 - val_accuracy: 0.9111\n",
      "Epoch 8/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1377 - accuracy: 0.9517 - val_loss: 0.2076 - val_accuracy: 0.9145\n",
      "Epoch 9/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1154 - accuracy: 0.9592 - val_loss: 0.2173 - val_accuracy: 0.9158\n",
      "Epoch 10/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1084 - accuracy: 0.9625 - val_loss: 0.2221 - val_accuracy: 0.9189\n",
      "Epoch 11/20\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0835 - accuracy: 0.9742 - val_loss: 0.2357 - val_accuracy: 0.9094\n",
      "Epoch 12/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1221 - accuracy: 0.9508 - val_loss: 0.2031 - val_accuracy: 0.9230\n",
      "Epoch 13/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0996 - accuracy: 0.9633 - val_loss: 0.2228 - val_accuracy: 0.9216\n",
      "Epoch 14/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0717 - accuracy: 0.9758 - val_loss: 0.2218 - val_accuracy: 0.9175\n",
      "Epoch 15/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0938 - accuracy: 0.9617 - val_loss: 0.6918 - val_accuracy: 0.7805\n",
      "Epoch 16/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1327 - accuracy: 0.9508 - val_loss: 0.2095 - val_accuracy: 0.9277\n",
      "Epoch 17/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0811 - accuracy: 0.9717 - val_loss: 0.2447 - val_accuracy: 0.9135\n",
      "Epoch 18/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0991 - accuracy: 0.9708 - val_loss: 0.3621 - val_accuracy: 0.8846\n",
      "Epoch 19/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0932 - accuracy: 0.9633 - val_loss: 0.2218 - val_accuracy: 0.9253\n",
      "Epoch 20/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0429 - accuracy: 0.9850 - val_loss: 0.2146 - val_accuracy: 0.9260\n",
      "Epoch 1/20\n",
      "38/38 [==============================] - 1s 9ms/step - loss: 1.9246 - accuracy: 0.1183 - val_loss: 1.8780 - val_accuracy: 0.0540\n",
      "Epoch 2/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.9249 - accuracy: 0.0958 - val_loss: 1.8769 - val_accuracy: 0.0550\n",
      "Epoch 3/20\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 1.9261 - accuracy: 0.1042 - val_loss: 1.8759 - val_accuracy: 0.0556\n",
      "Epoch 4/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.9304 - accuracy: 0.1108 - val_loss: 1.8748 - val_accuracy: 0.0570\n",
      "Epoch 5/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.9123 - accuracy: 0.1258 - val_loss: 1.8738 - val_accuracy: 0.0584\n",
      "Epoch 6/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.9093 - accuracy: 0.1200 - val_loss: 1.8727 - val_accuracy: 0.0604\n",
      "Epoch 7/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.9097 - accuracy: 0.1058 - val_loss: 1.8717 - val_accuracy: 0.0611\n",
      "Epoch 8/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.9168 - accuracy: 0.1225 - val_loss: 1.8707 - val_accuracy: 0.0618\n",
      "Epoch 9/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.9215 - accuracy: 0.1167 - val_loss: 1.8696 - val_accuracy: 0.0631\n",
      "Epoch 10/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.9157 - accuracy: 0.1050 - val_loss: 1.8686 - val_accuracy: 0.0648\n",
      "Epoch 11/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.8969 - accuracy: 0.1250 - val_loss: 1.8676 - val_accuracy: 0.0668\n",
      "Epoch 12/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.9074 - accuracy: 0.1192 - val_loss: 1.8666 - val_accuracy: 0.0679\n",
      "Epoch 13/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.9124 - accuracy: 0.1258 - val_loss: 1.8656 - val_accuracy: 0.0699\n",
      "Epoch 14/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.9148 - accuracy: 0.1150 - val_loss: 1.8645 - val_accuracy: 0.0706\n",
      "Epoch 15/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.8927 - accuracy: 0.1433 - val_loss: 1.8635 - val_accuracy: 0.0726\n",
      "Epoch 16/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.9158 - accuracy: 0.1192 - val_loss: 1.8625 - val_accuracy: 0.0733\n",
      "Epoch 17/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.9049 - accuracy: 0.1342 - val_loss: 1.8615 - val_accuracy: 0.0757\n",
      "Epoch 18/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.9081 - accuracy: 0.1192 - val_loss: 1.8605 - val_accuracy: 0.0770\n",
      "Epoch 19/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.9094 - accuracy: 0.1158 - val_loss: 1.8595 - val_accuracy: 0.0794\n",
      "Epoch 20/20\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.9035 - accuracy: 0.1192 - val_loss: 1.8585 - val_accuracy: 0.0797\n",
      "Epoch 1/20\n",
      "38/38 [==============================] - 1s 11ms/step - loss: 1.2907 - accuracy: 0.4883 - val_loss: 0.9927 - val_accuracy: 0.6698\n",
      "Epoch 2/20\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.8594 - accuracy: 0.7267 - val_loss: 0.7565 - val_accuracy: 0.8229\n",
      "Epoch 3/20\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.6698 - accuracy: 0.8208 - val_loss: 0.6363 - val_accuracy: 0.8344\n",
      "Epoch 4/20\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.5617 - accuracy: 0.8467 - val_loss: 0.5396 - val_accuracy: 0.8442\n",
      "Epoch 5/20\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.4848 - accuracy: 0.8600 - val_loss: 0.4756 - val_accuracy: 0.8738\n",
      "Epoch 6/20\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.4144 - accuracy: 0.8858 - val_loss: 0.4416 - val_accuracy: 0.8588\n",
      "Epoch 7/20\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3645 - accuracy: 0.9000 - val_loss: 0.3933 - val_accuracy: 0.8755\n",
      "Epoch 8/20\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3362 - accuracy: 0.9117 - val_loss: 0.3592 - val_accuracy: 0.8948\n",
      "Epoch 9/20\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3047 - accuracy: 0.9117 - val_loss: 0.3436 - val_accuracy: 0.8873\n",
      "Epoch 10/20\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2739 - accuracy: 0.9250 - val_loss: 0.3135 - val_accuracy: 0.9046\n",
      "Epoch 11/20\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2516 - accuracy: 0.9300 - val_loss: 0.2945 - val_accuracy: 0.9128\n",
      "Epoch 12/20\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2399 - accuracy: 0.9292 - val_loss: 0.2907 - val_accuracy: 0.9019\n",
      "Epoch 13/20\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2274 - accuracy: 0.9258 - val_loss: 0.2650 - val_accuracy: 0.9158\n",
      "Epoch 14/20\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2088 - accuracy: 0.9392 - val_loss: 0.2625 - val_accuracy: 0.9131\n",
      "Epoch 15/20\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1985 - accuracy: 0.9425 - val_loss: 0.2663 - val_accuracy: 0.8999\n",
      "Epoch 16/20\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1815 - accuracy: 0.9500 - val_loss: 0.2360 - val_accuracy: 0.9203\n",
      "Epoch 17/20\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1769 - accuracy: 0.9483 - val_loss: 0.2364 - val_accuracy: 0.9223\n",
      "Epoch 18/20\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1730 - accuracy: 0.9442 - val_loss: 0.2385 - val_accuracy: 0.9114\n",
      "Epoch 19/20\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1635 - accuracy: 0.9508 - val_loss: 0.2194 - val_accuracy: 0.9264\n",
      "Epoch 20/20\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1579 - accuracy: 0.9517 - val_loss: 0.2237 - val_accuracy: 0.9277\n",
      "Epoch 1/20\n",
      "38/38 [==============================] - 1s 11ms/step - loss: 1.8091 - accuracy: 0.1800 - val_loss: 1.7165 - val_accuracy: 0.2338\n",
      "Epoch 2/20\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 1.6824 - accuracy: 0.3050 - val_loss: 1.6225 - val_accuracy: 0.3929\n",
      "Epoch 3/20\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 1.5874 - accuracy: 0.3708 - val_loss: 1.5433 - val_accuracy: 0.4622\n",
      "Epoch 4/20\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 1.5022 - accuracy: 0.4483 - val_loss: 1.4698 - val_accuracy: 0.5324\n",
      "Epoch 5/20\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 1.4280 - accuracy: 0.4983 - val_loss: 1.4011 - val_accuracy: 0.6077\n",
      "Epoch 6/20\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 1.3548 - accuracy: 0.5625 - val_loss: 1.3358 - val_accuracy: 0.6651\n",
      "Epoch 7/20\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 1.2914 - accuracy: 0.6017 - val_loss: 1.2768 - val_accuracy: 0.7106\n",
      "Epoch 8/20\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 1.2283 - accuracy: 0.6483 - val_loss: 1.2236 - val_accuracy: 0.7370\n",
      "Epoch 9/20\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 1.1812 - accuracy: 0.6842 - val_loss: 1.1762 - val_accuracy: 0.7720\n",
      "Epoch 10/20\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 1.1362 - accuracy: 0.6925 - val_loss: 1.1343 - val_accuracy: 0.7978\n",
      "Epoch 11/20\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 1.0903 - accuracy: 0.7033 - val_loss: 1.0966 - val_accuracy: 0.8073\n",
      "Epoch 12/20\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 1.0533 - accuracy: 0.7450 - val_loss: 1.0618 - val_accuracy: 0.8110\n",
      "Epoch 13/20\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 1.0158 - accuracy: 0.7425 - val_loss: 1.0303 - val_accuracy: 0.8140\n",
      "Epoch 14/20\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.9955 - accuracy: 0.7383 - val_loss: 1.0025 - val_accuracy: 0.8256\n",
      "Epoch 15/20\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.9588 - accuracy: 0.7908 - val_loss: 0.9768 - val_accuracy: 0.8219\n",
      "Epoch 16/20\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.9429 - accuracy: 0.7583 - val_loss: 0.9527 - val_accuracy: 0.8283\n",
      "Epoch 17/20\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.9175 - accuracy: 0.7725 - val_loss: 0.9296 - val_accuracy: 0.8297\n",
      "Epoch 18/20\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.8848 - accuracy: 0.8192 - val_loss: 0.9084 - val_accuracy: 0.8337\n",
      "Epoch 19/20\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.8691 - accuracy: 0.8000 - val_loss: 0.8880 - val_accuracy: 0.8378\n",
      "Epoch 20/20\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.8559 - accuracy: 0.7917 - val_loss: 0.8690 - val_accuracy: 0.8344\n",
      "Epoch 1/20\n",
      "38/38 [==============================] - 1s 12ms/step - loss: 1.4094 - accuracy: 0.4333 - val_loss: 1.0105 - val_accuracy: 0.7587\n",
      "Epoch 2/20\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.8850 - accuracy: 0.7117 - val_loss: 0.7510 - val_accuracy: 0.8395\n",
      "Epoch 3/20\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.7016 - accuracy: 0.7917 - val_loss: 0.6244 - val_accuracy: 0.8405\n",
      "Epoch 4/20\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.5879 - accuracy: 0.8083 - val_loss: 0.5488 - val_accuracy: 0.8168\n",
      "Epoch 5/20\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.5158 - accuracy: 0.8358 - val_loss: 0.4800 - val_accuracy: 0.8690\n",
      "Epoch 6/20\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.4438 - accuracy: 0.8642 - val_loss: 0.4202 - val_accuracy: 0.8904\n",
      "Epoch 7/20\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.4018 - accuracy: 0.8750 - val_loss: 0.3857 - val_accuracy: 0.8890\n",
      "Epoch 8/20\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3528 - accuracy: 0.9058 - val_loss: 0.3831 - val_accuracy: 0.8663\n",
      "Epoch 9/20\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3321 - accuracy: 0.8975 - val_loss: 0.3666 - val_accuracy: 0.8687\n",
      "Epoch 10/20\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3031 - accuracy: 0.9000 - val_loss: 0.3511 - val_accuracy: 0.8809\n",
      "Epoch 11/20\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2863 - accuracy: 0.9042 - val_loss: 0.3026 - val_accuracy: 0.8989\n",
      "Epoch 12/20\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2706 - accuracy: 0.9133 - val_loss: 0.3005 - val_accuracy: 0.8938\n",
      "Epoch 13/20\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2461 - accuracy: 0.9275 - val_loss: 0.2838 - val_accuracy: 0.9019\n",
      "Epoch 14/20\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2263 - accuracy: 0.9292 - val_loss: 0.2639 - val_accuracy: 0.9138\n",
      "Epoch 15/20\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2194 - accuracy: 0.9308 - val_loss: 0.2583 - val_accuracy: 0.9080\n",
      "Epoch 16/20\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2131 - accuracy: 0.9325 - val_loss: 0.2550 - val_accuracy: 0.9074\n",
      "Epoch 17/20\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1965 - accuracy: 0.9392 - val_loss: 0.2373 - val_accuracy: 0.9179\n",
      "Epoch 18/20\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1882 - accuracy: 0.9367 - val_loss: 0.2401 - val_accuracy: 0.9108\n",
      "Epoch 19/20\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1926 - accuracy: 0.9383 - val_loss: 0.2297 - val_accuracy: 0.9233\n",
      "Epoch 20/20\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1675 - accuracy: 0.9425 - val_loss: 0.2239 - val_accuracy: 0.9206\n"
     ]
    }
   ],
   "source": [
    "# Train on own private dataset only\n",
    "local_models = [get_model(n_classes, input_shape, model_params )[0] for model_params in models_params] \n",
    "for i, model in enumerate(local_models) : \n",
    "    local_training_history = model.fit(pri_x_list_noniid[i], pri_y_list_noniid[i], validation_data = (x_test, y_test_cat), epochs = 20, verbose = True)\n",
    "    pd.DataFrame(local_training_history.history).to_csv(os.path.join(experiment_dir, 'local_train_noniid', 'local_training_{}.csv'.format(i)))\n",
    "\n",
    "# Training a model on all distributed dataset (centralized training). \n",
    "centralized_models = [get_model(n_classes, input_shape, model_params )[0] for model_params in models_params] \n",
    "for i, model in enumerate(centralized_models) : \n",
    "    centralized_training_history = model.fit(pri_x_total_noniid, pri_y_total_noniid, validation_data = (x_test, y_test_cat), epochs = 20, verbose = True)\n",
    "    pd.DataFrame(centralized_training_history.history).to_csv(os.path.join(experiment_dir, 'central_train_noniid', 'centralized_training_{}.csv'.format(i)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Iteration: 0\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 988us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.15982355177402496, 0.36579573154449463, 0.05361384525895119, 0.23108245432376862, 0.4418052136898041, 0.31795045733451843, 0.12453342229127884, 0.49575838446617126, 0.2514421343803406, 0.39667457342147827]\n",
      "Avg Acc:0.28384797684848306 Mean:-0.06838959455490112 Std:1.6745089292526245\n",
      "\n",
      " Iteration: 1\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.17509330809116364, 0.35018661618232727, 0.18255853652954102, 0.16661010682582855, 0.3444180488586426, 0.31591448187828064, 0.30607396364212036, 0.44960978627204895, 0.3254156708717346, 0.3434000611305237]\n",
      "Avg Acc:0.29592805802822114 Mean:-0.08300695568323135 Std:1.3673005104064941\n",
      "\n",
      " Iteration: 2\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.16830675303936005, 0.44384118914604187, 0.34815067052841187, 0.16728876531124115, 0.39429929852485657, 0.3769935667514801, 0.3254156708717346, 0.36104512214660645, 0.3250763416290283, 0.41092637181282043]\n",
      "Avg Acc:0.33213437497615816 Mean:-0.04846369847655296 Std:1.327269434928894\n",
      "\n",
      " Iteration: 3\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.21445538103580475, 0.49643704295158386, 0.3349168598651886, 0.21106210350990295, 0.36477774381637573, 0.3793688416481018, 0.31862911581993103, 0.6749236583709717, 0.3379708230495453, 0.4224635362625122]\n",
      "Avg Acc:0.3755005106329918 Mean:-0.06191064789891243 Std:1.2542662620544434\n",
      "\n",
      " Iteration: 4\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 988us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.22395657002925873, 0.4716660976409912, 0.3383101522922516, 0.3311842679977417, 0.44791314005851746, 0.35833051800727844, 0.3359348475933075, 0.6878181099891663, 0.3322022259235382, 0.4251781404018402]\n",
      "Avg Acc:0.3952494069933891 Mean:-0.02594105526804924 Std:1.263675570487976\n",
      "\n",
      " Iteration: 5\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.22158126533031464, 0.4872751832008362, 0.3400067985057831, 0.3372921645641327, 0.49813368916511536, 0.35934847593307495, 0.3267729878425598, 0.5259585976600647, 0.3345775306224823, 0.41398030519485474]\n",
      "Avg Acc:0.38449269980192186 Mean:-0.01993848755955696 Std:1.2425875663757324\n",
      "\n",
      " Iteration: 6\n",
      "4/4 [==============================] - 0s 983us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.192059725522995, 0.46046826243400574, 0.3413640856742859, 0.3393281400203705, 0.4845605790615082, 0.3406854569911957, 0.3383101522922516, 0.6647437810897827, 0.3756362497806549, 0.41160503029823303]\n",
      "Avg Acc:0.39487614631652834 Mean:0.004352443851530552 Std:1.408326268196106\n",
      "\n",
      " Iteration: 7\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.17203935980796814, 0.5361384749412537, 0.3403461277484894, 0.3403461277484894, 0.49372243881225586, 0.3810654878616333, 0.3311842679977417, 0.5524262189865112, 0.3271123170852661, 0.4285714328289032]\n",
      "Avg Acc:0.3902952253818512 Mean:0.035453781485557556 Std:1.3060402870178223\n",
      "\n",
      " Iteration: 8\n",
      "4/4 [==============================] - 0s 998us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.16966407001018524, 0.5117068290710449, 0.3396674692630768, 0.3403461277484894, 0.4699694514274597, 0.34645402431488037, 0.3383101522922516, 0.5096708536148071, 0.3240583539009094, 0.4316253960132599]\n",
      "Avg Acc:0.3781472727656364 Mean:0.047710247337818146 Std:1.388187289237976\n",
      "\n",
      " Iteration: 9\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.16898541152477264, 0.5283339023590088, 0.3403461277484894, 0.3403461277484894, 0.5724465847015381, 0.3410247564315796, 0.3403461277484894, 0.6647437810897827, 0.3386494815349579, 0.4356973171234131]\n",
      "Avg Acc:0.4070919618010521 Mean:0.036424268037080765 Std:1.3329076766967773\n",
      "\n",
      " Iteration: 10\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 998us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.16830675303936005, 0.5147607922554016, 0.3396674692630768, 0.3403461277484894, 0.5391923785209656, 0.3698676526546478, 0.3396674692630768, 0.6569392681121826, 0.3440787196159363, 0.4353579878807068]\n",
      "Avg Acc:0.4048184618353844 Mean:0.06684277206659317 Std:1.503675103187561\n",
      "\n",
      " Iteration: 11\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 998us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.16830675303936005, 0.5503902435302734, 0.337631493806839, 0.3366135060787201, 0.49168646335601807, 0.328130304813385, 0.3318628966808319, 0.6467593908309937, 0.3250763416290283, 0.4370546340942383]\n",
      "Avg Acc:0.3953512027859688 Mean:0.12105239182710648 Std:1.5812231302261353\n",
      "\n",
      " Iteration: 12\n",
      "4/4 [==============================] - 0s 998us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.16830675303936005, 0.61588054895401, 0.3403461277484894, 0.35934847593307495, 0.5561587810516357, 0.34815067052841187, 0.3729216158390045, 0.5687139630317688, 0.4855785667896271, 0.4356973171234131]\n",
      "Avg Acc:0.42511028200387957 Mean:0.15420246124267578 Std:1.5915547609329224\n",
      "\n",
      " Iteration: 13\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.16830675303936005, 0.5683746337890625, 0.3403461277484894, 0.36511707305908203, 0.5212079882621765, 0.40719375014305115, 0.3837801218032837, 0.5459789633750916, 0.3756362497806549, 0.4370546340942383]\n",
      "Avg Acc:0.411299629509449 Mean:0.12942299246788025 Std:1.3673409223556519\n",
      "\n",
      " Iteration: 14\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.17102137207984924, 0.5629453659057617, 0.3393281400203705, 0.36240243911743164, 0.5643026828765869, 0.39938920736312866, 0.4129623472690582, 0.5137428045272827, 0.41465896368026733, 0.4285714328289032]\n",
      "Avg Acc:0.416932475566864 Mean:0.136915385723114 Std:1.6291290521621704\n",
      "\n",
      " Iteration: 15\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.16830675303936005, 0.5985748171806335, 0.3406854569911957, 0.3457753658294678, 0.5239226222038269, 0.40312182903289795, 0.421106219291687, 0.6996946334838867, 0.380726158618927, 0.4343400001525879]\n",
      "Avg Acc:0.43162538558244706 Mean:0.0977746918797493 Std:1.3532559871673584\n",
      "\n",
      " Iteration: 16\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.16966407001018524, 0.6063793897628784, 0.3410247564315796, 0.3393281400203705, 0.4326433539390564, 0.3909060060977936, 0.390227347612381, 0.554462194442749, 0.36443841457366943, 0.4360366463661194]\n",
      "Avg Acc:0.4025110319256783 Mean:0.11406189203262329 Std:1.5435420274734497\n",
      "\n",
      " Iteration: 17\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.17068204283714294, 0.6050220727920532, 0.3413640856742859, 0.3393281400203705, 0.5548014640808105, 0.4241601526737213, 0.4353579878807068, 0.6963013410568237, 0.4268747866153717, 0.4265354573726654]\n",
      "Avg Acc:0.4420427531003952 Mean:0.10377451777458191 Std:1.5100009441375732\n",
      "\n",
      " Iteration: 18\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 998us/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.16830675303936005, 0.6073973774909973, 0.3403461277484894, 0.3389888107776642, 0.4777739942073822, 0.44078725576400757, 0.45368170738220215, 0.724465548992157, 0.3403461277484894, 0.442823201417923]\n",
      "Avg Acc:0.4334916904568672 Mean:0.08302248269319534 Std:1.422257900238037\n",
      "\n",
      " Iteration: 19\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.17237868905067444, 0.612487256526947, 0.3406854569911957, 0.3383101522922516, 0.596878170967102, 0.5341024994850159, 0.5436036586761475, 0.6362402439117432, 0.4784526526927948, 0.4336613416671753]\n",
      "Avg Acc:0.4686800122261047 Mean:0.09092974662780762 Std:1.6555395126342773\n",
      "\n",
      " Iteration: 20\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.17068204283714294, 0.5853410363197327, 0.3400067985057831, 0.3379708230495453, 0.538513720035553, 0.5469969511032104, 0.5273159146308899, 0.5324058532714844, 0.4133016765117645, 0.4356973171234131]\n",
      "Avg Acc:0.44282321333885194 Mean:0.06923075020313263 Std:1.5438779592514038\n",
      "\n",
      " Iteration: 21\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.16898541152477264, 0.6087546944618225, 0.3400067985057831, 0.3383101522922516, 0.5127248167991638, 0.4764167070388794, 0.4648795425891876, 0.631489634513855, 0.35052594542503357, 0.4394299387931824]\n",
      "Avg Acc:0.4331523641943932 Mean:0.0627397820353508 Std:1.4763264656066895\n",
      "\n",
      " Iteration: 22\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "models' accuracies: [0.17102137207984924, 0.5571767687797546, 0.3403461277484894, 0.3383101522922516, 0.5924668908119202, 0.49575838446617126, 0.49541908502578735, 0.689854085445404, 0.3875127136707306, 0.4241601526737213]\n",
      "Avg Acc:0.44920257329940794 Mean:0.08089752495288849 Std:1.5575523376464844\n",
      "\n",
      " Iteration: 23\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.17102137207984924, 0.6104512810707092, 0.3403461277484894, 0.3379708230495453, 0.541907012462616, 0.5201900005340576, 0.49338310956954956, 0.5826264023780823, 0.39667457342147827, 0.4384119510650635]\n",
      "Avg Acc:0.44329826533794403 Mean:0.0855245366692543 Std:1.47105872631073\n",
      "\n",
      " Iteration: 24\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.16830675303936005, 0.6067187190055847, 0.3413640856742859, 0.35188326239585876, 0.5615880489349365, 0.5602307319641113, 0.5398710370063782, 0.7550050616264343, 0.3919239938259125, 0.44485917687416077]\n",
      "Avg Acc:0.4721750870347023 Mean:0.08337599039077759 Std:1.761070966720581\n",
      "\n",
      " Iteration: 25\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.16830675303936005, 0.6121479272842407, 0.3450967073440552, 0.35120460391044617, 0.5921275615692139, 0.4343400001525879, 0.559891402721405, 0.6131659150123596, 0.45978960394859314, 0.4370546340942383]\n",
      "Avg Acc:0.45731251090765 Mean:0.06755023449659348 Std:1.746156096458435\n",
      "\n",
      " Iteration: 26\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 998us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.16830675303936005, 0.5551407933235168, 0.34373939037323, 0.35731253027915955, 0.5391923785209656, 0.5089921951293945, 0.5218866467475891, 0.7645062804222107, 0.4285714328289032, 0.4278927743434906]\n",
      "Avg Acc:0.461554117500782 Mean:0.04996046796441078 Std:1.5680701732635498\n",
      "\n",
      " Iteration: 27\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "models' accuracies: [0.16830675303936005, 0.6118085980415344, 0.3430607318878174, 0.36545640230178833, 0.5171360969543457, 0.597896158695221, 0.5809297561645508, 0.6538853049278259, 0.4723447561264038, 0.41601628065109253]\n",
      "Avg Acc:0.47268408387899397 Mean:0.02537345141172409 Std:1.6535016298294067\n",
      "\n",
      " Iteration: 28\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.16864608228206635, 0.6135052442550659, 0.35391923785209656, 0.36918899416923523, 0.6050220727920532, 0.5792331099510193, 0.5704106092453003, 0.7743467688560486, 0.3749575912952423, 0.40685442090034485]\n",
      "Avg Acc:0.48160841315984726 Mean:0.01318011712282896 Std:1.7563358545303345\n",
      "\n",
      " Iteration: 29\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "models' accuracies: [0.16830675303936005, 0.5900916457176208, 0.3430607318878174, 0.3769935667514801, 0.5045809149742126, 0.585680365562439, 0.5785544514656067, 0.6525279879570007, 0.4899898171424866, 0.41058704257011414]\n",
      "Avg Acc:0.47003732770681383 Mean:0.021171415224671364 Std:1.9411251544952393\n",
      "\n",
      " Iteration: 30\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "models' accuracies: [0.16830675303936005, 0.6141839027404785, 0.34645402431488037, 0.3824228048324585, 0.591109573841095, 0.6243637800216675, 0.5819477438926697, 0.5269765853881836, 0.49643704295158386, 0.4336613416671753]\n",
      "Avg Acc:0.4765863552689552 Mean:0.0021233863662928343 Std:1.8087083101272583\n",
      "\n",
      " Iteration: 31\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "models' accuracies: [0.16898541152477264, 0.6138445734977722, 0.34916865825653076, 0.3430607318878174, 0.5710892677307129, 0.5656599998474121, 0.57550048828125, 0.7845266461372375, 0.5514082312583923, 0.4377332925796509]\n",
      "Avg Acc:0.4960977301001549 Mean:-0.024203892797231674 Std:1.6867059469223022\n",
      "\n",
      " Iteration: 32\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "models' accuracies: [0.17305734753608704, 0.61588054895401, 0.3444180488586426, 0.3403461277484894, 0.5619273781776428, 0.5727858543395996, 0.5870376825332642, 0.758059024810791, 0.5663386583328247, 0.44994911551475525]\n",
      "Avg Acc:0.49697997868061067 Mean:-0.04918905720114708 Std:1.7355825901031494\n",
      "\n",
      " Iteration: 33\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "models' accuracies: [0.17475399374961853, 0.5690532922744751, 0.3406854569911957, 0.3393281400203705, 0.5948421955108643, 0.6111299395561218, 0.5904309749603271, 0.773668110370636, 0.5751611590385437, 0.4414658844470978]\n",
      "Avg Acc:0.501051914691925 Mean:-0.04895230755209923 Std:1.6413267850875854\n",
      "\n",
      " Iteration: 34\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "models' accuracies: [0.16898541152477264, 0.5805904269218445, 0.3427214026451111, 0.3450967073440552, 0.5887343287467957, 0.6155412197113037, 0.5721072554588318, 0.6637257933616638, 0.6043434143066406, 0.4384119510650635]\n",
      "Avg Acc:0.4920257911086082 Mean:-0.031447429209947586 Std:1.9202628135681152\n",
      "\n",
      " Iteration: 35\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "models' accuracies: [0.16830675303936005, 0.6141839027404785, 0.3423820734024048, 0.3742789328098297, 0.5907703042030334, 0.6138445734977722, 0.5948421955108643, 0.7051238417625427, 0.5246012806892395, 0.46250423789024353]\n",
      "Avg Acc:0.4990838095545769 Mean:-0.10289545357227325 Std:1.671302318572998\n",
      "\n",
      " Iteration: 36\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "models' accuracies: [0.17034272849559784, 0.6111299395561218, 0.3444180488586426, 0.35290125012397766, 0.49100780487060547, 0.5768578052520752, 0.5924668908119202, 0.6586359143257141, 0.514082133769989, 0.39667457342147827]\n",
      "Avg Acc:0.4708517089486122 Mean:-0.08222696930170059 Std:1.8151787519454956\n",
      "\n",
      " Iteration: 37\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "models' accuracies: [0.18086189031600952, 0.597896158695221, 0.3454360365867615, 0.36851033568382263, 0.594502866268158, 0.5303698778152466, 0.578893780708313, 0.7811333537101746, 0.41533762216567993, 0.4200882315635681]\n",
      "Avg Acc:0.4813030153512955 Mean:-0.07926560193300247 Std:1.8073114156723022\n",
      "\n",
      " Iteration: 38\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "models' accuracies: [0.1849338263273239, 0.6118085980415344, 0.34679335355758667, 0.3434000611305237, 0.5527655482292175, 0.6182558536529541, 0.6409908533096313, 0.7261621952056885, 0.5900916457176208, 0.4275534451007843]\n",
      "Avg Acc:0.5042755380272865 Mean:-0.1331760734319687 Std:1.7040740251541138\n",
      "\n",
      " Iteration: 39\n",
      "4/4 [==============================] - 0s 998us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "models' accuracies: [0.17373600602149963, 0.5975568294525146, 0.34373939037323, 0.3396674692630768, 0.5283339023590088, 0.6152018904685974, 0.634882926940918, 0.7583983540534973, 0.510688841342926, 0.46318289637565613]\n",
      "Avg Acc:0.49653885066509246 Mean:-0.13324248790740967 Std:1.8031591176986694\n",
      "\n",
      " Iteration: 40\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "models' accuracies: [0.16898541152477264, 0.594502866268158, 0.3440787196159363, 0.3417034149169922, 0.5639633536338806, 0.6029860973358154, 0.5995928049087524, 0.7760434150695801, 0.5707499384880066, 0.44418051838874817]\n",
      "Avg Acc:0.5006786540150643 Mean:-0.13924166560173035 Std:1.6904141902923584\n",
      "\n",
      " Iteration: 41\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "models' accuracies: [0.16898541152477264, 0.6189345121383667, 0.3440787196159363, 0.34713268280029297, 0.600271463394165, 0.6101119518280029, 0.5917882323265076, 0.7529691457748413, 0.5093315243721008, 0.44519850611686707]\n",
      "Avg Acc:0.49888021498918533 Mean:-0.11688248813152313 Std:1.9669522047042847\n",
      "\n",
      " Iteration: 42\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "models' accuracies: [0.17271801829338074, 0.6145232319831848, 0.3457753658294678, 0.34916865825653076, 0.5724465847015381, 0.6019681096076965, 0.6175771951675415, 0.7672209143638611, 0.6477773785591125, 0.470308780670166]\n",
      "Avg Acc:0.515948423743248 Mean:-0.16101238131523132 Std:1.7176549434661865\n",
      "\n",
      " Iteration: 43\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "models' accuracies: [0.17509330809116364, 0.6165592074394226, 0.3447573781013489, 0.35697320103645325, 0.5748218297958374, 0.6772989630699158, 0.6016287803649902, 0.7475398778915405, 0.5378350615501404, 0.4760773777961731]\n",
      "Avg Acc:0.5108584985136986 Mean:-0.1693284958600998 Std:1.858167052268982\n",
      "\n",
      " Iteration: 44\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "models' accuracies: [0.17814727127552032, 0.6101119518280029, 0.34882932901382446, 0.36206310987472534, 0.6026467680931091, 0.6722090244293213, 0.6087546944618225, 0.6946046948432922, 0.5802510976791382, 0.45775365829467773]\n",
      "Avg Acc:0.5115371599793435 Mean:-0.19017620384693146 Std:1.8615766763687134\n",
      "\n",
      " Iteration: 45\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 8ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "models' accuracies: [0.17577196657657623, 0.6111299395561218, 0.3444180488586426, 0.36375975608825684, 0.541907012462616, 0.6216491460800171, 0.5900916457176208, 0.7475398778915405, 0.5473362803459167, 0.4767560362815857]\n",
      "Avg Acc:0.5020359709858895 Mean:-0.19579492509365082 Std:1.733677625656128\n",
      "\n",
      " Iteration: 46\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "models' accuracies: [0.17509330809116364, 0.6016287803649902, 0.3427214026451111, 0.3440787196159363, 0.5931455492973328, 0.6284356713294983, 0.5877163410186768, 0.6884967684745789, 0.5792331099510193, 0.4821852743625641]\n",
      "Avg Acc:0.5022734925150871 Mean:-0.19809827208518982 Std:1.8331172466278076\n",
      "\n",
      " Iteration: 47\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "models' accuracies: [0.17271801829338074, 0.603664755821228, 0.3454360365867615, 0.3410247564315796, 0.5873770117759705, 0.6063793897628784, 0.6118085980415344, 0.7027485370635986, 0.4285714328289032, 0.5120461583137512]\n",
      "Avg Acc:0.4911774694919586 Mean:-0.24816350638866425 Std:1.7173141241073608\n",
      "\n",
      " Iteration: 48\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 11ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "models' accuracies: [0.18018323183059692, 0.6155412197113037, 0.35120460391044617, 0.34815067052841187, 0.5860196948051453, 0.6138445734977722, 0.6182558536529541, 0.6308109760284424, 0.5042415857315063, 0.4848999083042145]\n",
      "Avg Acc:0.49331523180007936 Mean:-0.22471407055854797 Std:2.001532554626465\n",
      "\n",
      " Iteration: 49\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "models' accuracies: [0.40481844544410706, 0.6135052442550659, 0.35324057936668396, 0.3851374387741089, 0.600271463394165, 0.693247377872467, 0.6749236583709717, 0.7315914630889893, 0.6304716467857361, 0.46216490864753723]\n",
      "Avg Acc:0.5549372225999832 Mean:-0.2852008044719696 Std:1.7298439741134644\n"
     ]
    }
   ],
   "source": [
    "\n",
    "shared_public_dataset = (pub_x[:n_alignment, ...], pub_y[:n_alignment, ...])\n",
    "validation_dataset = (x_test, y_test_cat)\n",
    "fedmd_nodes = [FedAMDNode(noniid_models[i], (pri_x_list_noniid[i], pri_y_list_noniid[i]), shared_public_dataset, target_validation_gen = validation_dataset) for i in range(n_parties)]\n",
    "\n",
    "# Training iterations \n",
    "for iteration in range(n_iterations) : \n",
    "  print('\\n Iteration:', iteration)\n",
    "\n",
    "  for i, node in enumerate(fedmd_nodes) : \n",
    "    # logger_file = os.path.join(experiment_dir,'fedMD_noniid', 'FedMD_train_{}.csv'.format(i))\n",
    "    logger_file = os.path.join(experiment_dir,'noniid', 'train_{}.csv'.format(i))\n",
    "    node.train_on_target(epochs = 2, verbose = False, logger_file = logger_file, evaluate = True)\n",
    "\n",
    "  # seed and alpha variables are not used in FedMD since it uses Node not FedAMDNode\n",
    "  seed = np.random.randint(0, 10000) \n",
    "  alpha = np.random.rand()\n",
    "\n",
    "  pub_scores, priv_performances = collect_metadatas(fedmd_nodes, seed, alpha) \n",
    "  print(\"models' accuracies:\", priv_performances) \n",
    "  print(\"Avg Acc:{} Mean:{} Std:{}\".format(np.mean(priv_performances), np.mean(pub_scores), np.std(pub_scores)))\n",
    "  \n",
    "  # Aggregate training metadata \n",
    "  weighted_pub_scores = aggregate_training_metadatas(pub_scores, priv_performances, weighted_averaging = True) \n",
    "\n",
    "\n",
    "  # Receive training metadata (and rebuilds Carrier dataset with updated labels)\n",
    "  for i, node in enumerate(fedmd_nodes) : \n",
    "    node.receive_training_metadata(weighted_pub_scores)   \n",
    "    node.train_on_public(epochs = 1, verbose = False) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def smooth(signal, window_len = 11, polyorder = 3) : \n",
    "    return savgol_filter(signal, window_length= window_len, polyorder = polyorder)\n",
    "\n",
    "def get_csv_files(dir) : \n",
    "    return [join(dir, f) for f in os.listdir(dir) if f.endswith('.csv')]\n",
    "\n",
    "\n",
    "class Experiment : \n",
    "\n",
    "    def __init__(self, root) : \n",
    "        self.root = root \n",
    "        self.colors = list(mcolors.TABLEAU_COLORS.keys())\n",
    "    \n",
    "    \n",
    "    def get_last_accuracies (self, subdir) : \n",
    "        return [pd.read_csv(f)['val_accuracy'].values[-1] for f in get_csv_files(join(self.root, subdir))]\n",
    "\n",
    "    def get_accuracies(self, subdir) : \n",
    "        return [pd.read_csv(f)['val_accuracy'] for f in get_csv_files(join(self.root, subdir))]\n",
    "    \n",
    "    def plot_fedMD_like(self, left, center, right, labels, shades = None, title = 'Accuracy', limit = None):\n",
    "        assert len(left) == len(right) == len(center), 'statistics should have the same length'\n",
    "        \n",
    "        n_epochs = len(center[0]) \n",
    "        epochs = np.arange(n_epochs) \n",
    "        n_parties = len(center)\n",
    "        if limit is None : \n",
    "            limit = n_parties \n",
    "        plt.figure(figsize=(20, 11))\n",
    "\n",
    "        plt.subplot(2, 2, 1)\n",
    "        for i in range(limit) : \n",
    "            if left is not None : \n",
    "                plt.hlines(y=left[i], xmin=-10, xmax=10, linestyle = '--', color = self.colors[i])\n",
    "            if right is not None : \n",
    "                plt.hlines(y=right[i], xmin=n_epochs-10, xmax=n_epochs+10, linestyle = '--', color = self.colors[i])\n",
    "            plt.plot(epochs, center[i], label=labels[i], color = self.colors[i])\n",
    "            if shades is not None :\n",
    "                plt.fill_between(epochs, shades[0][i], shades[1][i], alpha=0.1, color = self.colors[i])\n",
    "        plt.legend(loc='best', bbox_to_anchor=(0.95, 0.5))\n",
    "        plt.title(title) \n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.xlim(0, n_epochs)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def plot_fedMD_like_comparison(left, center, right, labels = None, shades = None, colors = None, title = None, limit = None) :\n",
    "    n_epochs = len(center[0]) \n",
    "    epochs = np.arange(n_epochs) \n",
    "    n_parties = len(center)\n",
    "    if limit is None : \n",
    "        limit = n_parties \n",
    "    plt.figure(figsize=(20, 11))\n",
    "    if colors is None : \n",
    "        colors = list(mcolors.TABLEAU_COLORS.keys())\n",
    "    plt.subplot(2, 2, 1)\n",
    "    for i in range(limit) : \n",
    "        if left is not None :\n",
    "            plt.hlines(y=left[i], xmin=-10, xmax=10, linestyle = '--', color = colors[i])\n",
    "        if right is not None : \n",
    "            plt.hlines(y=right[i], xmin=n_epochs-10, xmax=n_epochs+10, linestyle = '--', color = colors[i])\n",
    "        plt.plot(epochs, center[i], label=labels[i], color = colors[i])\n",
    "        if shades is not None :\n",
    "            plt.fill_between(epochs, shades[i][0], shades[i][0], alpha=0.1, color = colors[i])\n",
    "    plt.legend(loc='lower right', bbox_to_anchor=(0.95, 0.5))\n",
    "    plt.title(title) \n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlim(0, n_epochs)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models gains iid: [61, 62, 55, 54, 45, 44, 50, 41, 47, 22]\n",
      "models gains noniid: [39, 48, 26, 39, 47, 35, 51, 50, 26, 31]\n",
      "10\n",
      "10\n",
      "10\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "exp = Experiment('results/FedMD')\n",
    "last_local_accs_iid = [0 for i in range(n_parties)] # exp.get_last_accuracies('local_train_iid')\n",
    "last_local_accs_noniid = [0 for i in range(n_parties)] # exp.get_last_accuracies('local_train_noniid')\n",
    "\n",
    "last_central_accs_iid = [0 for i in range(n_parties)] #exp.get_last_accuracies('central_train_iid')\n",
    "last_central_accs_noniid = [0 for i in range(n_parties)] # exp.get_last_accuracies('central_train_noniid')\n",
    "\n",
    "fedAMD_iid = exp.get_accuracies('iid') \n",
    "fedAMD_noniid = exp.get_accuracies('noniid') \n",
    "smooth_iid = [smooth(acc) for acc in fedAMD_iid]\n",
    "smooth_noniid = [smooth(acc) for acc in fedAMD_noniid]\n",
    "\n",
    "# fedAMD_iid = exp.get_accuracies('fedMD_iid') \n",
    "# fedAMD_noniid = exp.get_accuracies('fedMD_noniid') \n",
    "\n",
    "# avg_left_iid, avg_right_iid = [np.mean(last_local_accs_iid)], [np.mean(last_central_accs_iid)]\n",
    "# avg_left_noniid, avg_right_noniid = [np.mean(last_local_accs_noniid)], [np.mean(last_central_accs_noniid)]\n",
    "\n",
    "smooth_center_iid = [smooth(np.mean(fedAMD_iid, axis = 0), window_len = 27, polyorder = 3)]\n",
    "smooth_center_noniid = [smooth(np.mean(fedAMD_noniid, axis = 0), window_len = 27, polyorder = 3)]\n",
    "\n",
    "center_iid = [np.mean(fedAMD_iid, axis = 0)]\n",
    "center_noniid = [np.mean(fedAMD_noniid, axis = 0)]\n",
    "\n",
    "# fedAMD_noniid_limits = [np.min(fedAMD_noniid, axis = 0), np.max(fedAMD_noniid, axis = 0)]\n",
    "# fedAMD_iid_limits = [np.min(fedAMD_iid, axis = 0), np.max(fedAMD_iid, axis = 0)]\n",
    "\n",
    "\n",
    "models_gains_iid = [int(round(fedAMD_iid[i].values[-1] - last_local_accs_iid[i], 2) *100) for i in range(len(last_local_accs_iid))]\n",
    "models_gains_noniid = [int(round(fedAMD_noniid[i].values[-1] - last_local_accs_noniid[i], 2) *100) for i in range(len(last_local_accs_noniid))]\n",
    "print('models gains iid:', models_gains_iid)\n",
    "print('models gains noniid:', models_gains_noniid)\n",
    "\n",
    "ts = [last_local_accs_iid, smooth_iid, last_central_accs_iid]\n",
    "for t in ts : \n",
    "    print(len(t)) \n",
    "exp.plot_fedMD_like(last_local_accs_iid, smooth_iid, last_central_accs_iid, \\\n",
    "    labels = ['Model ' + str(i) for i in range(n_parties)],\n",
    "     shades =None, \n",
    "     title = 'FedAKD accuracy on HARS dataset (i.i.d)' , limit = 5)\n",
    "\n",
    "exp.plot_fedMD_like(last_local_accs_noniid, smooth_noniid, last_central_accs_noniid, \\\n",
    "    labels = ['Model ' + str(i)  for i in range(n_parties)],\n",
    "     shades =None, \n",
    "     title = 'FedAKD accuracy HARS dataset (Non-i.i.d)', limit = 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3223427f9efc78bde2a0bfa649eaafd59d76d8ff88e8ea3cc707a79302c4d372"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
