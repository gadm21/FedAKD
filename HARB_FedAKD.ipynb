{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout, MaxPooling1D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import CSVLogger, EarlyStopping\n",
    "\n",
    "import os\n",
    "from os.path import join\n",
    "import warnings\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
    "from tensorflow.keras.layers import Dropout, Flatten, RepeatVector, Activation, Concatenate\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, Conv2D, MaxPooling2D, LSTM, GRU, BatchNormalization, Reshape\n",
    "from tensorflow.keras.layers import TimeDistributed, Dense, Input, GlobalAveragePooling2D, Bidirectional\n",
    "from tensorflow.keras.layers import LayerNormalization\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
    "\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.models import  Sequential\n",
    "from tensorflow.keras.optimizers import RMSprop, Adadelta, Adam\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.optimizers.schedules import PolynomialDecay\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.losses import BinaryCrossentropy, CategoricalCrossentropy, SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow.keras.backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "from functools import reduce\n",
    "from scipy.signal import savgol_filter \n",
    "import matplotlib.colors as mcolors\n",
    "csfont = {'fontname':'Arial'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_data (data_dir, label, as_np = False, as_df = False) : \n",
    "\n",
    "    experiments = [] \n",
    "    data = [] \n",
    "    with open(data_dir, 'r') as f : \n",
    "        for line in f.readlines() : \n",
    "            if line.startswith('month') : \n",
    "                if len(data) : \n",
    "                    experiments.append(data) \n",
    "                    data = [] \n",
    "            data.append(line) \n",
    "        if len(data) : \n",
    "            experiments.append(data) \n",
    "    \n",
    "    if as_np or as_df : \n",
    "        np_exps = [] \n",
    "        for i, exp in enumerate(experiments) : \n",
    "            _, data = put_experiment_data_to_np(exp, label = label)  \n",
    "            np_exps.append(data) \n",
    "        np_exp = np.concatenate(np_exps) \n",
    "\n",
    "        if as_df : \n",
    "            dataframe_dict = {\n",
    "                'hr': np_exp[:, 0],\n",
    "                'gryo_x': np_exp[:, 1], \n",
    "                'gyro_y': np_exp[:, 2], \n",
    "                'gyro_z': np_exp[:, 3],\n",
    "                'timestamp': np_exp[:, 4], \n",
    "                'label': np_exp[:, 5]}\n",
    "            df = pd.DataFrame(dataframe_dict)\n",
    "            return df \n",
    "         \n",
    "        return np_exp \n",
    "\n",
    "\n",
    "    return experiments \n",
    "\n",
    "\n",
    "\n",
    "def put_experiment_data_to_np(exp, label = None) : \n",
    "\n",
    "    def get_first_hr(exp) : \n",
    "        for i in range(1, len(exp)):\n",
    "            line = exp[i]\n",
    "            vars = line.split(',') \n",
    "            if len(vars) == 2 : \n",
    "                return int(vars[0])\n",
    "    hr = get_first_hr(exp) \n",
    "    np_data = []\n",
    "    for i in range(1, len(exp)):\n",
    "        line = exp[i]\n",
    "        vars = line.split(',') \n",
    "        if len(vars) == 2 : \n",
    "            if (int(vars[0])  < 0) : continue \n",
    "            hr = (int(vars[0]) + hr) // 2\n",
    "        elif len(vars) == 4 : \n",
    "            gryo_vars = list(map(int, vars[:3])) \n",
    "            if label is not None : \n",
    "                data = np.array([hr, *gryo_vars, int(vars[3].split('.')[0]), label])\n",
    "            else : \n",
    "                data = np.array([hr, *gryo_vars, int(vars[3].split('.')[0])])\n",
    "            np_data.append(data)      \n",
    "    return exp[0], np.array(np_data) \n",
    "\n",
    "\n",
    "\n",
    "def get_models(p, configurations) : \n",
    "\n",
    "    learning_rate = p['learning_rate']\n",
    "    seq_len = p['seq_len']\n",
    "    n_features = p['n_features']\n",
    "    n_classes = p['n_classes']\n",
    "\n",
    "    filters1, filters2, filters3 = configurations['filters']\n",
    "    lstm_units1, lstm_units2 = configurations['lstm_units']\n",
    "    ks1, ks2, ks3 = configurations['kernel_size']\n",
    "\n",
    "    # l2_norm_clip = p['l2_norm_clip']\n",
    "    # dp_learning_rate = p['dp_learning_rate']\n",
    "    # batch_size = p['batch_size']\n",
    "    # num_microbatches = p['num_microbatches']\n",
    "    # noise_multiplier = p['noise_multiplier']\n",
    "    # dp_optimizer = p['dp_optimizer']\n",
    "    # from_logits = p['from_logits']\n",
    "\n",
    "    # if batch_size % num_microbatches != 0:\n",
    "    #     raise ValueError('Batch size should be an integer multiple of the number of microbatches')\n",
    "\n",
    "    K.clear_session() \n",
    "    #__________________________Inputs\n",
    "    inp = Input(shape = (seq_len, n_features))\n",
    "    #__________________________layers\n",
    "    conv1 = Conv1D(filters = filters1 , kernel_size = 20, dilation_rate = 2, activation = 'relu')(inp)\n",
    "    conv2 = Conv1D(filters = filters2 , kernel_size = 20, dilation_rate = 2, activation = 'relu')(conv1)\n",
    "    conv3 = Conv1D(filters = filters3 , kernel_size = 10, dilation_rate = 2, activation = 'relu')(conv2)\n",
    "    lstm1 = LSTM(lstm_units1, return_sequences = True, activation = 'tanh')(conv3)\n",
    "    lstm2 = LSTM(lstm_units2, return_sequences = False, activation = 'tanh')(lstm1) \n",
    "    lstm_d = Dropout(0.1)(lstm2)\n",
    "    dense1 = Dense(10)(lstm_d)\n",
    "    dense2 = Dense(n_classes)(dense1)\n",
    "    dense2 = Activation('softmax')(dense2)\n",
    "    model_A = models.Model(inputs = inp, outputs = dense2)\n",
    "\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n",
    "    model_A.compile(optimizer= optimizer, loss = loss, metrics = [\"accuracy\"])\n",
    "    \n",
    "    # remove the last layer and compile with a different loss function\n",
    "    model_B = models.Model(inputs = model_A.inputs, outputs = model_A.layers[-2].output)\n",
    "    model_B.compile(optimizer = optimizer, loss = \"mean_absolute_error\")\n",
    "\n",
    "    return model_A, model_B\n",
    "\n",
    "# def split_dataset(x, y, samples_per_class, n_models, to_categorical = False) : \n",
    "#   datasets = [None]*n_models \n",
    "#   labels = [None]*n_models \n",
    "   \n",
    "#   sample_indecies = [None]*n_models \n",
    "#   n_classes = len(np.unique(y))\n",
    "#   combined_idx = np.array([], dtype = np.int16) \n",
    "#   n_samples_per_model = len(np.unique(y)) * samples_per_class \n",
    "\n",
    "#   for label in np.unique(y) : \n",
    "#     idx = np.where(y == label)[0]\n",
    "#     idx = np.random.choice(idx, samples_per_class*n_models, replace = True) \n",
    "#     combined_idx = np.r_[combined_idx, idx]\n",
    "#     for i in range(n_models) :\n",
    "#       if datasets[i] is None :\n",
    "#         datasets[i] = [x[idx[i*samples_per_class : (i+1)*samples_per_class]]]\n",
    "#         labels[i] = [y[idx[i*samples_per_class : (i+1)*samples_per_class]]]\n",
    "#       else : \n",
    "#         datasets[i].append( x[idx[i*samples_per_class : (i+1)*samples_per_class]])\n",
    "#         labels[i].append(y[idx[i*samples_per_class : (i+1)*samples_per_class]])\n",
    "  \n",
    "#   for i in range(n_models) : \n",
    "#     datasets[i] = np.concatenate(datasets[i])\n",
    "#     labels[i] = np.concatenate(labels[i])\n",
    "  \n",
    "\n",
    "#   total_datasets = x[combined_idx]\n",
    "#   total_labels = y[combined_idx]\n",
    "\n",
    "    \n",
    "#   if to_categorical : \n",
    "#     for i, l in enumerate(labels): \n",
    "#         labels[i] = tf.keras.utils.to_categorical(l, num_classes = n_classes)\n",
    "#     total_labels = tf.keras.utils.to_categorical(total_labels, num_classes = n_classes)\n",
    "  \n",
    "#   return datasets, labels, total_datasets, total_labels \n",
    "\n",
    "\n",
    "\n",
    "def split_dataset(x, y, samples_per_class, n_models, include_classes, to_categorical = False) : \n",
    "    datasets = [None]*n_models \n",
    "    labels = [None]*n_models \n",
    "\n",
    "    sample_indecies = [None]*n_models \n",
    "    n_classes = len(original_labels)\n",
    "    combined_idx = np.array([], dtype = np.int16) \n",
    "     \n",
    "    all_classes = list(np.arange(n_classes))\n",
    "\n",
    "    for label in all_classes :\n",
    "        idx = np.where(y == label)[0]\n",
    "        idx = np.random.choice(idx, samples_per_class*n_models, replace = True) \n",
    "        combined_idx = np.r_[combined_idx, idx]\n",
    "        for i in range(n_models) :\n",
    "            if include_classes != 'all' : \n",
    "                if label not in include_classes[i] :\n",
    "                    continue\n",
    "            if datasets[i] is None :\n",
    "                datasets[i] = [x[idx[i*samples_per_class : (i+1)*samples_per_class]]]\n",
    "                labels[i] = [y[idx[i*samples_per_class : (i+1)*samples_per_class]]]\n",
    "            else : \n",
    "                datasets[i].append( x[idx[i*samples_per_class : (i+1)*samples_per_class]])\n",
    "                labels[i].append(y[idx[i*samples_per_class : (i+1)*samples_per_class]])\n",
    "  \n",
    "    for i in range(n_models) : \n",
    "        datasets[i] = np.concatenate(datasets[i])\n",
    "        labels[i] = np.concatenate(labels[i])\n",
    "    \n",
    "\n",
    "    total_datasets = x[combined_idx]\n",
    "    total_labels = y[combined_idx]\n",
    "\n",
    "    \n",
    "    if to_categorical : \n",
    "        for i, l in enumerate(labels): \n",
    "            labels[i] = tf.keras.utils.to_categorical(l, num_classes = n_classes)       \n",
    "        total_labels = tf.keras.utils.to_categorical(total_labels, num_classes = n_classes)\n",
    "    \n",
    "    return datasets, labels, total_datasets, total_labels \n",
    "\n",
    "\n",
    "\n",
    "def get_optimizer(hp) : \n",
    "    optimizer_name = hp['optimizer'].lower()\n",
    "    if optimizer_name == 'adam' :\n",
    "        return tf.keras.optimizers.Adam(learning_rate=hp['learning_rate'])\n",
    "    elif optimizer_name == 'sgd' :\n",
    "        return tf.keras.optimizers.SGD(learning_rate=hp['learning_rate'])\n",
    "    elif optimizer_name == 'rmsprop' :\n",
    "        return tf.keras.optimizers.RMSprop(learning_rate=hp['learning_rate'])\n",
    "    else : \n",
    "        raise Exception('Optimizer not supported')\n",
    "\n",
    "\n",
    "def get_model(n_classes, input_shape, model_configurations) : \n",
    "    ub, ua, dropout_rate = model_configurations\n",
    "    act1, act2 = np.random.choice([\"relu\", \"elu\", \"selu\", \"tanh\"], 2)\n",
    "    lr = np.random.choice([1e-3, 1e-4, 1e-5])\n",
    "    opt = np.random.choice([\"adam\", \"sgd\", \"rmsprop\"])\n",
    "    optimizer = get_optimizer({\"optimizer\" : opt, \"learning_rate\" : lr})\n",
    "    \n",
    "    inp = tf.keras.layers.Input(input_shape) \n",
    "    y = Dense(units = ua, activation = act1)(inp) \n",
    "    y = Dropout(dropout_rate)(y)\n",
    "    y = Dense(units = ub, activation = act2)(y) \n",
    "    y = Dense(units = n_classes)(y)\n",
    "    y = tf.keras.layers.Activation('softmax')(y) \n",
    "\n",
    "    model_A = tf.keras.models.Model(inputs = inp, outputs = y)\n",
    "\n",
    "    model_A.compile(optimizer=optimizer,  \n",
    "                        loss = \"categorical_crossentropy\",\n",
    "                        metrics = [\"accuracy\"])\n",
    "    model_B = remove_last_layer(model_A) \n",
    "    configurations = {\n",
    "        \"act1\" : act1,\n",
    "        \"act2\" : act2,\n",
    "        \"ua\" : ua,\n",
    "        \"ub\" : ub,\n",
    "        \"dropout_rate\" : dropout_rate,\n",
    "        \"lr\" : lr,\n",
    "        \"opt\" : opt\n",
    "        \n",
    "    }\n",
    "    return model_A, model_B, configurations \n",
    "\n",
    "\n",
    "def remove_last_layer(model, loss = \"mean_absolute_error\"):\n",
    "    \"\"\"\n",
    "    Input: Keras model, a classification model whose last layer is a softmax activation\n",
    "    Output: Keras model, the same model with the last softmax activation layer removed,\n",
    "        while keeping the same parameters \n",
    "    \"\"\"\n",
    "    \n",
    "    new_model = tf.keras.models.Model(inputs = model.inputs, outputs = model.layers[-2].output)\n",
    "    new_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate = 1e-3), \n",
    "                      loss = loss)\n",
    "    \n",
    "    return new_model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_label(filename) : \n",
    "    filename = filename.split(\".\")[0]\n",
    "    if filename.startswith('study') :\n",
    "        return 0\n",
    "    elif filename.startswith('walk') : \n",
    "        return 1\n",
    "    elif filename.startswith('sleep') : \n",
    "        return 2\n",
    "    elif filename.startswith('idle') : \n",
    "        return 3\n",
    "    else :\n",
    "        return -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def number_of_parameters(model) : \n",
    "    return model.count_params()\n",
    "\n",
    "\n",
    "\n",
    "def get_tunable_models(hp) : \n",
    "    K.clear_session()\n",
    "    n_conv_layers = hp['n_conv_layers'] \n",
    "    n_lstm_layers = hp['n_lstm_layers']\n",
    "    activation_function = hp['activation_function']\n",
    "    dropout_rate = hp['dropout_rate']\n",
    "    conv_filter = hp['conv_filter']\n",
    "    conv_kernel_size = hp['conv_kernel_size']\n",
    "    lstm_units = hp['lstm_units']\n",
    "    optimizer = get_optimizer(hp)\n",
    "    learning_rate = hp['learning_rate']\n",
    "    input_shape = hp['input_shape']\n",
    "\n",
    "    x = Input(shape = input_shape) \n",
    "    y = Reshape(input_shape)(x) \n",
    "    for i in range(n_conv_layers) : \n",
    "        y = Conv1D(conv_filter, conv_kernel_size, activation = activation_function)(y)\n",
    "        y = MaxPooling1D(2)(y)\n",
    "    y = Dropout(dropout_rate)(y)\n",
    "    for i in range(n_lstm_layers) :\n",
    "        y = LSTM(lstm_units, return_sequences = True)(y)\n",
    "    lstm_layer = LSTM(lstm_units, return_sequences = False)(y)\n",
    "    lstm_dropout_layer = Dropout(dropout_rate)(lstm_layer)\n",
    "    \n",
    "    dense = Dense(hp['n_classes'])(lstm_dropout_layer)\n",
    "    output = Activation('softmax')(dense)\n",
    "    model1 = tf.keras.models.Model(inputs = x, outputs = output)\n",
    "    model1.compile(optimizer = optimizer, loss= 'categorical_crossentropy', metrics=['accuracy'])\n",
    "    model2 = tf.keras.models.Model(inputs = x, outputs = dense)\n",
    "    model2.compile(optimizer = optimizer, loss= 'mean_absolute_error')\n",
    "\n",
    "    return model1, model2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Node : \n",
    "\n",
    "    model = None \n",
    "    carrier_dataset_metadata = None\n",
    "    carrier_datset = None\n",
    "\n",
    "    local_target_dataset = None \n",
    "    target_validation_set = None \n",
    "\n",
    "    target_validation_acc = []\n",
    "    target_validation_loss = [] \n",
    "\n",
    "\n",
    "    def __init__(self, model, local_target_dataset, shared_public_dataset, target_validation_gen) : \n",
    "        self.model = model \n",
    "        self.local_target_dataset = local_target_dataset\n",
    "        self.shared_public_dataset = shared_public_dataset\n",
    "        self.target_validation_gen = target_validation_gen\n",
    "\n",
    "\n",
    "    def get_training_metadata(self, seed, alpha) : \n",
    "\n",
    "        self.seed = seed \n",
    "        self.alpha = alpha\n",
    "        carrier_preds = self.get_carrier_scores() \n",
    "        target_performance = self.evaluate_on_validation_set(save = False)[1]\n",
    "        data_shape = carrier_preds.shape\n",
    "\n",
    "        # carrier_preds = from_categorical(carrier_preds) \n",
    "\n",
    "        # print(\"carrier_preds:{}  new_labels:{}\".format(carrier_preds.shape, new_labels.shape))\n",
    "        return carrier_preds, target_performance\n",
    "\n",
    "\n",
    "    def get_carrier_scores(self) : \n",
    "        return self.model[1].predict(self.shared_public_dataset[0], batch_size = 32)\n",
    "\n",
    "\n",
    "    def receive_training_metadata(self, metadata) : \n",
    "\n",
    "        self.update_public_dataset_labels(metadata) \n",
    "\n",
    "\n",
    "    def update_public_dataset_labels(self, metadata) : \n",
    "        new_shared_public_dataset = (self.shared_public_dataset[0], metadata )\n",
    "        \n",
    "        self.shared_public_dataset = new_shared_public_dataset\n",
    "\n",
    "\n",
    "    def evaluate_on_validation_set(self, save = True) : \n",
    "        eval_x, eval_y = self.target_validation_gen\n",
    "        loss, acc = self.model[0].evaluate(eval_x, eval_y, batch_size = 32, verbose = False)\n",
    "        if save : \n",
    "            self.target_validation_loss.append(loss)\n",
    "            self.target_validation_acc.append(acc)\n",
    "        return loss, acc\n",
    "\n",
    "    def train_on_target(self, epochs = 1, use_callbacks = False, verbose = True, logger_file = None, evaluate = False) :\n",
    "        if use_callbacks : cbs = [EarlyStopping(monitor = 'val_loss', patience = 7, restore_best_weights= True)]\n",
    "        else : cbs = []\n",
    "        if logger_file : \n",
    "            cbs.append([CSVLogger(filename = logger_file, append = True)])\n",
    "        \n",
    "        if evaluate : \n",
    "            history = self.model[0].fit(self.local_target_dataset[0], self.local_target_dataset[1], \\\n",
    "                validation_data = self.target_validation_gen, epochs = epochs, callbacks = cbs, verbose = verbose)\n",
    "        else : \n",
    "\n",
    "            history = self.model[0].fit(self.local_target_dataset[0], self.local_target_dataset[1], epochs = epochs, \n",
    "                                        callbacks = cbs, verbose = verbose)\n",
    "\n",
    "\n",
    "\n",
    "    def train_on_public(self, epochs = 1, use_callbacks = False, verbose = True, logger_file = None) : \n",
    "\n",
    "        if use_callbacks : cbs = [EarlyStopping(monitor = 'val_loss', patience = 7, restore_best_weights= True)]\n",
    "        else : cbs = []\n",
    "        if logger_file : \n",
    "            cbs.append([CSVLogger(filename = logger_file, append = True)])\n",
    "        history = self.model[1].fit(self.shared_public_dataset[0], self.shared_public_dataset[1],\n",
    "         epochs = epochs, callbacks = cbs, verbose = verbose)\n",
    "\n",
    "\n",
    "\n",
    "    def save_model(self, model_path) : \n",
    "        self.model[0].save(model_path + '_classifier.h5') \n",
    "        self.model[1].save(model_path + '_regressor.h5') \n",
    "\n",
    "\n",
    "def aggregate_training_metadatas(carrier_labels, target_performance, weighted_averaging = False) : \n",
    "    \n",
    "    \n",
    "    if weighted_averaging : \n",
    "        aggregate_training_metadata = np.average(carrier_labels, weights = target_performance, axis = 0)\n",
    "    else : \n",
    "        aggregate_training_metadata = np.average(carrier_labels, axis = 0) \n",
    "\n",
    "    return aggregate_training_metadata\n",
    "\n",
    "\n",
    "def collect_metadatas(nodes, seed, alpha) : \n",
    "    # Collect training metadata\n",
    "    pub_scores, target_performances = [], []\n",
    "    for i, node in enumerate(nodes) : \n",
    "        training_metadata, target_performance = node.get_training_metadata(seed, alpha) \n",
    "        pub_scores.append(training_metadata)\n",
    "        target_performances.append(target_performance) \n",
    "    return pub_scores, target_performances \n",
    "\n",
    "\n",
    "class FedAMDNode : \n",
    "\n",
    "    model = None \n",
    "    carrier_dataset_metadata = None\n",
    "    carrier_datset = None\n",
    "\n",
    "    local_target_dataset = None \n",
    "    target_validation_set = None \n",
    "\n",
    "    target_validation_acc = []\n",
    "    target_validation_loss = [] \n",
    "\n",
    "\n",
    "    def __init__(self, model, local_target_dataset, shared_public_dataset, target_validation_gen) : \n",
    "        self.model = model \n",
    "        self.local_target_dataset = local_target_dataset\n",
    "        self.shared_public_dataset = shared_public_dataset\n",
    "        self.target_validation_gen = target_validation_gen\n",
    "\n",
    "\n",
    "    def get_training_metadata(self, seed, alpha) : \n",
    "\n",
    "        self.seed = seed \n",
    "        self.alpha = alpha\n",
    "        carrier_preds = self.get_carrier_scores() \n",
    "        target_performance = self.evaluate_on_validation_set(save = False)[1]\n",
    "        data_shape = carrier_preds.shape\n",
    "\n",
    "        # carrier_preds = from_categorical(carrier_preds) \n",
    "\n",
    "        # print(\"carrier_preds:{}  new_labels:{}\".format(carrier_preds.shape, new_labels.shape))\n",
    "        return carrier_preds, target_performance\n",
    "\n",
    "\n",
    "    def get_carrier_scores(self) : \n",
    "        \n",
    "        x = self.shared_public_dataset[0]\n",
    "        np.random.seed(self.seed) \n",
    "        index = np.random.permutation(len(x))  \n",
    "        mixed_x = self.alpha * x + (1 - self.alpha) * x[index, ...]\n",
    "    \n",
    "        return self.model[1].predict(mixed_x, batch_size = 32)\n",
    "\n",
    "\n",
    "    def receive_training_metadata(self, metadata) : \n",
    "\n",
    "        self.update_public_dataset_labels(metadata) \n",
    "\n",
    "\n",
    "    def update_public_dataset_labels(self, metadata) : \n",
    "        new_shared_public_dataset = (self.shared_public_dataset[0], metadata )\n",
    "        \n",
    "        self.shared_public_dataset = new_shared_public_dataset\n",
    "\n",
    "\n",
    "    def evaluate_on_validation_set(self, save = True) : \n",
    "        eval_x, eval_y = self.target_validation_gen\n",
    "        loss, acc = self.model[0].evaluate(eval_x, eval_y, batch_size = 32, verbose = False)\n",
    "        if save : \n",
    "            self.target_validation_loss.append(loss)\n",
    "            self.target_validation_acc.append(acc)\n",
    "        return loss, acc\n",
    "\n",
    "    def train_on_target(self, epochs = 1, use_callbacks = False, verbose = True, logger_file = None, evaluate = False) :\n",
    "        if use_callbacks : cbs = [EarlyStopping(monitor = 'val_loss', patience = 7, restore_best_weights= True)]\n",
    "        else : cbs = []\n",
    "        if logger_file : \n",
    "            cbs.append([CSVLogger(filename = logger_file, append = True)])\n",
    "        if evaluate : \n",
    "            history = self.model[0].fit(self.local_target_dataset[0], self.local_target_dataset[1], \\\n",
    "                validation_data = self.target_validation_gen, epochs = epochs, callbacks = cbs, verbose = verbose)\n",
    "        else : \n",
    "\n",
    "            history = self.model[0].fit(self.local_target_dataset[0], self.local_target_dataset[1], epochs = epochs, \n",
    "                                        callbacks = cbs, verbose = verbose)\n",
    "\n",
    "\n",
    "    def train_on_public(self, epochs = 1, use_callbacks = False, verbose = True, logger_file = None) : \n",
    "\n",
    "        if use_callbacks : cbs = [EarlyStopping(monitor = 'val_loss', patience = 7, restore_best_weights= True)]\n",
    "        else : cbs = []\n",
    "        if logger_file : \n",
    "            cbs.append([CSVLogger(filename = logger_file, append = True)])\n",
    "    \n",
    "        x = self.shared_public_dataset[0]\n",
    "        np.random.seed(self.seed) \n",
    "        index = np.random.permutation(len(x))  \n",
    "        mixed_x = self.alpha * x + (1 - self.alpha) * x[index, ...]\n",
    "\n",
    "        history = self.model[1].fit(mixed_x, self.shared_public_dataset[1],\n",
    "         epochs = epochs, callbacks = cbs, verbose = verbose)\n",
    "\n",
    "\n",
    "\n",
    "    def save_model(self, model_path) : \n",
    "        self.model[0].save(model_path + '_classifier.h5') \n",
    "        self.model[1].save(model_path + '_regressor.h5') \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data and models setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = 'results'\n",
    "\n",
    "experiment_dir = os.path.join(results_dir, 'exp_smartHAR_FedWAKD')\n",
    "subdirs = ['local_train_iid', 'local_train_noniid', 'central_train_iid', 'central_train_noniid', 'iid', 'noniid']\n",
    "# subdirs = ['local_train_iid', 'local_train_noniid', 'central_train_iid', 'central_train_noniid', 'fedAMD_iid', 'fedAMD_noniid']\n",
    "if not os.path.exists(experiment_dir):\n",
    "    os.makedirs(experiment_dir)\n",
    "    for subdir in subdirs : \n",
    "        os.makedirs(os.path.join(experiment_dir, subdir))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "n_parties = 10\n",
    "n_samples_per_class = 20\n",
    "input_shape = (561,)\n",
    "n_alignment =  100\n",
    "n_iterations = 50 \n",
    "\n",
    "models_params = [\n",
    "    (5, 8, 0.1), # n1, n2, dropout_rate \n",
    "    (5, 10, 0.25), # n1, n2, dropout_rate \n",
    "    (7, 30, 0.15), # n1, n2, dropout_rate \n",
    "    (20, 70, 0.2), # n1, n2, dropout_rate \n",
    "\n",
    "\n",
    "\n",
    "    (90, 120, 0.1), \n",
    "    (99, 170, 0.15), \n",
    "    (93, 200, 0.25),\n",
    "\n",
    "    (200, 270, 0.1),\n",
    "    (240, 300, 0.15),\n",
    "    (290, 340, 0.25)\n",
    "]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../smartphone_HAR/train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/gadmohamed/Library/CloudStorage/GoogleDrive-ggad@lakeheadu.ca/My Drive/dead repos/FedAKD/explore_FL_results.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gadmohamed/Library/CloudStorage/GoogleDrive-ggad%40lakeheadu.ca/My%20Drive/dead%20repos/FedAKD/explore_FL_results.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m dataset_dir \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m../smartphone_HAR\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/gadmohamed/Library/CloudStorage/GoogleDrive-ggad%40lakeheadu.ca/My%20Drive/dead%20repos/FedAKD/explore_FL_results.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m train_data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(dataset_dir,\u001b[39m'\u001b[39;49m\u001b[39mtrain.csv\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gadmohamed/Library/CloudStorage/GoogleDrive-ggad%40lakeheadu.ca/My%20Drive/dead%20repos/FedAKD/explore_FL_results.ipynb#X14sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m test_data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(dataset_dir,\u001b[39m'\u001b[39m\u001b[39mtest.csv\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gadmohamed/Library/CloudStorage/GoogleDrive-ggad%40lakeheadu.ca/My%20Drive/dead%20repos/FedAKD/explore_FL_results.ipynb#X14sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m train_data \u001b[39m=\u001b[39m train_data\u001b[39m.\u001b[39msample(frac \u001b[39m=\u001b[39m \u001b[39m1.0\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/fl/lib/python3.9/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/fl/lib/python3.9/site-packages/pandas/util/_decorators.py:317\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    312\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    313\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[1;32m    314\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    315\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(inspect\u001b[39m.\u001b[39mcurrentframe()),\n\u001b[1;32m    316\u001b[0m     )\n\u001b[0;32m--> 317\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/fl/lib/python3.9/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/miniforge3/envs/fl/lib/python3.9/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    607\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/miniforge3/envs/fl/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/miniforge3/envs/fl/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1729\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1727\u001b[0m     is_text \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1728\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1729\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1730\u001b[0m     f,\n\u001b[1;32m   1731\u001b[0m     mode,\n\u001b[1;32m   1732\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1733\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1734\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1735\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1736\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1737\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1738\u001b[0m )\n\u001b[1;32m   1739\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1740\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/miniforge3/envs/fl/lib/python3.9/site-packages/pandas/io/common.py:857\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    852\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    853\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    855\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    856\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    858\u001b[0m             handle,\n\u001b[1;32m    859\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    860\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    861\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    862\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    863\u001b[0m         )\n\u001b[1;32m    864\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    865\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    866\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../smartphone_HAR/train.csv'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "dataset_dir = '../smartphone_HAR'\n",
    "train_data = pd.read_csv(os.path.join(dataset_dir,'train.csv'))\n",
    "test_data = pd.read_csv(os.path.join(dataset_dir,'test.csv'))\n",
    "\n",
    "train_data = train_data.sample(frac = 1.0)\n",
    "\n",
    "train_data_len = int(0.9 * len(train_data) ) \n",
    "train_data, public_data = train_data.iloc[:train_data_len], train_data.iloc[train_data_len:]\n",
    "\n",
    "# Eliminate last two columns from the x data ('subject', 'label') \n",
    "x_train, y_train = train_data.iloc[:, :-2], train_data.iloc[:, -1:] \n",
    "x_test, y_test = test_data.iloc[:, :-2], test_data.iloc[:, -1:]\n",
    "\n",
    "pub_x, pub_y = public_data.iloc[:, :-2], public_data.iloc[:, -1:]\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)\n",
    "pub_y = le.transform(pub_y) \n",
    "\n",
    "scaling_data = MinMaxScaler()\n",
    "x_train = scaling_data.fit_transform(x_train)\n",
    "x_test = scaling_data.transform(x_test)\n",
    "pub_x = scaling_data.transform(pub_x) \n",
    "\n",
    "n_classes = len(le.classes_)\n",
    "original_labels = le.classes_\n",
    "pri_x_list, pri_y_list, pri_x_total, pri_y_total  = split_dataset(x_train, y_train, include_classes = 'all', samples_per_class = n_samples_per_class ,\\\n",
    "                                                                n_models = n_parties, to_categorical = True) \n",
    "y_train_cat = to_categorical(y_train, num_classes = n_classes)\n",
    "y_test_cat = to_categorical(y_test, num_classes = n_classes)\n",
    "pub_y_cat = to_categorical(pub_y, num_classes = n_classes)\n",
    "\n",
    "print(f'Shape of x train data is: {x_train.shape}. Shape of  y train data is: {y_train.shape}')\n",
    "print(f'Shape of x test data is: {x_test.shape}. Shape of y test data is: {y_test.shape}')\n",
    "print(f\"Shape of x public data is: {pub_x.shape}. Shape of y public data is: {pub_y.shape}\")\n",
    "print(f\"Single local x train is: {pri_x_list[0].shape}. Shape of single y train is: {pri_y_list[0].shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federated learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## i.i.d. clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_batches shape :  (6616, 561)\n",
      "train_labels shape :  (6616,)\n",
      "pub_data_batches shape :  (736, 561)\n",
      "pub_data_labels shape :  (736,)\n",
      "test_batches shape :  (2947, 561)\n",
      "cat_test_labels shape :  (2947, 6)\n",
      "pri_x_list shape :  (120, 561)\n",
      "pri_y_list shape :  (120, 6)\n",
      "pri_x_total shape :  (1200, 561)\n",
      "pri_y_total shape :  (1200, 6)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "iid_models = [get_model(n_classes, input_shape, model_params ) for model_params in models_params] \n",
    "\n",
    "# print data shapes\n",
    "print('train_batches shape : ', x_train.shape)\n",
    "print('train_labels shape : ', y_train.shape)\n",
    "print('pub_data_batches shape : ', pub_x.shape)\n",
    "print('pub_data_labels shape : ', pub_y.shape)\n",
    "print('test_batches shape : ', x_test.shape)\n",
    "print('cat_test_labels shape : ', y_test_cat.shape)\n",
    "\n",
    "print('pri_x_list shape : ', pri_x_list[0].shape)\n",
    "print('pri_y_list shape : ', pri_y_list[0].shape)\n",
    "print('pri_x_total shape : ', pri_x_total.shape)\n",
    "print('pri_y_total shape : ', pri_y_total.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on own private dataset only\n",
    "local_models = [get_model(n_classes, input_shape, model_params )[0] for model_params in models_params] \n",
    "for i, model in enumerate(local_models) : \n",
    "    local_training_history = model.fit(pri_x_list[i], pri_y_list[i], validation_data = (x_test, y_test_cat), epochs = 20, verbose = True)\n",
    "    pd.DataFrame(local_training_history.history).to_csv(os.path.join(experiment_dir, 'local_train_iid', 'local_training_{}.csv'.format(i)))\n",
    "\n",
    "# Training a model on all distributed dataset (centralized training). \n",
    "centralized_models = [get_model(n_classes, input_shape, model_params )[0] for model_params in models_params] \n",
    "for i, model in enumerate(centralized_models) : \n",
    "    centralized_training_history = model.fit(pri_x_total, pri_y_total, validation_data = (x_test, y_test_cat), epochs = 20, verbose = True)\n",
    "    pd.DataFrame(centralized_training_history.history).to_csv(os.path.join(experiment_dir, 'central_train_iid', 'centralized_training_{}.csv'.format(i)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "shared_public_dataset = (pub_x[:n_alignment, ...], pub_y[:n_alignment, ...])\n",
    "validation_dataset = (x_test, y_test_cat)\n",
    "fedmd_nodes = [FedAMDNode(iid_models[i], (pri_x_list[i], pri_y_list[i]), shared_public_dataset, target_validation_gen = validation_dataset) for i in range(n_parties)]\n",
    "\n",
    "# Training iterations \n",
    "for iteration in range(n_iterations) : \n",
    "  print('\\n Iteration:', iteration)\n",
    "\n",
    "  for i, node in enumerate(fedmd_nodes) : \n",
    "    logger_file = os.path.join(experiment_dir,'iid', 'train_{}.csv'.format(i))\n",
    "    node.train_on_target(epochs = 2, verbose = False, logger_file = logger_file, evaluate = True)\n",
    "\n",
    "  # seed and alpha variables are not used in FedMD since it uses Node not FedAMDNode\n",
    "  seed = np.random.randint(0, 10000) \n",
    "  alpha = np.random.rand()\n",
    "\n",
    "  pub_scores, priv_performances = collect_metadatas(fedmd_nodes, seed, alpha) \n",
    "  print(\"models' accuracies:\", priv_performances) \n",
    "  print(\"Avg Acc:{} Mean:{} Std:{}\".format(np.mean(priv_performances), np.mean(pub_scores), np.std(pub_scores)))\n",
    "  \n",
    "  # Aggregate training metadata \n",
    "  weighted_pub_scores = aggregate_training_metadatas(pub_scores, priv_performances, weighted_averaging = True) \n",
    "\n",
    "\n",
    "  # Receive training metadata (and rebuilds Carrier dataset with updated labels)\n",
    "  for i, node in enumerate(fedmd_nodes) : \n",
    "    node.receive_training_metadata(weighted_pub_scores)   \n",
    "    node.train_on_public(epochs = 1, verbose = False) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-i.i.d. clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_batches shape :  (6616, 561)\n",
      "train_labels shape :  (6616,)\n",
      "pub_data_batches shape :  (736, 561)\n",
      "pub_data_labels shape :  (736,)\n",
      "test_batches shape :  (2947, 561)\n",
      "categorical test_labels shape :  (2947, 6)\n",
      "_____________________________________________\n",
      "pri_x_total shape :  (100, 561)\n",
      "pri_y_total shape :  (100, 6)\n",
      "pri_x_total shape :  (80, 561)\n",
      "pri_y_total shape :  (80, 6)\n",
      "pri_x_total shape :  (60, 561)\n",
      "pri_y_total shape :  (60, 6)\n",
      "pri_x_total shape :  (60, 561)\n",
      "pri_y_total shape :  (60, 6)\n",
      "pri_x_total shape :  (80, 561)\n",
      "pri_y_total shape :  (80, 6)\n",
      "pri_x_total shape :  (100, 561)\n",
      "pri_y_total shape :  (100, 6)\n",
      "pri_x_total shape :  (60, 561)\n",
      "pri_y_total shape :  (60, 6)\n",
      "pri_x_total shape :  (100, 561)\n",
      "pri_y_total shape :  (100, 6)\n",
      "pri_x_total shape :  (80, 561)\n",
      "pri_y_total shape :  (80, 6)\n",
      "pri_x_total shape :  (60, 561)\n",
      "pri_y_total shape :  (60, 6)\n",
      "_____________________________________________\n",
      "pri_x_total shape :  (1200, 561)\n",
      "pri_y_total shape :  (1200, 6)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "parties_classes = [\n",
    "    [0, 1, 2, 3, 4], \n",
    "    [0, 1, 4, 5], \n",
    "    [2, 3, 4],\n",
    "    [0, 2, 3],\n",
    "    [1, 2, 3, 5],\n",
    "    [0, 1, 3, 4, 2],\n",
    "    [0, 1, 2],\n",
    "    [0, 1, 2, 3, 5],\n",
    "    [0, 3, 4, 5], \n",
    "    [1, 2, 5]\n",
    "]\n",
    "noniid_models = [get_model(n_classes, input_shape, model_params ) for model_params in models_params] \n",
    "\n",
    "\n",
    "pri_x_list_noniid, pri_y_list_noniid, pri_x_total_noniid, pri_y_total_noniid  = split_dataset(x_train, y_train, samples_per_class = n_samples_per_class ,\\\n",
    "                                                                n_models = n_parties, include_classes = parties_classes, to_categorical = True) \n",
    "\n",
    "\n",
    "\n",
    "# print data shapes\n",
    "print('train_batches shape : ', x_train.shape)\n",
    "print('train_labels shape : ', y_train.shape)\n",
    "print('pub_data_batches shape : ', pub_x.shape)\n",
    "print('pub_data_labels shape : ', pub_y.shape)\n",
    "print('test_batches shape : ', x_test.shape)\n",
    "print('categorical test_labels shape : ', y_test_cat.shape)\n",
    "\n",
    "print(\"_____________________________________________\")\n",
    "for i in range(n_parties):\n",
    "  print('pri_x_total shape : ', pri_x_list_noniid[i].shape)\n",
    "  print('pri_y_total shape : ', pri_y_list_noniid[i].shape)\n",
    "print(\"_____________________________________________\")\n",
    "print('pri_x_total shape : ', pri_x_total_noniid.shape)\n",
    "print('pri_y_total shape : ', pri_y_total_noniid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on own private dataset only\n",
    "local_models = [get_model(n_classes, input_shape, model_params )[0] for model_params in models_params] \n",
    "for i, model in enumerate(local_models) : \n",
    "    local_training_history = model.fit(pri_x_list_noniid[i], pri_y_list_noniid[i], validation_data = (x_test, y_test_cat), epochs = 20, verbose = True)\n",
    "    pd.DataFrame(local_training_history.history).to_csv(os.path.join(experiment_dir, 'local_train_noniid', 'local_training_{}.csv'.format(i)))\n",
    "\n",
    "# Training a model on all distributed dataset (centralized training). \n",
    "centralized_models = [get_model(n_classes, input_shape, model_params )[0] for model_params in models_params] \n",
    "for i, model in enumerate(centralized_models) : \n",
    "    centralized_training_history = model.fit(pri_x_total_noniid, pri_y_total_noniid, validation_data = (x_test, y_test_cat), epochs = 20, verbose = True)\n",
    "    pd.DataFrame(centralized_training_history.history).to_csv(os.path.join(experiment_dir, 'central_train_noniid', 'centralized_training_{}.csv'.format(i)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Iteration: 0\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 988us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.15982355177402496, 0.36579573154449463, 0.05361384525895119, 0.23108245432376862, 0.4418052136898041, 0.31795045733451843, 0.12453342229127884, 0.49575838446617126, 0.2514421343803406, 0.39667457342147827]\n",
      "Avg Acc:0.28384797684848306 Mean:-0.06838959455490112 Std:1.6745089292526245\n",
      "\n",
      " Iteration: 1\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.17509330809116364, 0.35018661618232727, 0.18255853652954102, 0.16661010682582855, 0.3444180488586426, 0.31591448187828064, 0.30607396364212036, 0.44960978627204895, 0.3254156708717346, 0.3434000611305237]\n",
      "Avg Acc:0.29592805802822114 Mean:-0.08300695568323135 Std:1.3673005104064941\n",
      "\n",
      " Iteration: 2\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.16830675303936005, 0.44384118914604187, 0.34815067052841187, 0.16728876531124115, 0.39429929852485657, 0.3769935667514801, 0.3254156708717346, 0.36104512214660645, 0.3250763416290283, 0.41092637181282043]\n",
      "Avg Acc:0.33213437497615816 Mean:-0.04846369847655296 Std:1.327269434928894\n",
      "\n",
      " Iteration: 3\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.21445538103580475, 0.49643704295158386, 0.3349168598651886, 0.21106210350990295, 0.36477774381637573, 0.3793688416481018, 0.31862911581993103, 0.6749236583709717, 0.3379708230495453, 0.4224635362625122]\n",
      "Avg Acc:0.3755005106329918 Mean:-0.06191064789891243 Std:1.2542662620544434\n",
      "\n",
      " Iteration: 4\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 988us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.22395657002925873, 0.4716660976409912, 0.3383101522922516, 0.3311842679977417, 0.44791314005851746, 0.35833051800727844, 0.3359348475933075, 0.6878181099891663, 0.3322022259235382, 0.4251781404018402]\n",
      "Avg Acc:0.3952494069933891 Mean:-0.02594105526804924 Std:1.263675570487976\n",
      "\n",
      " Iteration: 5\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.22158126533031464, 0.4872751832008362, 0.3400067985057831, 0.3372921645641327, 0.49813368916511536, 0.35934847593307495, 0.3267729878425598, 0.5259585976600647, 0.3345775306224823, 0.41398030519485474]\n",
      "Avg Acc:0.38449269980192186 Mean:-0.01993848755955696 Std:1.2425875663757324\n",
      "\n",
      " Iteration: 6\n",
      "4/4 [==============================] - 0s 983us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.192059725522995, 0.46046826243400574, 0.3413640856742859, 0.3393281400203705, 0.4845605790615082, 0.3406854569911957, 0.3383101522922516, 0.6647437810897827, 0.3756362497806549, 0.41160503029823303]\n",
      "Avg Acc:0.39487614631652834 Mean:0.004352443851530552 Std:1.408326268196106\n",
      "\n",
      " Iteration: 7\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.17203935980796814, 0.5361384749412537, 0.3403461277484894, 0.3403461277484894, 0.49372243881225586, 0.3810654878616333, 0.3311842679977417, 0.5524262189865112, 0.3271123170852661, 0.4285714328289032]\n",
      "Avg Acc:0.3902952253818512 Mean:0.035453781485557556 Std:1.3060402870178223\n",
      "\n",
      " Iteration: 8\n",
      "4/4 [==============================] - 0s 998us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.16966407001018524, 0.5117068290710449, 0.3396674692630768, 0.3403461277484894, 0.4699694514274597, 0.34645402431488037, 0.3383101522922516, 0.5096708536148071, 0.3240583539009094, 0.4316253960132599]\n",
      "Avg Acc:0.3781472727656364 Mean:0.047710247337818146 Std:1.388187289237976\n",
      "\n",
      " Iteration: 9\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.16898541152477264, 0.5283339023590088, 0.3403461277484894, 0.3403461277484894, 0.5724465847015381, 0.3410247564315796, 0.3403461277484894, 0.6647437810897827, 0.3386494815349579, 0.4356973171234131]\n",
      "Avg Acc:0.4070919618010521 Mean:0.036424268037080765 Std:1.3329076766967773\n",
      "\n",
      " Iteration: 10\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 998us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.16830675303936005, 0.5147607922554016, 0.3396674692630768, 0.3403461277484894, 0.5391923785209656, 0.3698676526546478, 0.3396674692630768, 0.6569392681121826, 0.3440787196159363, 0.4353579878807068]\n",
      "Avg Acc:0.4048184618353844 Mean:0.06684277206659317 Std:1.503675103187561\n",
      "\n",
      " Iteration: 11\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 998us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.16830675303936005, 0.5503902435302734, 0.337631493806839, 0.3366135060787201, 0.49168646335601807, 0.328130304813385, 0.3318628966808319, 0.6467593908309937, 0.3250763416290283, 0.4370546340942383]\n",
      "Avg Acc:0.3953512027859688 Mean:0.12105239182710648 Std:1.5812231302261353\n",
      "\n",
      " Iteration: 12\n",
      "4/4 [==============================] - 0s 998us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.16830675303936005, 0.61588054895401, 0.3403461277484894, 0.35934847593307495, 0.5561587810516357, 0.34815067052841187, 0.3729216158390045, 0.5687139630317688, 0.4855785667896271, 0.4356973171234131]\n",
      "Avg Acc:0.42511028200387957 Mean:0.15420246124267578 Std:1.5915547609329224\n",
      "\n",
      " Iteration: 13\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.16830675303936005, 0.5683746337890625, 0.3403461277484894, 0.36511707305908203, 0.5212079882621765, 0.40719375014305115, 0.3837801218032837, 0.5459789633750916, 0.3756362497806549, 0.4370546340942383]\n",
      "Avg Acc:0.411299629509449 Mean:0.12942299246788025 Std:1.3673409223556519\n",
      "\n",
      " Iteration: 14\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.17102137207984924, 0.5629453659057617, 0.3393281400203705, 0.36240243911743164, 0.5643026828765869, 0.39938920736312866, 0.4129623472690582, 0.5137428045272827, 0.41465896368026733, 0.4285714328289032]\n",
      "Avg Acc:0.416932475566864 Mean:0.136915385723114 Std:1.6291290521621704\n",
      "\n",
      " Iteration: 15\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.16830675303936005, 0.5985748171806335, 0.3406854569911957, 0.3457753658294678, 0.5239226222038269, 0.40312182903289795, 0.421106219291687, 0.6996946334838867, 0.380726158618927, 0.4343400001525879]\n",
      "Avg Acc:0.43162538558244706 Mean:0.0977746918797493 Std:1.3532559871673584\n",
      "\n",
      " Iteration: 16\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.16966407001018524, 0.6063793897628784, 0.3410247564315796, 0.3393281400203705, 0.4326433539390564, 0.3909060060977936, 0.390227347612381, 0.554462194442749, 0.36443841457366943, 0.4360366463661194]\n",
      "Avg Acc:0.4025110319256783 Mean:0.11406189203262329 Std:1.5435420274734497\n",
      "\n",
      " Iteration: 17\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.17068204283714294, 0.6050220727920532, 0.3413640856742859, 0.3393281400203705, 0.5548014640808105, 0.4241601526737213, 0.4353579878807068, 0.6963013410568237, 0.4268747866153717, 0.4265354573726654]\n",
      "Avg Acc:0.4420427531003952 Mean:0.10377451777458191 Std:1.5100009441375732\n",
      "\n",
      " Iteration: 18\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 998us/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.16830675303936005, 0.6073973774909973, 0.3403461277484894, 0.3389888107776642, 0.4777739942073822, 0.44078725576400757, 0.45368170738220215, 0.724465548992157, 0.3403461277484894, 0.442823201417923]\n",
      "Avg Acc:0.4334916904568672 Mean:0.08302248269319534 Std:1.422257900238037\n",
      "\n",
      " Iteration: 19\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.17237868905067444, 0.612487256526947, 0.3406854569911957, 0.3383101522922516, 0.596878170967102, 0.5341024994850159, 0.5436036586761475, 0.6362402439117432, 0.4784526526927948, 0.4336613416671753]\n",
      "Avg Acc:0.4686800122261047 Mean:0.09092974662780762 Std:1.6555395126342773\n",
      "\n",
      " Iteration: 20\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.17068204283714294, 0.5853410363197327, 0.3400067985057831, 0.3379708230495453, 0.538513720035553, 0.5469969511032104, 0.5273159146308899, 0.5324058532714844, 0.4133016765117645, 0.4356973171234131]\n",
      "Avg Acc:0.44282321333885194 Mean:0.06923075020313263 Std:1.5438779592514038\n",
      "\n",
      " Iteration: 21\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.16898541152477264, 0.6087546944618225, 0.3400067985057831, 0.3383101522922516, 0.5127248167991638, 0.4764167070388794, 0.4648795425891876, 0.631489634513855, 0.35052594542503357, 0.4394299387931824]\n",
      "Avg Acc:0.4331523641943932 Mean:0.0627397820353508 Std:1.4763264656066895\n",
      "\n",
      " Iteration: 22\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "models' accuracies: [0.17102137207984924, 0.5571767687797546, 0.3403461277484894, 0.3383101522922516, 0.5924668908119202, 0.49575838446617126, 0.49541908502578735, 0.689854085445404, 0.3875127136707306, 0.4241601526737213]\n",
      "Avg Acc:0.44920257329940794 Mean:0.08089752495288849 Std:1.5575523376464844\n",
      "\n",
      " Iteration: 23\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.17102137207984924, 0.6104512810707092, 0.3403461277484894, 0.3379708230495453, 0.541907012462616, 0.5201900005340576, 0.49338310956954956, 0.5826264023780823, 0.39667457342147827, 0.4384119510650635]\n",
      "Avg Acc:0.44329826533794403 Mean:0.0855245366692543 Std:1.47105872631073\n",
      "\n",
      " Iteration: 24\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.16830675303936005, 0.6067187190055847, 0.3413640856742859, 0.35188326239585876, 0.5615880489349365, 0.5602307319641113, 0.5398710370063782, 0.7550050616264343, 0.3919239938259125, 0.44485917687416077]\n",
      "Avg Acc:0.4721750870347023 Mean:0.08337599039077759 Std:1.761070966720581\n",
      "\n",
      " Iteration: 25\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.16830675303936005, 0.6121479272842407, 0.3450967073440552, 0.35120460391044617, 0.5921275615692139, 0.4343400001525879, 0.559891402721405, 0.6131659150123596, 0.45978960394859314, 0.4370546340942383]\n",
      "Avg Acc:0.45731251090765 Mean:0.06755023449659348 Std:1.746156096458435\n",
      "\n",
      " Iteration: 26\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 998us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.16830675303936005, 0.5551407933235168, 0.34373939037323, 0.35731253027915955, 0.5391923785209656, 0.5089921951293945, 0.5218866467475891, 0.7645062804222107, 0.4285714328289032, 0.4278927743434906]\n",
      "Avg Acc:0.461554117500782 Mean:0.04996046796441078 Std:1.5680701732635498\n",
      "\n",
      " Iteration: 27\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "models' accuracies: [0.16830675303936005, 0.6118085980415344, 0.3430607318878174, 0.36545640230178833, 0.5171360969543457, 0.597896158695221, 0.5809297561645508, 0.6538853049278259, 0.4723447561264038, 0.41601628065109253]\n",
      "Avg Acc:0.47268408387899397 Mean:0.02537345141172409 Std:1.6535016298294067\n",
      "\n",
      " Iteration: 28\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "models' accuracies: [0.16864608228206635, 0.6135052442550659, 0.35391923785209656, 0.36918899416923523, 0.6050220727920532, 0.5792331099510193, 0.5704106092453003, 0.7743467688560486, 0.3749575912952423, 0.40685442090034485]\n",
      "Avg Acc:0.48160841315984726 Mean:0.01318011712282896 Std:1.7563358545303345\n",
      "\n",
      " Iteration: 29\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "models' accuracies: [0.16830675303936005, 0.5900916457176208, 0.3430607318878174, 0.3769935667514801, 0.5045809149742126, 0.585680365562439, 0.5785544514656067, 0.6525279879570007, 0.4899898171424866, 0.41058704257011414]\n",
      "Avg Acc:0.47003732770681383 Mean:0.021171415224671364 Std:1.9411251544952393\n",
      "\n",
      " Iteration: 30\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "models' accuracies: [0.16830675303936005, 0.6141839027404785, 0.34645402431488037, 0.3824228048324585, 0.591109573841095, 0.6243637800216675, 0.5819477438926697, 0.5269765853881836, 0.49643704295158386, 0.4336613416671753]\n",
      "Avg Acc:0.4765863552689552 Mean:0.0021233863662928343 Std:1.8087083101272583\n",
      "\n",
      " Iteration: 31\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "models' accuracies: [0.16898541152477264, 0.6138445734977722, 0.34916865825653076, 0.3430607318878174, 0.5710892677307129, 0.5656599998474121, 0.57550048828125, 0.7845266461372375, 0.5514082312583923, 0.4377332925796509]\n",
      "Avg Acc:0.4960977301001549 Mean:-0.024203892797231674 Std:1.6867059469223022\n",
      "\n",
      " Iteration: 32\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "models' accuracies: [0.17305734753608704, 0.61588054895401, 0.3444180488586426, 0.3403461277484894, 0.5619273781776428, 0.5727858543395996, 0.5870376825332642, 0.758059024810791, 0.5663386583328247, 0.44994911551475525]\n",
      "Avg Acc:0.49697997868061067 Mean:-0.04918905720114708 Std:1.7355825901031494\n",
      "\n",
      " Iteration: 33\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "models' accuracies: [0.17475399374961853, 0.5690532922744751, 0.3406854569911957, 0.3393281400203705, 0.5948421955108643, 0.6111299395561218, 0.5904309749603271, 0.773668110370636, 0.5751611590385437, 0.4414658844470978]\n",
      "Avg Acc:0.501051914691925 Mean:-0.04895230755209923 Std:1.6413267850875854\n",
      "\n",
      " Iteration: 34\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "models' accuracies: [0.16898541152477264, 0.5805904269218445, 0.3427214026451111, 0.3450967073440552, 0.5887343287467957, 0.6155412197113037, 0.5721072554588318, 0.6637257933616638, 0.6043434143066406, 0.4384119510650635]\n",
      "Avg Acc:0.4920257911086082 Mean:-0.031447429209947586 Std:1.9202628135681152\n",
      "\n",
      " Iteration: 35\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "models' accuracies: [0.16830675303936005, 0.6141839027404785, 0.3423820734024048, 0.3742789328098297, 0.5907703042030334, 0.6138445734977722, 0.5948421955108643, 0.7051238417625427, 0.5246012806892395, 0.46250423789024353]\n",
      "Avg Acc:0.4990838095545769 Mean:-0.10289545357227325 Std:1.671302318572998\n",
      "\n",
      " Iteration: 36\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "models' accuracies: [0.17034272849559784, 0.6111299395561218, 0.3444180488586426, 0.35290125012397766, 0.49100780487060547, 0.5768578052520752, 0.5924668908119202, 0.6586359143257141, 0.514082133769989, 0.39667457342147827]\n",
      "Avg Acc:0.4708517089486122 Mean:-0.08222696930170059 Std:1.8151787519454956\n",
      "\n",
      " Iteration: 37\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "models' accuracies: [0.18086189031600952, 0.597896158695221, 0.3454360365867615, 0.36851033568382263, 0.594502866268158, 0.5303698778152466, 0.578893780708313, 0.7811333537101746, 0.41533762216567993, 0.4200882315635681]\n",
      "Avg Acc:0.4813030153512955 Mean:-0.07926560193300247 Std:1.8073114156723022\n",
      "\n",
      " Iteration: 38\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "models' accuracies: [0.1849338263273239, 0.6118085980415344, 0.34679335355758667, 0.3434000611305237, 0.5527655482292175, 0.6182558536529541, 0.6409908533096313, 0.7261621952056885, 0.5900916457176208, 0.4275534451007843]\n",
      "Avg Acc:0.5042755380272865 Mean:-0.1331760734319687 Std:1.7040740251541138\n",
      "\n",
      " Iteration: 39\n",
      "4/4 [==============================] - 0s 998us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "models' accuracies: [0.17373600602149963, 0.5975568294525146, 0.34373939037323, 0.3396674692630768, 0.5283339023590088, 0.6152018904685974, 0.634882926940918, 0.7583983540534973, 0.510688841342926, 0.46318289637565613]\n",
      "Avg Acc:0.49653885066509246 Mean:-0.13324248790740967 Std:1.8031591176986694\n",
      "\n",
      " Iteration: 40\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "models' accuracies: [0.16898541152477264, 0.594502866268158, 0.3440787196159363, 0.3417034149169922, 0.5639633536338806, 0.6029860973358154, 0.5995928049087524, 0.7760434150695801, 0.5707499384880066, 0.44418051838874817]\n",
      "Avg Acc:0.5006786540150643 Mean:-0.13924166560173035 Std:1.6904141902923584\n",
      "\n",
      " Iteration: 41\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "models' accuracies: [0.16898541152477264, 0.6189345121383667, 0.3440787196159363, 0.34713268280029297, 0.600271463394165, 0.6101119518280029, 0.5917882323265076, 0.7529691457748413, 0.5093315243721008, 0.44519850611686707]\n",
      "Avg Acc:0.49888021498918533 Mean:-0.11688248813152313 Std:1.9669522047042847\n",
      "\n",
      " Iteration: 42\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "models' accuracies: [0.17271801829338074, 0.6145232319831848, 0.3457753658294678, 0.34916865825653076, 0.5724465847015381, 0.6019681096076965, 0.6175771951675415, 0.7672209143638611, 0.6477773785591125, 0.470308780670166]\n",
      "Avg Acc:0.515948423743248 Mean:-0.16101238131523132 Std:1.7176549434661865\n",
      "\n",
      " Iteration: 43\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "models' accuracies: [0.17509330809116364, 0.6165592074394226, 0.3447573781013489, 0.35697320103645325, 0.5748218297958374, 0.6772989630699158, 0.6016287803649902, 0.7475398778915405, 0.5378350615501404, 0.4760773777961731]\n",
      "Avg Acc:0.5108584985136986 Mean:-0.1693284958600998 Std:1.858167052268982\n",
      "\n",
      " Iteration: 44\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "models' accuracies: [0.17814727127552032, 0.6101119518280029, 0.34882932901382446, 0.36206310987472534, 0.6026467680931091, 0.6722090244293213, 0.6087546944618225, 0.6946046948432922, 0.5802510976791382, 0.45775365829467773]\n",
      "Avg Acc:0.5115371599793435 Mean:-0.19017620384693146 Std:1.8615766763687134\n",
      "\n",
      " Iteration: 45\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 8ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "models' accuracies: [0.17577196657657623, 0.6111299395561218, 0.3444180488586426, 0.36375975608825684, 0.541907012462616, 0.6216491460800171, 0.5900916457176208, 0.7475398778915405, 0.5473362803459167, 0.4767560362815857]\n",
      "Avg Acc:0.5020359709858895 Mean:-0.19579492509365082 Std:1.733677625656128\n",
      "\n",
      " Iteration: 46\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "models' accuracies: [0.17509330809116364, 0.6016287803649902, 0.3427214026451111, 0.3440787196159363, 0.5931455492973328, 0.6284356713294983, 0.5877163410186768, 0.6884967684745789, 0.5792331099510193, 0.4821852743625641]\n",
      "Avg Acc:0.5022734925150871 Mean:-0.19809827208518982 Std:1.8331172466278076\n",
      "\n",
      " Iteration: 47\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "models' accuracies: [0.17271801829338074, 0.603664755821228, 0.3454360365867615, 0.3410247564315796, 0.5873770117759705, 0.6063793897628784, 0.6118085980415344, 0.7027485370635986, 0.4285714328289032, 0.5120461583137512]\n",
      "Avg Acc:0.4911774694919586 Mean:-0.24816350638866425 Std:1.7173141241073608\n",
      "\n",
      " Iteration: 48\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 11ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "models' accuracies: [0.18018323183059692, 0.6155412197113037, 0.35120460391044617, 0.34815067052841187, 0.5860196948051453, 0.6138445734977722, 0.6182558536529541, 0.6308109760284424, 0.5042415857315063, 0.4848999083042145]\n",
      "Avg Acc:0.49331523180007936 Mean:-0.22471407055854797 Std:2.001532554626465\n",
      "\n",
      " Iteration: 49\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "models' accuracies: [0.40481844544410706, 0.6135052442550659, 0.35324057936668396, 0.3851374387741089, 0.600271463394165, 0.693247377872467, 0.6749236583709717, 0.7315914630889893, 0.6304716467857361, 0.46216490864753723]\n",
      "Avg Acc:0.5549372225999832 Mean:-0.2852008044719696 Std:1.7298439741134644\n"
     ]
    }
   ],
   "source": [
    "\n",
    "shared_public_dataset = (pub_x[:n_alignment, ...], pub_y[:n_alignment, ...])\n",
    "validation_dataset = (x_test, y_test_cat)\n",
    "fedmd_nodes = [FedAMDNode(noniid_models[i], (pri_x_list_noniid[i], pri_y_list_noniid[i]), shared_public_dataset, target_validation_gen = validation_dataset) for i in range(n_parties)]\n",
    "\n",
    "# Training iterations \n",
    "for iteration in range(n_iterations) : \n",
    "  print('\\n Iteration:', iteration)\n",
    "\n",
    "  for i, node in enumerate(fedmd_nodes) : \n",
    "    # logger_file = os.path.join(experiment_dir,'fedMD_noniid', 'FedMD_train_{}.csv'.format(i))\n",
    "    logger_file = os.path.join(experiment_dir,'noniid', 'train_{}.csv'.format(i))\n",
    "    node.train_on_target(epochs = 2, verbose = False, logger_file = logger_file, evaluate = True)\n",
    "\n",
    "  # seed and alpha variables are not used in FedMD since it uses Node not FedAMDNode\n",
    "  seed = np.random.randint(0, 10000) \n",
    "  alpha = np.random.rand()\n",
    "\n",
    "  pub_scores, priv_performances = collect_metadatas(fedmd_nodes, seed, alpha) \n",
    "  print(\"models' accuracies:\", priv_performances) \n",
    "  print(\"Avg Acc:{} Mean:{} Std:{}\".format(np.mean(priv_performances), np.mean(pub_scores), np.std(pub_scores)))\n",
    "  \n",
    "  # Aggregate training metadata \n",
    "  weighted_pub_scores = aggregate_training_metadatas(pub_scores, priv_performances, weighted_averaging = True) \n",
    "\n",
    "\n",
    "  # Receive training metadata (and rebuilds Carrier dataset with updated labels)\n",
    "  for i, node in enumerate(fedmd_nodes) : \n",
    "    node.receive_training_metadata(weighted_pub_scores)   \n",
    "    node.train_on_public(epochs = 1, verbose = False) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def smooth(signal, window_len = 11, polyorder = 3) : \n",
    "    return savgol_filter(signal, window_length= window_len, polyorder = polyorder)\n",
    "\n",
    "def get_csv_files(dir) : \n",
    "    return [join(dir, f) for f in os.listdir(dir) if f.endswith('.csv')]\n",
    "\n",
    "\n",
    "class Experiment : \n",
    "\n",
    "    def __init__(self, root) : \n",
    "        self.root = root \n",
    "        self.colors = list(mcolors.TABLEAU_COLORS.keys())\n",
    "    \n",
    "    \n",
    "    def get_last_accuracies (self, subdir) : \n",
    "        return [pd.read_csv(f)['val_accuracy'].values[-1] for f in get_csv_files(join(self.root, subdir))]\n",
    "\n",
    "    def get_accuracies(self, subdir) : \n",
    "        return [pd.read_csv(f)['val_accuracy'] for f in get_csv_files(join(self.root, subdir))]\n",
    "    \n",
    "    def plot_fedMD_like(self, left, center, right, labels, shades = None, title = 'Accuracy', limit = None):\n",
    "        assert len(left) == len(right) == len(center), 'statistics should have the same length'\n",
    "        \n",
    "        n_epochs = len(center[0]) \n",
    "        epochs = np.arange(n_epochs) \n",
    "        n_parties = len(center)\n",
    "        if limit is None : \n",
    "            limit = n_parties \n",
    "        plt.figure(figsize=(20, 11))\n",
    "\n",
    "        plt.subplot(2, 2, 1)\n",
    "        for i in range(limit) : \n",
    "            if left is not None : \n",
    "                plt.hlines(y=left[i], xmin=-10, xmax=10, linestyle = '--', color = self.colors[i])\n",
    "            if right is not None : \n",
    "                plt.hlines(y=right[i], xmin=n_epochs-10, xmax=n_epochs+10, linestyle = '--', color = self.colors[i])\n",
    "            plt.plot(epochs, center[i], label=labels[i], color = self.colors[i])\n",
    "            if shades is not None :\n",
    "                plt.fill_between(epochs, shades[0][i], shades[1][i], alpha=0.1, color = self.colors[i])\n",
    "        plt.legend(loc='best', bbox_to_anchor=(0.95, 0.5))\n",
    "        plt.title(title) \n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.xlim(0, n_epochs)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def plot_fedMD_like_comparison(left, center, right, labels = None, shades = None, colors = None, title = None, limit = None) :\n",
    "    n_epochs = len(center[0]) \n",
    "    epochs = np.arange(n_epochs) \n",
    "    n_parties = len(center)\n",
    "    if limit is None : \n",
    "        limit = n_parties \n",
    "    plt.figure(figsize=(20, 11))\n",
    "    if colors is None : \n",
    "        colors = list(mcolors.TABLEAU_COLORS.keys())\n",
    "    plt.subplot(2, 2, 1)\n",
    "    for i in range(limit) : \n",
    "        if left is not None :\n",
    "            plt.hlines(y=left[i], xmin=-10, xmax=10, linestyle = '--', color = colors[i])\n",
    "        if right is not None : \n",
    "            plt.hlines(y=right[i], xmin=n_epochs-10, xmax=n_epochs+10, linestyle = '--', color = colors[i])\n",
    "        plt.plot(epochs, center[i], label=labels[i], color = colors[i])\n",
    "        if shades is not None :\n",
    "            plt.fill_between(epochs, shades[i][0], shades[i][0], alpha=0.1, color = colors[i])\n",
    "    plt.legend(loc='lower right', bbox_to_anchor=(0.95, 0.5))\n",
    "    plt.title(title) \n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlim(0, n_epochs)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Experiment' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/gadmohamed/Desktop/mac_local/FedAKD/HARB_FedAKD.ipynb Cell 24\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/gadmohamed/Desktop/mac_local/FedAKD/HARB_FedAKD.ipynb#X32sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m exp \u001b[39m=\u001b[39m Experiment(\u001b[39m'\u001b[39m\u001b[39mresults/FedMD\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gadmohamed/Desktop/mac_local/FedAKD/HARB_FedAKD.ipynb#X32sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m last_local_accs_iid \u001b[39m=\u001b[39m [\u001b[39m0\u001b[39m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_parties)] \u001b[39m# exp.get_last_accuracies('local_train_iid')\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gadmohamed/Desktop/mac_local/FedAKD/HARB_FedAKD.ipynb#X32sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m last_local_accs_noniid \u001b[39m=\u001b[39m [\u001b[39m0\u001b[39m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_parties)] \u001b[39m# exp.get_last_accuracies('local_train_noniid')\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Experiment' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "exp = Experiment('results/FedMD')\n",
    "last_local_accs_iid = [0 for i in range(n_parties)] # exp.get_last_accuracies('local_train_iid')\n",
    "last_local_accs_noniid = [0 for i in range(n_parties)] # exp.get_last_accuracies('local_train_noniid')\n",
    "\n",
    "last_central_accs_iid = [0 for i in range(n_parties)] #exp.get_last_accuracies('central_train_iid')\n",
    "last_central_accs_noniid = [0 for i in range(n_parties)] # exp.get_last_accuracies('central_train_noniid')\n",
    "\n",
    "fedAMD_iid = exp.get_accuracies('iid') \n",
    "fedAMD_noniid = exp.get_accuracies('noniid') \n",
    "smooth_iid = [smooth(acc) for acc in fedAMD_iid]\n",
    "smooth_noniid = [smooth(acc) for acc in fedAMD_noniid]\n",
    "\n",
    "# fedAMD_iid = exp.get_accuracies('fedMD_iid') \n",
    "# fedAMD_noniid = exp.get_accuracies('fedMD_noniid') \n",
    "\n",
    "# avg_left_iid, avg_right_iid = [np.mean(last_local_accs_iid)], [np.mean(last_central_accs_iid)]\n",
    "# avg_left_noniid, avg_right_noniid = [np.mean(last_local_accs_noniid)], [np.mean(last_central_accs_noniid)]\n",
    "\n",
    "smooth_center_iid = [smooth(np.mean(fedAMD_iid, axis = 0), window_len = 27, polyorder = 3)]\n",
    "smooth_center_noniid = [smooth(np.mean(fedAMD_noniid, axis = 0), window_len = 27, polyorder = 3)]\n",
    "\n",
    "center_iid = [np.mean(fedAMD_iid, axis = 0)]\n",
    "center_noniid = [np.mean(fedAMD_noniid, axis = 0)]\n",
    "\n",
    "# fedAMD_noniid_limits = [np.min(fedAMD_noniid, axis = 0), np.max(fedAMD_noniid, axis = 0)]\n",
    "# fedAMD_iid_limits = [np.min(fedAMD_iid, axis = 0), np.max(fedAMD_iid, axis = 0)]\n",
    "\n",
    "\n",
    "models_gains_iid = [int(round(fedAMD_iid[i].values[-1] - last_local_accs_iid[i], 2) *100) for i in range(len(last_local_accs_iid))]\n",
    "models_gains_noniid = [int(round(fedAMD_noniid[i].values[-1] - last_local_accs_noniid[i], 2) *100) for i in range(len(last_local_accs_noniid))]\n",
    "print('models gains iid:', models_gains_iid)\n",
    "print('models gains noniid:', models_gains_noniid)\n",
    "\n",
    "ts = [last_local_accs_iid, smooth_iid, last_central_accs_iid]\n",
    "for t in ts : \n",
    "    print(len(t)) \n",
    "exp.plot_fedMD_like(last_local_accs_iid, smooth_iid, last_central_accs_iid, \\\n",
    "    labels = ['Model ' + str(i) for i in range(n_parties)],\n",
    "     shades =None, \n",
    "     title = 'FedAKD accuracy on HARS dataset (i.i.d)' , limit = 5)\n",
    "\n",
    "exp.plot_fedMD_like(last_local_accs_noniid, smooth_noniid, last_central_accs_noniid, \\\n",
    "    labels = ['Model ' + str(i)  for i in range(n_parties)],\n",
    "     shades =None, \n",
    "     title = 'FedAKD accuracy HARS dataset (Non-i.i.d)', limit = 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('fl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f46111f1a6919d1b57bf7c88aba8eeca6cdf6548b00be16333f60903412df538"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
